DOI,Title,Authors,Abstract,Section,Date
https://doi.org/10.48550/arXiv.2503.18893,xkv cross layer svd kv cache compression,"Chi-Chih Chang, Chien-Yu Lin, Yash Akhauri, Wei-Cheng Lin, Kai-Chiang Wu, Luis Ceze, Mohamed S. Abdelfattah",large language model llm long context window enable powerful application come cost high memory consumption store key value state kv cache recent study attempt merge kv cache multiple layer share representation yet approach require expensive pretraining rely assumption high per token cosine similarity layer generally hold practice find dominant singular vector remarkably well aligned multiple layer kv cache exploit insight propose xkv simple post training method apply singular value decomposition svd kv cache grouped layer xkv consolidate kv cache multiple layer share low rank subspace significantly reduce kv cache size extensive evaluation ruler long context benchmark widely used llm xkv achieve high compression rate state of the art inter layer technique improve accuracy moreover xkv compatible emerge multi head latent attention mla yield notable compression rate cod task performance degradation result highlight xkv strong capability versatility address memory bottleneck long context llm inference code publicly available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18891,agentdropout dynamic agent elimination token efficient high performance llm based multi agent collaboration,"Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang",multi agent system ma base large language model llm demonstrate significant potential collaborative problem solving however still face substantial challenge low communication efficiency suboptimal task performance make careful design agent communication topology particularly important inspire management theory roles efficient team often dynamically adjust propose identify redundant agent communication different communication round optimize adjacency matrix communication graph eliminate enhance token efficiency task performance compare state of the art method agentdropout achieves average reduction prompt token consumption completion token consumption performance improvement task furthermore extended experiment demonstrate agentdropout achieves notable domain transferability structure robustness reveal reliability effectiveness release code http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18878,cover base interpret reason feature large language model sparse autoencoders,"Andrey Galichin, Alexey Dontsov, Polina Druzhinina, Anton Razzhigaev, Oleg Y. Rogov, Elena Tutubalina, Ivan Oseledets",large language model llm achieve remarkable success natural language processing recent advance lead developing new class reason llm example open source achieve state of the art performance integrate deep thinking complex reasoning impressive capability internal reasoning mechanism model remain unexplored work employ sparse autoencoders saes method learn sparse decomposition latent representation neural network interpretable feature identify feature drive reason series model first propose approach extract candidate reason feature sae representation validate feature empirical analysis interpretability method demonstrate direct correlation model reason ability crucially demonstrate steer feature systematically enhance reason performance offer first mechanistic account reason llm code available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18769,alphaspace enabling robotic action semantic tokenization symbolic reasoning,"Alan Dao (Gia Tuan Dao), Dinh Bach Vu, Bui Quang Huy",paper present alphaspace novel methodology design enhance spatial reasoning capability large language model llm cartesian space navigation alphaspace employ semantics based tokenization strategy encode height information specialize semantic token integrate primarily symbolic synthetic reasoning data approach enable llm accurately manipulate object position specific x z coordinate experimental result demonstrate alphaspace significantly outperform exist model manipulation subtasks achieve total accuracy compare claude sonnet,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18760,synthetic function demonstration improve generation low resource programming language,"Nick McKenna, Xinnuo Xu, Jack Williams, Nick Wilson, Benjamin Van Durme, Christian Poelitz",key consideration train llm target language less resourced english compare welsh python compare excel typical training data programming language consist real program demonstration couple human written comment present novel approach creation data low resource programming language generate fully synthetic textbook quality demonstration common library function example domain excel formula use teacher model finetune underperforming student model show improvement question answering datasets recast excel domain show advantage finetuning standard off the shelf rag approach offer modest improvement due unfamiliar target domain,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18751,construction identification disambiguation use bert case study npn,"Wesley Scivetti, Nathan Schneider",construction grammar hypothesize knowledge language consist chiefly knowledge form meaning pair construction include vocabulary general grammar rule even idiosyncratic pattern recent work show transformer language model represent least constructional pattern include one construction rare overall work probe bert representation form meaning minor construction english npn noun preposition noun construction exhibit expression face face day day know polysemous construct benchmark dataset semantically annotate corpus instance include distractors superficially resemble construction dataset train evaluate probe classifier achieve decent discrimination construction distractors well sense disambiguation true instance construction reveal bert embeddings carry indication construction semantics moreover artificially permute word order true construction instance cause reject indicate sensitivity matter form conclude bert latently encode least knowledge npn construction go surface syntactic pattern lexical cue,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18730,predict road ahead knowledge graph base foundation model scene understanding autonomous driving,"Hongkuan Zhou, Stefan Schmid, Yicong Li, Lavdim Halilaj, Xiangtong Yao, Wei cao",autonomous driving field see remarkable advancement various topic object recognition trajectory prediction motion planning however current approach face limitation effectively comprehend complex evolution drive scene time paper propose novel methodology train symbolic foundation model fm scene understanding autonomous driving leverage knowledge graph kg capture sensory observation domain knowledge road topology traffic rule complex interaction traffic participant bird eye view bev symbolic representation extract kg drive scene include spatio temporal information object scene bev representation serialize sequence token give pre trained language model plms learn inherent understanding co occurrence drive scene element generate prediction next scene conduct number experiment use nuscenes dataset kg various scenario result demonstrate fine tuned model achieve significantly high accuracy task fine tuned model achieve next scene prediction accuracy paper conclude offer promising foundation develop comprehensive model scene understanding autonomous driving,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18702,unsupervised acquisition discrete grammatical category,"David Ph. Shakouri, Crit Cremers, Niels O. Schiller",article present experiment perform use computational laboratory environment language acquisition experiment implement multi agent system consist two agent adult language model daughter language model aim learn mother language crucially daughter agent access internal knowledge mother language model language exemplars mother agent generates experiment illustrate system use acquire abstract grammatical knowledge demonstrate statistical analysis pattern input data correspond grammatical category yield discrete grammatical rule rule subsequently add grammatical knowledge daughter language model end hierarchical agglomerative cluster analysis apply utterance consecutively generate mother language model argue procedure use acquire structure resemble grammatical category propose linguist natural language thus establish non trivial grammatical knowledge acquire moreover parameter configuration computational laboratory environment determine use train data generate mother language model validate second experiment test set similarly result acquisition non trivial category,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18681,commander gpt fully unleash sarcasm detection capability multi modal large language model,"Yazhou Zhang, Chunwang Zou, Bo Wang, Jing Qin",sarcasm detection crucial research direction field natural language processing nlp attract widespread attention traditional sarcasm detection task typically focus single modal approach text due implicit subtle nature sarcasm method often fail yield satisfactory result recent year researcher shift focus sarcasm detection multi modal approach however effectively leverage multi modal information accurately identify sarcastic content remain challenge warrant exploration leverage powerful integrated processing capability multi modal large language model mllms various information source propose innovative multi modal commander gpt framework inspire military strategy first decompose sarcasm detection task six distinct sub task central commander decision maker assign best suited large language model address specific sub task ultimately detection result model aggregate identify sarcasm conduct extensive experiment mmsd mmsd utilize four multi modal large language model six prompt strategy experiment demonstrate approach achieve state of the art performance improvement score necessitate fine tuning ground truth rationale,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18646,zerolm data free transformer architecture search language model,"Zhen-Song Chen, Hong-Wei Ding, Xian-Jia Wang, Witold Pedrycz",neural architecture search nas provide systematic framework automate design neural network architecture widespread adoption hinder prohibitive computational requirement exist zero cost proxy method reduce search overhead demonstrate inadequate performance architecture ranking task particularly transformer based model often underperform simple parameter count metric current automate proxy discovery approach suffer extend search time susceptibility data overfitting structural complexity paper introduce novel zero cost proxy methodology quantify model capacity efficient weight statistic computation decompose transformer architecture functionally distinct sub module thereby optimize balance contribution overall performance comprehensive evaluation demonstrate superiority approach achieve spearman rho kendall tau flexibert benchmark propose method exhibit exceptional computational efficiency maintain robust performance diverse na benchmark task offer practical solution large scale architecture search,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18603,langalign enhance non english language model cross lingual embed alignment,"Jong Myoung Kim, Young-Jun Lee, Ho-Jin Choi, Sangkeun Jung",large language model gain attention many service developer still rely embedding based model due practical constraint case quality fine tuning data directly impact performance english datasets often use seed data train non english model study propose langalign enhance target language processing align english embed vector target language interface language model task header experiment korean japanese chinese demonstrate langalign significantly improve performance three language additionally show langalign apply reverse convert target language data format english based model process,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18596,linkalign scalable schema link real world large scale multi database text to sql,"Yihan Wang, Peiyu Liu, Xin Yang",schema linking critical bottleneck achieve human level performance text to sql task particularly real world large scale multi database scenario address schema link face two major challenge database retrieval select correct database large schema pool multi database setting filter irrelevant one schema item grounding accurately identify relevant table column large redundant schema sql generation address introduce linkalign novel framework effectively adapt exist baseline real world environment systematically address schema link framework comprise three key step multi round semantic enhance retrieval irrelevant information isolation challenge schema extraction enhancement challenge evaluate method performance schema link spider bird benchmark ability adapt exist text to sql model real world environment spider benchmark experiment show linkalign outperforms exist baseline multi database setting demonstrate effectiveness robustness hand method rank high model exclude use long chain of thought reasoning llm work bridge gap current research real world scenario provide practical solution robust scalable schema link code available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18594,clintext sp rigoberta clinical new set open resource spanish clinical nlp,"Guillem García Subies, Álvaro Barbero Jiménez, Paloma Martínez Fernández",present novel contribution spanish clinical natural language processing introduce large publicly available clinical corpus clintext sp state of the art clinical encoder language model rigoberta clinical corpus meticulously curated diverse open source include clinical case medical journal annotate corpus share task provide rich diverse dataset previously difficult access rigoberta clinical develop domain adaptive pretraining comprehensive dataset significantly outperform exist model multiple clinical nlp benchmark publicly release dataset model aim empower research community robust resource drive advancement clinical nlp ultimately contribute improve healthcare application,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18562,self reported confidence large language model gastroenterology analysis commercial open source quantize model,"Nariman Naderi, Seyed Amir Ahmad Safavi-Naini, Thomas Savage, Zahra Atf, Peter Lewis, Girish Nadkarni, Ali Soroush",study evaluate self reported response certainty several large language model gpt claude llama phi mistral gemini gemma qwen use gastroenterology board style question high performing model preview achieve brier score auroc new model demonstrate improved performance exhibit consistent tendency towards overconfidence uncertainty estimation present significant challenge safe use llm healthcare keywords large language model confidence elicitation artificial intelligence gastroenterology uncertainty quantification,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18539,natural language processing electronic health record scandinavian language norwegian swedish danish,"Ashenafi Zebene Woldaregay, Jørgen Aarmo Lund, Phuong Dinh Ngo, Mariyam Tayefi, Joel Burman, Stine Hansen, Martin Hylleholt Sillesen, Hercules Dalianis, Robert Jenssen, Lindsetmo Rolf Ole, Karl Øyvind Mikalsen",background clinical natural language processing nlp refers use computational method extract processing analyze unstructured clinical text data hold huge potential transform healthcare various clinical task objective study aim perform systematic review comprehensively assess analyze state of the art nlp method mainland scandinavian clinical text method literature search conduct various online database include pubmed sciencedirect google scholar acm digital library ieee xplore december february relevant reference included article also use solidify search final pool include article conduct clinical nlp mainland scandinavian language publish english result article focus norwegian clinical text swedish danish focus one language generally review identify positive development region observable gap disparity language substantial disparity level adoption transformer based model essential task de identification significantly less research activity focus norwegian danish compare swedish text review identify low level share resource data experimentation code pre trained model rate adaptation transfer learning region conclusion review present comprehensive assessment state of the art clinical nlp electronic health record ehr text mainland scandinavian language highlight potential barrier challenge hinder rapid advancement field region,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18526,sciclaims end to end generative system biomedical claim analysis,"Raúl Ortega, José Manuel Gómez-Pérez",validate key claim scientific literature particularly biomedical research essential ensure accuracy advance knowledge process critical sector pharmaceutical industry rapid scientific progress require automation deep domain expertise however current solution significant limitation lack end to end pipeline encompass claim extraction evidence retrieval verification step rely complex nlp information retrieval pipelines prone multiple failure point often fail provide clear user friendly justification claim verification outcomes address challenge introduce sciclaims advanced system power state of the art large language model llm seamlessly integrate entire scientific claim analysis process sciclaims outperform previous approach claim extraction verification require additional fine tuning set new benchmark automated scientific claim analysis,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18502,autoregressive language model knowledge base population case study space mission domain,"Andrés García-Silva, José Manuel Gómez-Pérez",knowledge base population kbp play crucial role populate maintain knowledge base up to date organization leverage domain corpus motivate increasingly large context window support large language model propose fine tune autoregressive language model end toend kpb case study involve population space mission knowledge graph fine tune model generate dataset end to end kbp tap exist domain resource case study show fine tuned language model limited size achieve competitive even high accuracy large model kbp task small model specialize kbp offer affordable deployment low cost inference moreover kbp specialist model require ontology include prompt allow space context additional input text output serialization,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18491,magic vqa multimodal ground inference commonsense knowledge visual question answer,"Shuo Yang, Siwen Luo, Soyeon Caren Han, Eduard Hovy",visual question answering vqa require reason visual textual modality yet large vision language model lvlms often lack integrated commonsense knowledge limit robustness real world scenario address introduce magic vqa novel framework enhance vqa systematically integrate commonsense knowledge lvlms magic vqa employ three stage process explicit knowledge integration external source by type post processing contextual refinement implicit knowledge augmentation use graph neural network gnn structure reasoning gnns bring great depth structure inference enable superior relational inference lvlms magic vqa bridge key gap unify commonsensse knowledge lvlm driven reasoning eliminate need extensive pre training complex prompt tuning framework achieve state of the art performance benchmark datasets significantly improve commonsense reason vqa,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18485,whisper amharic fine tuning whisper low resource language,"Dawit Ketema Gete, Bedru Yimam Ahamed, Tadesse Destaw Belay, Yohannes Ayana Ejigu, Sukairaj Hafiz Imam, Alemu Belay Tessema, Mohammed Oumer Adem, Tadesse Amare Belay, Robert Geislinger, Umma Aliyu Musa, Martin Semmann, Shamsuddeen Hassan Muhammad, Henning Schreiber, Seid Muhie Yimam",work explore fine tuning openai whisper automatic speech recognition asr model amharic low resource language improve transcription accuracy foundational whisper model struggle amharic due limited representation training data fine tune use datasets mozilla common voice fleurs bdu speech dataset best performing model whispersmall am significantly improve finetuned mix exist fleurs data new unseen amharic datasets train solely new data lead poor performance combine fleurs data reinforces model enable good specialization amharic also demonstrate normalize amharic homophone significantly enhance word error rate wer bilingual evaluation understudy bleu score study underscore importance fine tuning strategy dataset composition improve asr low resource language provide insight future amharic speech recognition research,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18471,word bridge explore computational support cross disciplinary translation work,"Calvin Bao, Yow-Ting Shiue, Marine Carpuat, Joel Chan",scholar often explore literature home community study exploration process frequently hamper field specific jargon past computational work often focus support translation work remove jargon simplification summarization explore different approach preserve jargon useful bridge new conceptual space specifically cast different scholarly domains different language using community explore adapt technique unsupervised cross lingual alignment word embeddings explore conceptual alignment domain specific word embed http url develop prototype cross domain search engine use align domain specific embeddings support conceptual exploration test prototype two case study discuss qualitative insight promise pitfall approach translation work suggest design insight future interface provide computational support cross domain information seek,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18432,teach llm step level automatic math correction reinforcement learning,"Junsong Li, Jie Zhou, Yutao Yang, Bihao Zhan, Qianjun Pan, Yuyang Ding, Qin Chen, Jiang Bo, Xin Lin, Liang He",automatic math correction aim check student solution mathematical problem artificial intelligence technology existing study focus judge final answer problem level ignore detailed feedback step math problem solving process require ability semantic understanding reasoning paper propose reinforcement learning rl  base method boost large language model llm step level automatic math correction name stepamc particularly convert step level automatic math correction text classification task rl problem enhance reason capability llm design space constrained policy network improve stability rl introduce fine grained reward network convert binary human feedback continuous value conduct extensive experiment two benchmark datasets result show model outperform eleven strong baseline,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18360,j h evaluate robustness large language model knowledge injection attack legal domain,"Yiran Hu, Huanghai Liu, Qingjing Chen, Ning Zheng, Chong Wang, Yun Liu, Charles L.A. Clarke, Weixing Shen",scale capability large language model llm increase application knowledge intensive field legal domain garner widespread attention however remain doubtful llm make judgment base domain knowledge reason llms base judgment solely specific word pattern rather underlie logic language llm as judges paradigm pose substantial risk real world application address question propose method legal knowledge injection attack robustness testing thereby infer llm learn legal knowledge reason logic paper propose j h evaluation framework detect robustness llm knowledge injection attack legal domain aim framework explore llms perform deductive reason accomplish legal task aim attack part reason logic underlie task major premise minor premise conclusion generation collect mistake legal expert might make judicial decision real world typo legal synonym inaccurate external legal statute retrieval however real legal practice legal expert tend overlook mistake make judgment base logic however face error llm likely mislead typographical error may utilize logic judgment conduct knowledge injection attack exist general domain specific llm current llm robust attack employ experiment addition propose compare several method enhance knowledge robustness llm,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18296,surgical action plan large language model,"Mengya Xu, Zhongzhen Huang, Jie Zhang, Xiaofan Zhang, Qi Dou",robot assisted minimally invasive surgery introduce surgical action planning sap task generate future action plan visual input address absence intraoperative predictive planning current intelligent application sap show great potential enhance intraoperative guidance automating procedure however face challenge understand instrument action relationship track surgical progress large language model llm show promise understand surgical video content remain underexplored predictive decision making sap focus mainly retrospective analysis challenge data privacy computational demand modality specific constraint highlight significant research gap tackle challenge introduce llm sap large language models based surgical action planning framework predict future action generates text response interpret natural language prompt surgical goal text responses potentially support surgical education intraoperative decision making procedure documentation skill analysis llm sap integrates two novel module near history focus memory module nhf mm model historical state prompt factory action planning evaluate llm sap construct dataset use model demonstrate effectiveness next action prediction pre trained llm test zero shot supervise fine tuning sft lora implement address data privacy concern experiment show surpasses high accuracy,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18293,fact checking ai generated news report llms catch lie,"Jiayi Yao, Haibo Sun, Nianwen Xue",paper evaluate ability large language model llm assess veracity claim news report generate llm goal determine llm effectively fact check content use method similar use verify claim make human finding indicate llm effective assess claim national international news story local news story good evaluate static information dynamic information good verify true claim compare false one hypothesize disparity arise former type claim well represent training data additionally find incorporate retrieve result search engine retrieval augmented generation rag set significantly reduce number claim llm assess however approach also increase occurrence incorrect assessment partly due irrelevant low quality search result diagnostic study highlight need future research fact checking machine generated report prioritize improve precision relevance retrieved information good support fact checking effort furthermore claim dynamic event local news may require human in the loop fact checking system ensure accuracy reliability,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18290,dataset cartography ineffective use train dynamic improve robustness adversarial squad,Paul K. Mandal,paper investigate effectiveness dataset cartography extractive question answer squad dataset begin analyze annotation artifact squad evaluate impact two adversarial datasets addsent addonesent electra small model use train dynamic partition squad easy to learn ambiguous hard to learn subset compare performance model train subset train randomly select sample equal size result show train cartography based subset improve generalization squad validation set addsent adversarial set hard to learn subset yield slightly high score addonesent dataset overall gain limit finding suggest dataset cartography provide little benefit adversarial robustness squad style qa task conclude compare result prior finding snli discus possible reason observed difference,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18288,sun shine large language model tibetan culture,"Cheng Huang, Fan Gao, Nyima Tashi, Yutong Liu, Xiangxiang Wang, Thupten Tsering, Ban Ma-bao, Renzeg Duojie, Gadeng Luosang, Rinchen Dongrub, Dorje Tashi, Xiao Feng, Yongbin Yu",tibetan minority language china feature highly intricate grammatical structure characterize four verb tense tense system frequent irregularity contribute extensive inflectional diversity recently advance large language model llm transform paradigm many domain success field current llm often fall short cater need domain expert tibetan potential llm tibetan culture under explored intrinsic reason immense intricate nature tibetan culture well necessity high granularity richness knowledge simultaneously complexity uniqueness grammatical structure couple status minority ethnic language contribute data scarcity remain fundamental challenge alleviate issue introduce llama sunshine sun shine first large language model tibetan culture expert various tibetan language processing task sun shine incorporate state of the art model architecture optimize tibetan linguistic feature also propose tib stc comprehensive dataset comprise diverse tibetan text literature religious script news conversational data also first large scale dataset tibetan culture comprehensive experiment sun shine demonstrate high level knowledge expertise tibetan culture also gain preliminary embody intelligence capability tibetan language processing task language modeling text classification machine translation syntactic analysis moreover excel low resource scenario showcasing strong generalization capability,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18260,bridge emotion architecture sentiment analysis modern distribute system,"Mahak Shah, Akaash Vishal Hazarika, Meetu Malhotra, Sachin C. Patil, Joshit Mohanty",sentiment analysis field nlp gain importance apply various area social medium surveillance customer feedback evaluation market research time distribute system allow effective processing large amount data therefore paper examine sentiment analysis converges distributed system concentrate different approach challenge future investigation furthermore extensive experiment train sentiment analysis model use single node configuration distributed architecture bring benefit shortcoming method term performance accuracy,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18253,enhance multi label emotion analysis corresponding intensity ethiopian language,"Tadesse Destaw Belay, Dawit Ketema Gete, Abinew Ali Ayele, Olga Kolesnikova, Grigori Sidorov, Seid Muhie Yimam",digital world people freely express emotion use different social medium platform result modeling integrate emotion understanding model vital various human computer interaction task decision making product customer feedback analysis political promotion marketing research social medium monitoring user express different emotion simultaneously single instance annotate emotion multilabel set ethioemo belay et dataset effectively capture dynamic additionally incorporate intensity degree emotion crucial emotion significantly differ expressive strength impact intensity significant assess action necessary decision making process especially concern negative emotion application healthcare mental health study enhance ethioemo dataset include annotation intensity label emotion furthermore evaluate various state of the art encoder only pretrained language model plms decoder only large language model llm provide comprehensive benchmarking,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18250,pad towards efficient data generation transfer learn use phrase alignment,"Jong Myoung Kim, Young-Jun_Lee, Ho-Jin Choi, Sangkeun Jung",transfer learning leverage abundance english data address scarcity resource model non english language korean study explore potential phrase align data pad standardized statistical machine translation smt enhance efficiency transfer learning extensive experiment demonstrate pad synergizes effectively syntactic characteristic korean language mitigate weakness smt significantly improve model performance moreover reveal pad complement traditional data construction method enhances effectiveness combine innovative approach boost model performance also suggest cost efficient solution resource scarce language,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18247,afroxlmr social adapt pre trained language model african language social medium text,"Tadesse Destaw Belay, Israel Abebe Azime, Ibrahim Said Ahmad, Idris Abdulmumin, Abinew Ali Ayele, Shamsuddeen Hassan Muhammad, Seid Muhie Yimam",pretrained language model plms build various source foundation today nlp progress language representation learn model achieve strong performance many task datasets vary size draw various source explore thorough analysis domain task adaptive continual pretraining approach low resource african language promising result show evaluated task create afrisocial corpus design domain adaptive finetuning pass quality pre processing step continual pretraining plms use afrisocial domain adaptive pretraining dapt data consistently improve performance fine grained emotion classification task targeted language macro score likewise use task adaptive pertaining tapt approach finetuning small unlabeled similar task data show promise result example unlabeled sentiment data source fine grained emotion classification task target improve base model result score range combine two method dapt tapt achieve also good result base model resource available improve low resource nlp task generally well similar domain task hate speech sentiment task,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18242,shed hd shannon entropy distribution framework lightweight hallucination detection edge device,"Aneesh Vathul, Daniel Lee, Sheryl Chen, Arthi Tasmia",large language model llm demonstrate impressive capability broad array nlp task tendency produce hallucination plausible sounding factually incorrect content pose severe challenge high stakes domain exist hallucination detection method bear computational cost multiple inference pass sacrifice accuracy efficiency single pass approach ideal resource constrained environment edge device propose shannon entropy distribution hallucination detector shed hd novel hallucination detection framework bridge gap classify sequence level entropy pattern use lightweight bilstm architecture single headed attention contrast prior approach shed hd efficiently detect distinctive uncertainty pattern entire output sequence preserve contextual awareness in depth evaluation three datasets bioasq triviaqa jeopardy question show shed hd significantly outperform computationally efficient approach out of distribution setting achieve comparable performance in distribution setting shed hd facilitates hallucination detection low cost accurate generalizable improve credibility content generate llm resource constrained environment trustworthy ai functionality crucial,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18226,map hymn organize concept rigveda quantitatively connect vedic suktas,"Venkatesh Bollineni, Igor Crk, Eren Gultepe",access gain insight rigveda pose non trivial challenge due extremely ancient sanskrit language poetic structure large volume text use nlp technique study identify topic semantic connection hymn rigveda corroborate seven well known grouping hymn suktas hymn modern english translation rigveda jamison brereton preprocessed sukta level embeddings obtain use novel adaptation lsa present herein ii sbert iii embeddings follow umap dimension reduction vector network suktas form use k near neighbour community detection topic sukta network perform louvain leiden label propagation method whose statistical significance form topic determine use appropriate null distribution novel adaptation lsa use leiden method detect sukta topic network significant z p modularity score seven famous sukta grouping analyze creation funeral water etc lsa derive network successful seven case significant fail detect relevant suktas sbert detect four famous suktas separate group mistakenly combine three single mixed group also sbert network statistically significant,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18212,lakotabert transformer based model low resource lakota language,"Kanishka Parankusham, Rodrigue Rizk, KC Santosh",lakota critically endanger language sioux people north america face significant challenge due decline fluency young generation paper introduce lakotabert first large language model llm tailor lakota aim support language revitalization effort research two primary objective create comprehensive lakota language corpus develop customized llm lakota compile diverse corpus sentence lakota english parallel text various source book website emphasize cultural significance historical context lakota language utilize roberta architecture pre train model conduct comparative evaluation establish model roberta bert multilingual bert initial result demonstrate masked language model accuracy single ground truth assumption showcasing performance comparable english based model also evaluate model use additional metric precision score provide comprehensive assessment capability integrate ai linguistic methodology aspire enhance linguistic diversity cultural resilience set valuable precedent leverage technology revitalization endanger indigenous language,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18182,explore topic trend research literature use non negative matrix factorization,"Divya Patel, Vansh Parikh, Om Patel, Agam Shah, Bhaskar Chaudhury",work apply topic model use non negative matrix factorization nmf open research dataset uncover underlying thematic structure evolution extensive body research literature factorize document term matrix two non negative matrix effectively represent topic distribution document help see strongly document relate topic topic relate word describe complete methodology involve series rigorous pre processing step standardize available text data preserve context phrase subsequently feature extraction use term frequency inverse document frequency tf idf assign weight word base frequency rarity dataset ensure robustness topic model conduct stability analysis process assess stability score nmf topic model different number topic enable select optimal number topic analysis analysis track evolution topic time dataset finding contribute understanding knowledge structure research landscape provide valuable resource future research field,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18174,ginger ground information nugget based generation response,"Weronika Łajewska, Krisztian Balog",retrieval augmented generation rag face challenge relate factual correctness source attribution response completeness address propose modular pipeline ground response generation operate information nuggets minimal atomic unit relevant information extract retrieved document multistage pipeline encompass detection cluster rank top cluster summarization fluency enhancement guarantee ground specific fact facilitate source attribution ensure maximum information inclusion length constraint extensive experiment trec dataset evaluate autonuggetizer framework demonstrate ginger achieve state of the art performance benchmark,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18172,unmask deceptive visuals benchmarking multimodal large language model mislead chart question answer,"Zixin Chen, Sicheng Song, Kashun Shum, Yanna Lin, Rui Sheng, Huamin Qu",mislead chart visualization intentionally manipulate data representation support specific claim distort perception lead incorrect conclusion decade research mislead visualization remain widespread pressing issue recent advance multimodal large language model mllms demonstrate strong chart comprehension capability yet exist work systematically evaluate ability detect interpret misleading chart paper introduce misleading chart question answer mislead chartqa benchmark large scale multimodal dataset design assess mllms identifying reason mislead chart contain curated example cover type misleader chart type example include standardized chart code csv data multiple choice question labeled explanation validate multi round mllm check exhaust expert human review benchmark state of the art mllms dataset reveal limitation identify visually deceptive practice also propose novel pipeline detect localize misleader enhance mllms accuracy mislead chart interpretation work establish foundation advance mllm driven misleading chart comprehension publicly release sample dataset support research critical area,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18167,evaluate negative sampling approach neural topic model,"Suman Adhya, Avishek Lahiri, Debarshi Kumar Sanyal, Partha Pratim Das",negative sampling emerge effective technique enable deep learning model learn good representation introduce paradigm learn to compare goal approach add robustness deep learning model learn good representation compare positive sample negative one numerous demonstration various area computer vision natural language processing comprehensive study effect negative sampling unsupervised domain topic modeling well explore paper present comprehensive analysis impact different negative sampling strategy neural topic model compare performance several popular neural topic model incorporate negative sampling technique decoder variational autoencoder based neural topic model experiment four publicly available datasets demonstrate integrate negative sampling topic model result significant enhancement multiple aspect include improve topic coherence rich topic diversity accurate document classification manual evaluation also indicate inclusion negative sample neural topic model enhance quality generated topic finding highlight potential negative sampling valuable tool advance effectiveness neural topic model,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18132,mathagent leverage mixture of math agent framework real world multimodal mathematical error detection,"Yibo Yan, Shen Wang, Jiahao Huo, Philip S. Yu, Xuming Hu, Qingsong Wen",mathematical error detection educational setting present significant challenge multimodal large language model mllms require sophisticated understanding visual textual mathematical content complex reason capability effective mathematical problem solving mllms often struggle nuanced task identify categorize student error multimodal mathematical context therefore introduce mathagent novel mixture of math agent framework design specifically address challenge approach decompose error detection three phase handle specialized agent image text consistency validator visual semantic interpreter integrative error analyzer architecture enable accurate processing mathematical content explicitly model relationship multimodal problem student solution step evaluate mathagent real world educational data demonstrate approximately high accuracy error step identification improvement error categorization compare baseline model besides mathagent successfully deploy educational platform serve one million student achieve nearly student satisfaction generate significant cost saving reduce manual error detection,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18129,geobenchx benchmarking llm multistep geospatial task,"Varvara Krechetova, Denis Kochedykov",paper establish benchmark evaluate large language model llm multi step geospatial task relevant commercial gi practitioner assess seven lead commercial llm sonnet haiku gemini mini use simple tool calling agent equip geospatial function benchmark comprise task four category increase complexity solvable intentionally unsolvable task test hallucination rejection develop llm as judge evaluation framework compare agent solution reference implementation result show sonnet achieve best overall performance claude model excel solvable task openai model well identify unsolvable scenario observe significant difference token usage anthropic model consume substantially token competitor common error include misunderstand geometrical relationship rely outdated knowledge inefficient data manipulation result benchmark set evaluation framework data generation pipeline release open source resource provide one standardized method ongoing evaluation llm geoai,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18117,detection somali written fake news toxic message social medium use transformer based language model,"Muhidin A. Mohamed, Shuab D. Ahmed, Yahye A. Isse, Hanad M. Mohamed, Fuad M. Hassan, Houssein A. Assowe",fact everyone social medium account create share content increase public reliance social medium platform news information source bring significant challenge misinformation fake news harmful content etc human content moderation may useful extent use platform flag posted material use ai model provide sustainable scalable effective way mitigate harmful content however low resourced language somali language face limitation ai automation include scarce annotate train datasets lack language model tailor unique linguistic characteristic paper present part ongoing research work bridge gap somali language particular create two human annotated social media sourced somali datasets two downstream application fake news toxicity classification develop transformer based monolingual somali language model name somberta first kind best knowledge somberta fine tuned evaluate toxic content fake news news topic classification datasets comparative evaluation analysis propose model related multilingual model afriberta afroxlmr etc demonstrate somberta consistently outperform comparators fake news toxic content classification task achieve best average accuracy task research contribute somali nlp offer foundational language model replicable framework low resource language promote digital ai inclusivity linguistic diversity,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18095,clarify misconception vaccine sentiment stance analysis implication vaccine hesitancy mitigation systematic review,"Lorena G Barberia, Belinda Lombard, Norton Trevisan Roman, Tatiane C. M. Sousa",background advance machine learning ml model increase capability researcher detect vaccine hesitancy social medium use natural language processing nlp considerable volume research identify persistence vaccine hesitancy discourse share various social medium platform method objective study conduct systematic review research employ sentiment analysis stance detection study discourse towards vaccine vaccination spread twitter officially know x follow registration prospero international registry systematic review search paper publish january december use supervise machine learn assess vaccine hesitancy stance detection sentiment analysis twitter categorize study accord taxonomy five dimension tweet sample selection approach self reported study type classification typology annotation codebook definition interpretation result analyze study use stance detection report different hesitancy trend use sentiment analysis examine vaccine hesitancy measure effort make avoid measurement bias result review find measurement bias widely prevalent study employ supervised machine learn analyze sentiment stance vaccine vaccination reporting error sufficiently serious hinder generalisability interpretation study understand individual opinion communicate reluctance vaccinate conclusion improve reporting nlp method crucial address knowledge gap vaccine hesitancy discourse,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18089,data driven lora initialization low resource task,"Javad SeraJ, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti",tune large language model essential optimize performance diverse application particularly scenario limited data availability tune large language model scarce data scenario crucial particularly give convergence speed lora method low full fine tuning paper present analysis post training method include supervise fine tuning sft direct preference optimization dpo odds ratio preference optimization orpo context task specific learn use lora method introduce data driven approach initialize lora metric enhance training efficiency especially limited data setting experiment compare vanilla lora term performance catastrophic forget extremely data constrained condition result demonstrate achieve improvement benchmark improvement rouge score title generation task facilitate adaptation llm multiple task even task specific data scarce thereby reduce training expense offer data cost,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18085,temporal relation extraction clinical text span based graph transformer approach,"Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio",temporal information extraction unstructured text essential contextualizing event derive actionable insight particularly medical domain address task extract clinical event temporal relation use well studied temporal relation challenge corpus task inherently challenge due complex clinical language long document sparse annotation introduce graphtrex novel method integrate span based entity relation extraction clinical large pre trained language model lplms heterogeneous graph transformer hgt capture local global dependency hgt component facilitate information propagation document innovative global landmark bridge distant entity method improve state of the art improvement tempeval score previous best improvement long range relation present formidable challenge work advance temporal information extraction also lay groundwork improve diagnostic prognostic model enhanced temporal reasoning,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18076,multi model adaptation speculative decoding classification,"Somnath Roy, Padharthi Sreekar, Srivatsa Narasimha, Anubhav Anand",current study introduce novel adaptation speculative decoding repurposed generation classification task propose multi model framework employ three lightweight worker model single robust judge model analogous draft model target model respectively speculative decoding worker model task bulk computation independently predict discrete class label give input majority worker model agree label accept final label optimize efficiency bypass computationally expensive judge model case disagreement judge model intervenes resolve label approach minimize redundant computation leverage redundancy multiple worker confidence confine judge model role challenge case offer practical balance efficiency accuracy analysis suggest small box finetuned worker model billion parameter hereafter demonstrate level alignment judge model comparable large finetuned worker model billion parameter hereafter simple high order reason task top performing worker model pair achieve agreement rate approximately sentiment similar ticket compare judge model additionally worker model provide speedup range relative judge model worker model combination achieve speedup range,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18072,effectiveness llm automatic grading open ended question spanish,"Germán Capdehourat, Isabel Amigo, Brian Lorenzo, Joaquín Trigo",grading time consuming laborious task educator must face important task provide feedback signal learner demonstrate timely feedback improve learning process recent year irruption llm shed light effectiveness automatic grading paper explore performance different llm prompt technique automatically grade short text answer open ended question literature study focus use case question answer prompt spanish experimental result compare automatic score human expert evaluator show good outcome term accuracy precision consistency advanced llm open proprietary result notably sensitive prompt style suggest bias certain word content prompt however best combination model prompt strategy consistently surpass accuracy three level grading task even rise simplify binary right wrong rating problem demonstrate potential llm implement type automation education application,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18071,mind eye language reason multimodal reason,"Zhiyu Lin, Yifei Gao, Xian Zhao, Yunfan Yang, Jitao Sang",language model recently advance realm reasoning multimodal reasoning fully unlock potential achieve comprehensive human like cognitive capability survey provide systematic overview recent multimodal reason approach categorize two level language centric multimodal reasoning collaborative multimodal reasoning former encompasses one pass visual perception active visual perception vision primarily serve support role language reasoning latter involve action generation state update reason process enable dynamic interaction modality furthermore analyze technical evolution method discuss inherent challenge introduce key benchmark task evaluation metric assess multimodal reason performance finally provide insight future research direction follow two perspective visual language reason omnimodal reasoning ii multimodal reason multimodal agent survey aim provide structured overview inspire advancement multimodal reason research,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18069,long important difficult train reasoning model,"Si Shen, Fei Huang, Zhixiao Zhao, Chang Liu, Tiansheng Zheng, Danhao Zhu",difficult problem often result long reasoning trace widely recognize key factor enhance performance reason model however high challenge problem scarce limit size available datasets paper propose simple method decouple reliance problem difficulty first empirically demonstrate reason length rather problem difficulty primarily influence performance trained model second identify scaling law reason length show model performance increase log linear fashion reason data length grows finally introduce straightforward technique generate reason data arbitrary length show synthesize data effective train reason model fine tune language model dataset present model achieve remarkable performance training sample achieve accuracy math gpqa outperform model code dataset open sourced available http url,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18063,dynamic task vector group efficient multi task prompt tuning,"Pieyi Zhang, Richong Zhang, Zhijie Nie",multi task prompt tune utilizes multiple high resource source task improve performance low source target task exist approach transfer soft prompt train combine source task single high similar source task one time only however find optimal transfer performance often come combination source task one find similarity source target task also change dynamically fine tuning transfer make similarity calculation initiation stage inadequate address issue propose method call dynamic task vector grouping dtvg whose core idea contain measure task similarity task vector instead soft prompt group optimal source task combination base two metric target similarity knowledge consistency dynamically update combination iteration step extensive experiment nlp datasets different setting demonstrate dtvg effectively group similar source task reduce negative transfer achieve start of art performance,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18062,investigate recent large language model vietnamese machine reading comprehension,"Anh Duc Nguyen, Hieu Minh Phi, Anh Viet Ngo, Long Hai Trieu, Thai Phuong Nguyen",large language model llm show remarkable proficiency machine reading comprehension mrc task however effectiveness low resource language vietnamese remains largely unexplored paper fine tune evaluate two state of the art llm llama parameter gemma parameter vimmrc vietnamese mrc dataset utilize quantized low rank adaptation qlora efficiently fine tune model compare performance powerful llm based baseline fine tuned model small outperform traditional bert based approach large model demonstrate effectiveness fine tuning process showcasing modern llm surpass capability old model bert still suitable deployment resource constrained environment intensive analysis explore various aspect model performance provide valuable insight adapt llm low resource language vietnamese study contribute advancement natural language processing low resource language make fine tuned model publicly available http url,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18008,personalize language model privacy preserving evolutionary model merge,"Kyuyoung Kim, Jinwoo Shin, Jaehyung Kim",personalization large language model llm seek tailor model individual user user group preference prompt based method augment query user preference information training based method directly encode preference model parameter effective personalization achieve success personalize llm prior method often fail directly optimize task specific metric lack explicit privacy preservation mechanism address limitation propose privacy preserving model merge evolutionary algorithm prime novel approach personalization employ gradient free method directly optimize task specific metric preserve user privacy incorporate privacy preservation optimization prime produce personalized module effectively capture target user preference minimize privacy risk user share private information experiment lamp benchmark show prime outperforms prompt based training based method achieve performance improvement prior art analysis show prime achieve significantly well privacy utility trade off highlight potential evolutionary approach privacy preserving llm personalization,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17994,instruct architecture search spatial temporal sequence forecasting llm,"Xin Xue, Haoyi Zhou, Tianyu Chen, Shuai Zhang, Yizhou Long, Jianxin Li",spatial temporal sequence forecasting stsf long standing research problem widespread real world application neural architecture search nas automate neural network design show effective tackle stsf problem however exist na method stsf focus generate architecture time consuming data driven fashion heavily limit ability use background knowledge explore complicate search trajectory large language model llm show remarkable ability decision making comprehensive internal world knowledge could benefit na stsf remain unexplored paper propose novel nas method stsf base llm instead directly generate architecture llm inspire llm capability multi level enhancement mechanism specifically step level decompose generation task decision step powerful prompt engineering inspire llm serve instructor architecture search base internal knowledge instance level utilize one step tuning framework quickly evaluate architecture instance memory bank cumulate knowledge improve llm search ability task level propose two stage architecture search balance exploration stage optimization stage reduce possibility trap local optimum extensive experimental result demonstrate method achieve competitive effectiveness superior efficiency exist nas method stsf,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17965,understand effect rlhf quality detectability llm generated text,"Beining Xu, Arkaitz Zubiaga",large language model llm demonstrate exceptional performance range downstream nlp task generate text closely resemble human write however ease achieve similarity raise concern potential malicious us scale bad actor llm generated text become increasingly difficult discern human text detection method develop address issue bad actor manipulate llm generated text make less detectable work study edit text reinforcement learn human feedback rlhf align model output human preference affect quality generated text two task b performance llm generated text detector look training based zero shot detection method rlhf improve quality llm generated text find also tend produce detectable lengthy repetitive output additionally observe training based detector vulnerable short text texts incorporate code zero shot detector exhibit great robustness,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17963,establishing best practice korean financial nlp,"Guijin Son, Hyunwoo Ko, Haneral Jung, Chami Hwang",work present first open leaderboard evaluate korean large language model focus finance operate eight week leaderboard evaluate submission closed benchmark cover five mcqa category finance accounting stock price prediction domestic company analysis financial market financial agent task one open ended qa task building insight evaluation release open instruction dataset instance summarize widely used training strategy observe top performing model finally introduce fully open transparent llm build use best practice hope contribution help advance development good safer financial llm korean language,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17952,slide slide localize information document extraction,"Divyansh Singh, Manuel Nunez Martinez, Bonnie J. Dorr, Sonja Schmer Galunder",construct accurate knowledge graph long text low resource language challenge large language model llm experience degrade performance long input chunk problem amplify low resource setting data scarcity hinders accurate entity relationship extraction contextual retrieval method improve retrieval accuracy struggle long document truncate critical information text exceed maximum context length llm significantly limit knowledge graph construction introduce slide slide localize information document extraction chunk method process long document generate local context overlap window slide ensure essential contextual information retain enhance knowledge graph extraction document exceed llm context limit significantly improve graphrag performance achieve increase entity extraction improvement relationship extraction english afrikaans low resource language slide achieve increase entity extraction improvement relationship extraction furthermore improve state of the art question answering metric comprehensiveness diversity empowerment demonstrate effectiveness multilingual resource constrained setting,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17936,empirical study role incompleteness ambiguity interaction large language model,"Riya Naik, Ashwin Srinivasan, Estrid He, Swati Agarwal",natural language medium human computer interaction long anticipate undergo sea change advent large language model llm startle capacity processing generating language many treat llm modern day oracle ask almost kind question delphic predecessor consult llm single turn activity ask question receive answer leave also pythia widely acknowledge answer llm improve additional context paper aim study need multi turn interaction llm successfully get question answer conclude question unanswerable present neural symbolic framework model interaction human llm agent propose framework define incompleteness ambiguity question property deducible message exchange interaction provide result benchmark problem answer correctness show depend question demonstrate presence incompleteness ambiguity accord property identify result show multi turn interaction usually require datasets high proportion incompleteness ambiguous question increase interaction length effect reduce incompleteness ambiguity result also suggest measure incompleteness ambiguity useful tool characterise interaction llm question answeringproblems,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17933,experience retrieval augmentation electronic health record enable accurate discharge qa,"Justice Ou, Tinglin Huang, Yilun Zhao, Ziyang Yu, Peiqing Lu, Rex Ying",improve reliability large language model llm clinical application retrieval augmented generation rag extensively apply provide factual medical knowledge however general medical knowledge open ended datasets clinical case based knowledge also critical effective medical reasoning provide context ground real world patient experience motivate propose experience retrieval augmentation exprag framework base electronic health record ehr aim offer relevant context patient discharge report exprag performs retrieval coarse to fine process utilize ehr based report ranker efficiently identify similar patient follow experience retriever extract task relevant content enhanced medical reasoning evaluate exprag introduce dischargeqa clinical qa dataset discharge related question diagnosis medication instruction task problem generate use ehr data ensure realistic challenging scenario experimental result demonstrate exprag consistently outperform text based ranker achieve average relative improvement highlight importance case based knowledge medical reasoning,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17932,stshield single token sentinel real time jailbreak detection large language model,"Xunguang Wang, Wenxuan Wang, Zhenlan Ji, Zongjie Li, Pingchuan Ma, Daoyuan Wu, Shuai Wang",large language model llm become increasingly vulnerable jailbreak attack circumvent safety mechanism exist defense method suffer adaptive attack require computationally expensive auxiliary model present stshield lightweight framework real time jailbroken judgement stshield introduce novel single token sentinel mechanism append binary safety indicator model response sequence leverage llm alignment capability detection framework combine supervise fine tuning normal prompt adversarial train use embedding space perturbation achieve robust detection preserve model utility extensive experiment demonstrate stshield successfully defend various jailbreak attack maintain model performance legitimate query compare exist approach stshield achieves superior defense performance minimal computational overhead make practical solution real world llm deployment,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17922,windowkv task adaptive group wise kv cache window selection efficient llm inference,"Youhui Zuo, Sibo Wei, Chen Zhang, Zhuorui Liu, Wenpeng Lu, Dawei Song",advancement long context inference capability large language model llm kv cache become one foundational component however substantial gpu memory consumption make kv cache compression key technique enable efficient llm inference industrial scenario recent study focus optimize memory occupy kv cache overlook two critical factor preserve semantic coherence consider task specific characteristic compression address limitation propose novel task adaptive kv cache window selection method windowkv windowkv dynamically select local semantic window consist consecutive token accord task specific characteristic ensure retain kv cache capture continuous essential context additionally introduce intra group layer kv cache index share strategy reduce computational overhead achieve balance performance efficiency rigorously evaluate windowkv longbench benchmark result demonstrate maintain performance comparable full kv cache retention use original kv cache significantly reduce memory requirement furthermore method also achieve state of the art result needle in a haystack evaluation highlight effectiveness robustness,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17900,medplan two stage rag based system personalized medical plan generation,"Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu",recent success apply large language model llm electronic health record ehr system focus primarily assessment rather treatment planning identify three critical limitation current approach generate treatment plan single pas rather follow sequential reasoning process use clinician rarely incorporate patient specific historical context fail effectively distinguish subjective objective clinical information motivate soap methodology subjective objective assessment plan introduce medplan novel framework structure llm reason align real life clinician workflow approach employ two stage architecture first generate clinical assessment base patient symptom objective data formulate structured treatment plan inform assessment enrich patient specific information retrieval augmented generation comprehensive evaluation demonstrate method significantly outperform baseline approach assessment accuracy treatment plan quality,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17882,think refusal trigger safety reflection llm mitigate false refusal behavior,"Shengyun Si, Xinpeng Wang, Guangyao Zhai, Nassir Navab, Barbara Plank",recent advancement large language model llm demonstrate fine tuning human alignment render llms harmless practice harmlessness behavior mainly achieve train model reject harmful request explain burn neighbor house model appropriately decline respond however approach inadvertently result false refusal model reject benign query well tell kill python process work demonstrate prompt safety reflection generate response mitigate false refusal behavior building finding introduce think before refusal tbr schema conduct safety aware instruction fine tuning incorporating safety reflection ablation study pre trained model show model fine tune safety reflection significantly reduce false refusal behavior maintain safety overall performance compare fine tuned safety reflection,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17876,satisfactory medical consultation base terminology enhanced information retrieval emotional in context learning,"Kaiwen Zuo, Jing Tang, Hanbing Qin, Binli Luo, Ligang He, Shiyan Tang",recent advancement large language model llm mark significant progress understanding respond medical inquiry however performance still fall short standard set professional consultation paper introduce novel framework medical consultation comprise two main module terminology enhanced information retrieval teir emotional in context learning eicl teir ensures implicit reason utilization inductive knowledge key terminology retrieval overcome limitation restricted domain knowledge public database additionally module feature capability process long context eicl module aid generate sentence high attribute relevance memorize semantic attribute information unlabelled corpus apply control retrieval required information furthermore dataset comprise consultation record compile china significantly enhance model capability complex dialogue proactive inquiry initiation comprehensive experiment demonstrate propose method effectiveness extend context window length exist llm experimental outcome extensive data validate framework superiority five baseline model term bleu rouge performance metric substantial lead certain capability notably ablation study confirm significance teir eicl component addition new framework potential significantly improve patient satisfaction real clinical consulting situation,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17860,enhance retrieval system inference time logical reasoning,"Felix Faltings, Wei Wei, Yujia Bao",traditional retrieval method rely transform user query vector representation retrieve document base cosine similarity embedding space efficient scalable approach often fail handle complex query involve logical construct negation conjunction disjunction paper propose novel inference time logical reasoning framework explicitly incorporate logical reason retrieval process method extract logical reason structure natural language query compose individual cosine similarity score formulate final document score approach enable retrieval process handle complex logical reasoning compromise computational efficiency result synthetic real world benchmark demonstrate propose method consistently outperform traditional retrieval method different model datasets significantly improve retrieval performance complex query,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17811,feather sql lightweight framework dual model collaboration paradigm small language model,"Wenqi Pei, Hailing Xu, Hengyuan Zhao, Shizheng Hou, Han Chen, Zining Zhang, Pingyi Luo, Bingsheng He",natural language sql see significant advancement large language model llm however model often depend closed source system high computational resource pose challenge data privacy deployment contrast small language model slms struggle task exhibit poor performance incompatibility exist framework address issue introduce feather sql new lightweight framework tailor slms feather sql improves sql executability accuracy schema pruning linking multi path multi candidate generation additionally introduce model collaboration paradigm pair strong general purpose chat model fine tuned sql specialist combine strong analytical reasoning high precision sql generation experimental result bird demonstrate feather sql improves performance slms boost model fine tuning propose paradigm raise accuracy ceiling slms highlight effectiveness,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17810,parsipy nlp toolkit historical persian text python,"Farhan Farsi, Parnian Fazel, Sepand Haghighi, Sadra Sabouri, Farzaneh Goshtasb, Nadia Hajipour, Ehsaneddin Asgari, Hossein Sameti",study historical language present unique challenge due complex orthographic system fragmentary textual evidence absence standardized digital representation text language tackle challenge need special nlp digital tool handle phonetic transcription analyze ancient text work introduce parsipy nlp toolkit design facilitate analysis historical persian language offer module tokenization lemmatization part of speech tagging phoneme to transliteration conversion word embedding demonstrate utility toolkit processing parsig middle persian text highlight potential expand computational method study historical language work contribute computational philology offering tool adapt broad study ancient text digital preservation,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17799,relation extraction instance adapted predicate description,"Yuhang Jiang, Ramakanth Kavuluru",relation extraction standard information extraction task play major role downstream application knowledge discovery question answer decoder only large language model excel generative task small encoder model still go architecture paper revisit fine tuning small model use novel dual encoder architecture joint contrastive cross entropy loss previous method employ fixed linear layer predicate representation approach use second encoder compute instance specific predicate representation infuse real entity span correspond input instance conduct experiment two biomedical datasets two general domain datasets approach achieve score improvement range state of the art method simple elegant formulation ablation study justify importance various component build propose architecture,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17755,improve preference extraction llm identify latent knowledge classify probe,"Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen",large language model llm often use automated judge evaluate text effectiveness hinder various unintentional bias propose use linear classify probe train leverage difference contrast pair prompt directly access llm latent knowledge extract accurate preference extensive experiment use model vary size four different family six diverse datasets assess text quality evaluation common sense reasoning demonstrate supervise unsupervised probing approach consistently outperform traditional generation based judgement maintain similar computational cost probe generalise domain shift even outperform finetuned evaluator training data size result suggest linear probe offer accurate robust computationally efficient approach llm as judge task provide interpretable insight model encode judgement relevant knowledge data code openly release future,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17753,build resource constrained language agent korean case study chemical toxicity information,"Hojun Cho, Donghu Kim, Soyoung Yang, Chan Lee, Hunjoo Lee, Jaegul Choo",language agent power large language model llm face significant deployment challenge resource constrained environment particularly specialized domain less common language paper present tox chat korean chemical toxicity information agent devise limitation propose two key innovation context efficient architecture reduce token consumption hierarchical section search scenario based dialogue generation methodology effectively distill tool using capability large model experimental evaluation demonstrate fine tuned parameter model substantially outperform untuned model baseline approach term db faithfulness preference work offer valuable insight researcher develop domain specific language agent practical constraint,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17739,enhance arabic automate essay score synthetic data error injection,"Chatrine Qwaider, Bashar Alhafni, Kirill Chirkunov, Nizar Habash, Ted Briscoe",automate essay scoring aes play crucial role assess language learner write quality reduce grade workload provide real time feedback arabic aes system particularly challenge lack annotated essay datasets paper present novel framework leverage large language model llm transformer generate synthetic arabic essay datasets aes prompt llm generate essay cefr proficiency level introduce control error injection use fine tuned standard arabic bert model error type prediction approach produce realistic human like essay contribute dataset annotated essay additionally develop bert based auto marking system accurate scalable arabic essay evaluation experimental result demonstrate effectiveness framework improve arabic aes performance,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17684,llms automate fact checking article writing,"Dhruv Sahnan, David Corney, Irene Larraz, Giovanni Zagni, Ruben Miguez, Zhuohan Xie, Iryna Gurevych, Elizabeth Churchill, Tanmoy Chakraborty, Preslav Nakov",automatic fact checking aim support professional fact checker offer tool help speed manual fact checking yet exist framework fail address key step produce output suitable broad dissemination general public human fact checker communicate finding fact checking article automate system typically produce little justification assessment aim bridge gap argue need extend typical automatic fact checking pipeline automatic generation full fact checking article first identify key desideratum article series interview expert lead fact checking organization develop qraft llm based agentic framework mimic write workflow human fact checker finally assess practical usefulness qraft human evaluation professional fact checker evaluation show qraft outperforms several previously propose text generation approach lag considerably expert written article hope work enable research new important direction,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17662,enhance persona consistency llm role playing use persona aware contrastive learning,"Ke Ji, Yixin Lian, Linxu Li, Jingsheng Gao, Weiyuan Li, Bin Dai",recent year large language model llm achieve progress many dialogue generation task however lack emotion fine grained role awareness limit model ability provide personalized diverse interaction current method face high cost collect high quality annotate data scenario role playing traditional human alignment method difficult deploy due inherent diversity model behavior role playing scenario inspire alignment model safety behavior rlhf reinforcement learn human feedback paper revisit model role playing behavior perspective persona alignment propose novel annotation free framework name p ersona aware c ontrastive l earn pcl align llm behavior role playing enhance model role consistency specifically first design role chain method encourage model self question base role characteristic dialogue context adjust personality consistency enhance model role playing strategy iterative contrastive learning use role characteristic experiment black box white box llm show llm equip pcl significantly outperform vanilla llm automatic evaluation method chareval human expert evaluation,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17599,gpbench comprehensive fine grained benchmark evaluate large language model general practitioner,"Zheqing Li, Yiying Yang, Jiping Lang, Wenhao Jiang, Yuhang Zhao, Shuang Li, Dingqian Wang, Zhu Lin, Xuanna Li, Yuze Tang, Jiexian Qiu, Xiaolin Lu, Hongji Yu, Shuang Chen, Yuhua Bi, Xiaofei Zeng, Yixian Chen, Junrong Chen, Lin Yao",general practitioner gps serve cornerstone primary healthcare system provide continuous comprehensive medical service however due community oriented nature practice uneven training resource gap clinical proficiency gps vary significantly region healthcare setting currently large language model llm demonstrate great potential clinical medical application make promising tool support general practice however exist benchmark evaluation framework focus exam style assessments typically multiple choice question lack comprehensive assessment set accurately mirror real world scenario encounter gps evaluate effectively llms make decision daily work gps design gpbench consist test question clinical practice novel evaluation framework test set include multiple choice question assess fundamental knowledge general practice well realistic scenario based problem question meticulously annotate expert incorporate rich fine grained information relate clinical management propose llm evaluation framework base competency model general practice provide comprehensive methodology assess llm performance real world setting first large model evaluation set target gp decision making scenario gpbench allow evaluate current mainstream llm expert assessment evaluation reveal area disease staging complication recognition treatment detail medication usage model exhibit least ten major shortcoming overall exist llm yet suitable independent use real world gp work scenario human oversight,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17579,leverage human production interpretation asymmetry test llm cognitive plausibility,"Suet-Ying Lam, Qingcheng Zeng, Jingyi Wu, Rob Voigt",large language model llm process language similarly human subject much theoretical practical debate examine question lens production interpretation distinction find human sentence processing evaluate extent instruction tuned llm replicate distinction use empirically document asymmetry production interpretation human implicit causality verb testbed find llm quantitatively qualitatively reflect human like asymmetry production interpretation demonstrate behavior hold depend model size large model likely reflect human like pattern choice meta linguistic prompt use elicit behavior,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17523,bayesian teaching enables probabilistic reasoning large language model,"Linlu Qiu, Fei Sha, Kelsey Allen, Yoon Kim, Tal Linzen, Sjoerd van Steenkiste",artificial intelligence system base large language model llm increasingly use agent interact user world successfully llm need construct internal representation world form probabilistic belief representation provide user personalized recommendation example llm need gradually infer user preference course multiple interaction evaluate contemporary llm able use bayesian inference framework probability theory lay optimal way update agent belief receive new information first show llm update belief expect bayesian framework consequently prediction improve expect information become available even less find case human address issue teach llm reason bayesian manner train mimic prediction optimal bayesian model find approach significantly improve llm performance particular recommendation task train also enable generalization task suggest method endow llm broad bayesian reasoning skill generally result indicate llm learn reason strategy effectively generalize skill new domain part explain llm empirical success,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17514,language model may verbatim complete textthey explicitly train,"Ken Ziyu Liu, Christopher A. Choquette-Choo, Matthew Jagielski, Peter Kairouz, Sanmi Koyejo, Percy Liang, Nicolas Papernot",important question today give text use train large language model llm completion test often employ check llm complete sufficiently complex text however require ground truth definition membership commonly define member base n  gram overlap target text text dataset work demonstrate n  gram base membership definition effectively game study scenario sequence non member give n find completion test still succeed find many natural case phenomenon retrain llm scratch remove training sample complete case include exact duplicate near duplicate even short overlap showcase difficult find single viable choice n membership definition use insight design adversarial datasets cause give target sequence complete contain reasonable choice n finding highlight inadequacy n  gram membership suggest membership definition fail account auxiliary information available training algorithm,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17509,follow up question generation enhanced patient provider conversation,"Joseph Gatto, Parker Seegmiller, Timothy Burdick, Inas S. Khayal, Sarah DeLozier, Sarah M. Preum",follow up question generation essential feature dialogue system reduce conversational ambiguity enhance modeling complex interaction conversational context often pose core nlp challenge extract relevant information bury fragmented data source ii model parallel thought process two challenge occur frequently medical dialogue doctor ask question base patient utterance also prior ehr data current diagnostic hypothesis ask medical question asynchronous conversation compound issue doctor rely static ehr information motivate follow up challenge introduce followupq novel framework enhance asynchronous medical conversation followupq multi agent framework process patient message ehr data generate personalized follow up question clarify patient reported medical condition followupq reduce requisite provider follow up communication also improve performance real synthetic data respectively also release first public dataset asynchronous medical message link ehr data alongside follow up question write clinical expert wider nlp research community,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17489,judge anything mllm judge modality,"Shu Pu, Yaochen Wang, Dongping Chen, Yuhang Chen, Guohao Wang, Qi Qin, Zhongyi Zhang, Zhiyuan Zhang, Zetong Zhou, Shuang Gong, Yi Gui, Yao Wan, Philip S. Yu",evaluate generative foundation model open ended multimodal understanding mmu generation mmg task diverse modality image audio video pose significant challenge due complexity cross modal interaction end idea utilize multimodal llm mllms automate judge emerge encouraging result assess vision language understanding task move paper extend mllm as a judge modality unified manner introduce two benchmark taskanything judgeanything respectively evaluate overall performance judge capability mllms any to any modality task specifically taskanything evaluate mmu mmg capability any to any modality category employ query curated well established benchmark furthermore judgeanything evaluate judging capability advanced perspective pair comparison score evaluation provide standardized testbed incorporate human judgment detailed rubric extensive experiment reveal mllms show promise assess mmu achieve average pair comparison set score evaluation set encounter significant challenge mmg task average pair comparison set score evaluation set expose cross modality bias hallucination issue address present omniarena automated platform evaluate omni model multimodal reward model work highlight need fair evaluation protocol strong alignment human preference source code dataset publicly available http url,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17485,saudiculture benchmark evaluate large language model cultural competence saudi arabia,"Lama Ayash, Hassan Alhuzali, Ashwag Alasmari, Sultan Aloufi",large language model llm demonstrate remarkable capability natural language processing however often struggle accurately capture reflect cultural nuance research address challenge focus saudi arabia country characterize diverse dialect rich cultural tradition introduce saudiculture novel benchmark design evaluate cultural competence llm distinct geographical cultural context saudi arabia saudiculture comprehensive dataset question cover five major geographical region west east south north center general question applicable region dataset encompass broad spectrum cultural domain include food clothing entertainment celebration craft ensure rigorous evaluation saudiculture include question vary complexity open ended single choice multiple choice format require multiple correct answer additionally dataset distinguishes common cultural knowledge specialized regional aspect conduct extensive evaluation five llm llama fanar jais acegpt analyze performance different question type cultural context finding reveal model experience significant performance decline face highly specialize region specific question particularly require multiple correct response additionally certain cultural category easily identifiable others highlight inconsistency llms cultural understanding result emphasize importance incorporate region specific knowledge llms training enhance cultural competence,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17460,convogen enhance conversational ai synthetic data multi agent approach,"Reem Gody, Mahmoud Goudy, Ahmed Y. Tawfik",paper present convogen innovative framework generate synthetic conversational data use multi agent system method leverage few shot learning introduces iterative sample dynamically updated few shot hub create diverse realistic conversational scenario generate data numerous application include training evaluate conversational ai model augment exist datasets task conversational intent classification conversation summarization experiment demonstrate effectiveness method produce high quality diverse synthetic conversational data highlight potential enhance development evaluation conversational ai system,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17456,language specific neuron facilitate cross lingual transfer,"Soumen Kumar Mondal, Sayambhu Sen, Abhishek Singhania, Preethi Jyothi",multilingual large language model llm aim towards robust natural language understanding diverse language performance significantly degrade low resource language work explore exist technique identify language specific neuron leverage enhance cross lingual task performance lowresource language conduct detailed experiment cover exist language specific neuron identification technique language activation probability entropy activation probability based thresholding neuron specific lora fine tune model llama mistral nemo find neuron specific intervention insufficient yield cross lingual improvement downstream task xnli xquad lowresource language study highlight challenge achieve cross lingual generalization provide critical insight multilingual llm,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17425,negation detection comprehensive assertion detection model clinical nlp,"Veysel Kocaman, Yigit Gul, M. Aytug Kaya, Hasham Ul Haq, Mehmet Butgul, Cabir Celik, David Talby",assertion status detection critical yet often overlooked component clinical nlp essential accurately attribute extract medical fact past study narrowly focus negation detection lead underperforming commercial solution aws medical comprehend azure ai text analytics due limited domain adaptation address gap develop state of the art assertion detection model include fine tuned llm transformer based classifier few shot classifier deep learning dl approach evaluate model cloud based commercial api solution legacy rule based negex approach fine tuned llm achieve high overall accuracy outperform commercial apis notable margin particularly excel present absent hypothetical assertion dl based model surpass commercial solution conditional associated with someone else category few shot classifier offer lightweight yet highly competitive alternative make ideal resource constrained environment integrate spark nlp model consistently outperform black box commercial solution enable scalable inference seamless integration medical ner relation extraction terminology resolution result reinforce importance domain adapted transparent customizable clinical nlp solution general purpose llm proprietary apis,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17407,comprehensive survey long context language modeling,"Jiaheng Liu, Dawei Zhu, Zhiqi Bai, Yancheng He, Huanxuan Liao, Haoran Que, Zekun Wang, Chenchen Zhang, Ge Zhang, Jiebin Zhang, Yuanxing Zhang, Zhuo Chen, Hangyu Guo, Shilong Li, Ziqiang Liu, Yong Shan, Yifan Song, Jiayi Tian, Wenhao Wu, Zhejian Zhou, Ruijie Zhu, Junlan Feng, Yang Gao, Shizhu He, Zhoujun Li, Tianyu Liu, Fanyu Meng, Wenbo Su, Yingshui Tan, Zili Wang, Jian Yang, Wei Ye, Bo Zheng, Wangchunshu Zhou, Wenhao Huang, Sujian Li, Zhaoxiang Zhang",efficient processing long context persistent pursuit natural language processing grow number long document dialogue textual data important develop long context language model lclms process analyze extensive input effective efficient way paper present comprehensive survey recent advance long context modeling large language model survey structure three key aspect obtain effective efficient lclms train deploy lclms efficiently evaluate analyze lclms comprehensively first aspect discuss data strategy architectural design workflow approach orient long context processing second aspect provide detailed examination infrastructure require lclm training inference third aspect present evaluation paradigm long context comprehension long form generation well behavioral analysis mechanism interpretability lclms three key aspect thoroughly explore diverse application scenario exist lclms deploy outline promising future development direction survey provide up to date review literature long context llm wish serve valuable resource researcher engineer associated github repository collect late paper repos available http url rgb lclm horizon,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.17403,chatgpt silent everywhere helper survey large language model,"Azim Akhtarshenas, Afshin Dini, Navid Ayoobi",large language model llm revo lutionized natural language process natural language processing nlp generative pre trained transformer chatgpt stand notable exampledue advanced capability widespread application survey provide comprehensive analysis chatgpt explore architecture training process functionality examine integration various domain industry customer service education healthcare entertainment comparative analysis llm highlight chatgpt unique feature performance metric regard benchmark paper examine chatgpt comparative performance llm discuss potential risk misinformation bias data privacy concern additionally offer number figure table outline backdrop discussion main idea article numerous llm model thorough list datasets use pre training fine tuning evaluation well particular llm application pertinent reference finally identify future research direction technological advancement underscore evolve landscape llm profound impact artificial intelligence artificial intelligence ai society,CL,19 Mar 2025
https://doi.org/10.48550/arXiv.2503.18941,explore training inference scale law generative retrieval,"Hongru Cai, Yongqi Li, Ruifeng Yuan, Wenjie Wang, Zhen Zhang, Wenjie Li, Tat-Seng Chua",generative retrieval emerge novel paradigm leverage large language model llm autoregressively generate document identifier promising mechanism underpin performance scalability remain largely unclear conduct systematic investigation training inference scale law generative retrieval explore model size train data scale inference time compute jointly influence retrieval performance address lack suitable metric propose novel evaluation measure inspire contrastive entropy generation loss provide continuous performance signal enable robust comparison diverse generative retrieval method experiment show n gram based method demonstrate strong alignment training inference scaling law especially pair large llm furthermore increase inference computation yield substantial performance gain reveal generative retrieval significantly benefit high compute budget inference setting llama model consistently outperform model suggest particular advantage large decoder only model generative retrieval take together finding underscore model size data availability inference computation interact unlock full potential generative retrieval offer new insight design optimizing future system,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18892,simplerl zoo investigating tame zero reinforcement learn open base model wild,"Weihao Zeng, Yuzhen Huang, Qian Liu, Wei Liu, Keqing He, Zejun Ma, Junxian He",show long chain of thought cot reasoning naturally emerge simple reinforcement learning rl framework rule based reward training may directly start base models a paradigm refer zero rl training recent effort reproduce zero rl training primarily focus model series may representative find base model already exhibit strong instruction following self reflection ability work investigate zero rl train diverse base model span different family size include model leverage several key design strategies such adjust format reward control query difficulty we achieve substantial improvement reason accuracy response length setting however carefully monitor training dynamic observe different base model exhibit distinct pattern training instance increase response length always correlate emergence certain cognitive behavior verification aha moment notably observe aha moment first time small model qwen family share key design enable successful zero rl training finding practice facilitate research open source code model analysis tool,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18888,build next generation geocoding system systematic review,"Zhengcong Yin, Daniel W. Goldberg, Binbin Lin, Bing Zhou, Diya Li, Andong Ma, Ziqian Ming, Heng Cai, Zhe Zhang, Shaohua Wang, Shanzhen Gao, Joey Ying Lee, Xiao Li, Da Huo",geocoding system widely use scientific research spatial analysis everyday life location based service quality geocoded data significantly impact subsequent process application underscore need next generation system response demand review first examine evolving requirement geocoding input output various scenario system must address provide detailed analysis construct system break key functional component review broad spectrum exist approach traditional rule based method advance technique information retrieval natural language processing large language model finally identify opportunity improve next generation geocoding system light recent technological advance,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18866,reason learn latent thought,"Yangjun Ruan, Neil Band, Chris J. Maddison, Tatsunori Hashimoto",compute scale language model lm pretraining outpace growth human written text lead concern data become bottleneck lm scale continue scale pretraining data constrained regime propose explicitly model infer latent thought underlie text generation process significantly improve pretraining data efficiency intuitively approach view web text compressed final outcome verbose human thought process latent thought contain important contextual knowledge reason step critical data efficient learning empirically demonstrate effectiveness approach data constrained continued pretraining math first show synthetic data approach infer latent thought significantly improve data efficiency outperform training amount raw data math furthermore demonstrate latent think inference strong teacher lm bootstrap performance use em algorithm iteratively improve capability trained lm quality thought augmented pretraining data show lm bootstrap performance least three iteration significantly outperform baseline train raw data increase gain additional inference compute perform e step gain inference scaling em iteration suggest new opportunity scale data constrained pretraining,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18825,econevals benchmark litmus test llm agent unknown environment,"Sara Fish, Julia Shephard, Minkai Li, Ran I. Shorrer, Yannai A. Gonczarowski",develop benchmark llm agent act learn strategize unknown environment specification llm agent must learn time deliberate exploration benchmark consist decision making task derive key problem economics forestall saturation benchmark task synthetically generate scalable difficulty level additionally propose litmus test new kind quantitative measure llm llm agent benchmark litmus test quantify difference character value tendency llm llm agent consider behavior face tradeoff efficiency versus equality objectively right wrong behavior overall benchmark litmus test assess ability tendency llm agent tackle complex economic problem diverse setting span procurement scheduling task allocation pricing application grow importance agent integrate economy,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18792,realm dataset real world llm use case,"Jingwen Cheng, Kshitish Ghate, Wenyue Hua, William Yang Wang, Hong Shen, Fei Fang",large language model gpt series drive significant industrial application lead economic societal transformation however comprehensive understanding real world application remain limited address introduce realm dataset llm use case collect reddit news article realm capture two key dimension diverse application llm demographic user categorize llm application explore user occupation relate type application use integrate real world data realm offer insight llm adoption different domain provide foundation future research evolving societal role dedicated dashboard http url present data,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18773,bitdecoding unlocking tensor core long context llm decode low bit kv cache,"Dayou Du, Shijie Cao, Jianyi Cheng, Ting Cao, Mao Yang",grow adoption long context large language model llm introduce significant memory computational challenge autoregressive decoding due expand key value kv cache kv cache quantization emerge promising solution prior work show even quantization maintain model accuracy reduce memory cost however benefit preliminary implementation low bit kv cache struggle deliver expect speedup due quantization dequantization overhead lack tensor core utilization work propose bitdecoding gpu optimized framework unlock tensor core efficient decode low bit kv cache efficiently leverage tensor core low bit kv cache challenge due dynamic nature kv cache generation decode step bitdecoding address challenge tensor cores centric bitfusion scheme ensure data layout compatibility enable high utilization tensor core additionally bitdecoding incorporate warp efficient parallel decode kernel fine grained asynchronous pipeline minimize dequantization overhead improve computational efficiency experiment show bitdecoding achieve speedup rtx compare also outperform state of the art low bit kv cache implementation qserve sequence length bitdecoding reduces single batch decode latency demonstrate effectiveness long context generation scenario code available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18680,archseek retrieve architectural case study use vision language model,"Danrui Li, Yichao Shi, Yaluo Wang, Ziying Shi, Mubbasir Kapadia",efficiently search relevant case study critical architectural design designer rely precedent example guide inspire ongoing project however traditional text based search tool struggle capture inherently visual complex nature architectural knowledge often lead time consuming imprecise exploration paper introduce archseek innovative case study search system recommendation capability tailor architecture design professional power visual understanding capability vision language model cross modal embeddings enable text image query fine grained control interaction based design case recommendation offer architects efficient personalized way discover design inspiration potential application visually drive design field source code available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18666,agentspec customizable runtime enforcement safe reliable llm agent,"Haoyu Wang, Christopher M. Poskitt, Jun Sun",agent build llm increasingly deploy diverse domain automate complex decision making task execution however autonomy introduces safety risk include security vulnerability legal violation unintended harmful action exist mitigation method model based safeguard early enforcement strategy fall short robustness interpretability adaptability address challenge propose agentspec lightweight domain specific language specify enforce runtime constraint llm agent agentspec user define structure rule incorporate trigger predicate enforcement mechanism ensure agent operate predefined safety boundary implement agentspec multiple domain include code execution embodied agent autonomous driving demonstrate adaptability effectiveness evaluation show agentspec successfully prevent unsafe execution code agent case eliminate hazardous action embodied agent task enforce compliance autonomous vehicle av strong safety guarantee agentspec remain computationally lightweight overhead millisecond combine interpretability modularity efficiency agentspec provide practical scalable solution enforce llm agent safety diverse application also automate generation rule use llm assess effectiveness evaluation show rule generate openai achieve precision recall embodied agent successfully identify risky code prevent av break law scenario,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18570,dense retrieval low resource language case amharic language,"Tilahun Yeshambel, Moncef Garouani, Serge Molina, Josiane Mothe",paper report difficulty result use dense retriever amharic one low resource language speak million population effort put difficulty face university addis ababa amharic information retrieval develop presentation,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18565,distil xlstm learning attention mechanism recurrent structure,"Abdoul Majid O. Thiombiano, Brahim Hnich, Ali Ben Mrad, Mohamed Wiem Mkaouer",current era natural language processing nlp dominate transformer model however novel architecture rely recurrent mechanism xlstm mamba propose alternative attention based model computation do differently attention mechanism mechanism recurrent model yield good result sometimes even outperform state of the art attention based model work propose distil xlstm xlstm based small language model slm train distil knowledge large language model llm show promise result compute scale efficient distil xlstm focus approximate transformer based model attention parametrization use recurrent sequence mix component show good result minimal training,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18556,instruction aligned visual attention mitigate hallucination large vision language model,"Bin Li, Dehong Gao, Yeyuan Wang, Linbo Jin, Shanqing Yu, Xiaoyan Cai, Libin Yang",significant success large vision language model lvlms model still suffer hallucination describe image generate answer include non existent object report model tend over focus certain irrelevant image token contain critical information answer question distort output address propose instruction aligned visual attention iava approach identify irrelevant token compare change attention weight two different instruction apply contrastive decoding dynamically adjust logits generate original image token irrelevant image token reduce model over attention irrelevant information experimental result demonstrate iava consistently outperform exist decode technique benchmark mme pope textvqa mitigate object hallucination iava approach available online http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18494,verbal process supervision elicit well cod agent,"Hao-Yuan Chen, Cheng-Pong Huang, Jui-Ming Yao",emergence large language model application ai agent significantly advance state of the art code generation benchmark transform modern software engineering task however even test time computed reasoning model system still struggle complex software engineering challenge work introduce cura code understanding reason agent system enhance verbal process supervision vps achieve improvement baseline model challenge benchmark bigcodebench furthermore cura pair model vps technique attain state of the art performance work represent step forward integrate reasoning driven architecture llm based code generation enable agentic reasoning language model solve complex software engineering task,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18492,safeguard mobile gui agent logic based action verification,"Jungjae Lee, Dongjae Lee, Chihun Choi, Youngmin Im, Jaeyoung Wi, Kihong Heo, Sangeun Oh, Sunjae Lee, Insik Shin",large foundation model lfms unlock new possibility human computer interaction particularly rise mobile graphical user interface gui agents capable interpret gui agent promise revolutionize mobile compute allow user automate complex mobile task simple natural language instruction however inherent probabilistic nature lfms couple ambiguity context dependence mobile task make lfm based automation unreliable prone error address critical challenge introduce verisafe agent vsa formal verification system serve logically ground safeguard mobile gui agent vsa design deterministically ensure agent action strictly align user intent conduct action core vsa introduces novel autoformalization technique translate natural language user instruction formally verifiable specification express domain specific language dsl enable runtime rule based verification allow vsa detect prevent erroneous action execute action either provide corrective feedback halt unsafe behavior best knowledge vsa first attempt bring rigor formal verification gui agent effectively bridge gap lfm driven automation formal software verification implement vsa use off the shelf llm service evaluate performance user instruction widely use mobile apps result demonstrate vsa achieve accuracy verify agent action represent significant improvement exist llm based verification method consequently increase gui agent task completion rate,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18484,parallel multilingual multi modal multi task benchmark large vision language model,"Junyuan Gao, Jiahe Song, Jiang Wu, Runchuan Zhu, Guanlin Shen, Shasha Wang, Xingjian Wei, Haote Yang, Songyang Zhang, Weijia Li, Bin Wang, Dahua Lin, Lijun Wu, Conghui He",exist multilingual benchmark large vision language model lvlms suffer limitation include language specific content bias disjoint multimodal input format lack safety evaluation address gap propose first parallel multilingual multi modal multi task benchmark lvlms feature parallel corpus design language enable fair accurate cross lingual comparison include vision set text query embed image require lvlms simultaneously see read think align real world application additionally bench incorporates safety evaluation address critical oversight exist multilingual benchmark use evaluate mainstream lvlms reveal significant cross linguistic performance disparity particularly vision setting identify ocr capability key determinant imbalance release http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18476,global local tree search language guide scene generation,"Wei Deng, Mengshi Qi, Huadong Ma",large vision language model vlms achieve remarkable success various field however study indoor scene generation vlms paper consider task planning problem subject spatial layout common sense constraint solve problem vlm propose new global local tree search algorithm globally method place object sequentially explore multiple placement placement process problem space represent tree reduce depth tree decompose scene structure hierarchically room level region level floor object level support object level algorithm independently generate floor object different region support object place different floor object locally also decompose sub task placement object multiple step algorithm search tree problem space leverage vlm model produce position object discretize top down view space dense grid fill cell diverse emojis make cell distinct prompt vlm emoji grid vlm produce reasonable location object describe position name emojis quantitative qualitative experimental result illustrate approach generate plausible scene state of the art approach source code available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18458,stablegs floater free framework gaussian splatting,"Luchao Wang, Qian Ren, Kaiming He, Hua Wang, Zhi Chen, Yaohua Tang",recent year witness remarkable success gaussian splatting novel view synthesis surpass prior differentiable render method quality efficiency however training process suffers couple opacity color optimization frequently converge local minimum produce floater artifact degrade visual fidelity present stablegs framework eliminate floater cross view depth consistency constraint introduce dual opacity g model decouple geometry material property translucent object enhance reconstruction quality weakly textured region integrate depth estimation significantly improve geometric stability method fundamentally address training instability outperform exist state of the art method open source datasets,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18435,perception bottleneck vlms chart understanding,"Junteng Liu, Weihao Zeng, Xiwen Zhang, Yijun Wang, Zifei Shan, Junxian He",chart understand require model effectively analyze reason numerical data textual element complex visual component observation reveal perception capability exist large vision language model lvlms constitute critical bottleneck process study delve perception bottleneck decompose two component vision encoder bottleneck visual representation may fail encapsulate correct information extraction bottleneck language model struggle extract necessary information provide visual representation comprehensive experiment find information embed visual representation substantially rich typically capture linear extractor widely use retrieval accuracy metric instruction tune effectively enhance extraction capability lvlms vision encoder remain critical bottleneck demand focused attention improvement therefore enhance visual encoder mitigate vision encoder bottleneck contrastive learning framework empirical result demonstrate approach significantly mitigate perception bottleneck improve ability lvlms comprehend chart code publicly available http url,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18394,solve situation puzzle large language model external reformulation,"Kun Li, Xinwei Chen, Tianyou Song, Chengrui Zhou, Zhuoran Liu, Zhenyan Zhang, Jiangjian Guo, Qing Shan",recent year large language model llm show impressive ability perform arithmetic symbolic reasoning task however find llm chatgpt perform well reason require multiple round dialogue especially solve situation puzzle specifically llm intend ask detailed question focus specific aspect question several round q help llms get dilemma propose novel external reformulation methodology situation puzzle reformulate several round q llm raise incorrect guess experiment show superior performance win rate number attempt method directly use llm solve situation puzzle highlight potential strategic problem reformulation enhance reason capability llm complex interactive scenario,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18320,bridge write manner gap visual instruction tuning create llm aligned instruction,"Dong Jing, Nanyi Fei, Zhiwu Lu",realm large multi modal model lmms instruction quality visual instruction tune stage significantly influence performance modality alignment paper assess instruction quality unique perspective term write manner encompass selection vocabulary grammar sentence structure convey specific semantics argue exist substantial writing manner gap visual instruction base large language model llm lmms gap force pre trained base llm deviate original writing style lead capability degradation base llm lmms bridge writing manner gap preserve original semantics propose directly leverage base llm align write manner soft format visual instruction base llm result novel llm aligned instruction manual writing manner evaluation result demonstrate approach successfully minimize writing manner gap utilize llm aligned instruction baseline model qwenvl demonstrate enhance resistance hallucination non trivial comprehensive improvement visual language benchmark,CL,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18225,decouple angle strength low rank adaptation,"Massimo Bini, Leander Girrbach, Zeynep Akata",parameter efficient finetuning peft method recently gain significant popularity thanks widespread availability large scale pretrained model method allow quick adaptation downstream task minimal computational cost however popular finetuning method lora exhibit limited robustness come hyperparameter choice extended training regime prevent optimal out of the box performance contrast bound approach ether provide great robustness limit extremely low rank adaptation fixed strength transformation reduce adaptation expressive power work propose decoupled low rank adaptation delora novel finetuning method normalize scale learnable low rank matrix bound distance transformation delora effectively decouple angular learning adaptation strength enhance robustness compromise performance evaluation subject driven image generation natural language understanding instruction tuning show delora match surpasses performance compete peft method exhibit strong robustness code available http url,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18102,agentrxiv towards collaborative autonomous research,"Samuel Schmidgall, Michael Moor",progress scientific discovery rarely result single eureka moment rather product hundred scientist incrementally work together common goal exist agent workflow capable produce research autonomously isolation ability continuously improve prior research result address challenge introduce agentrxiv a framework let llm agent laboratory upload retrieve report share preprint server order collaborate share insight iteratively build research task agent laboratory develop new reasoning prompt technique find agent access prior research achieve high performance improvement compare agent operate isolation relative improvement baseline find best performing strategy generalize benchmarks domain improve average multiple agent laboratory share research agentrxiv able work together common goal progress rapidly isolated laboratory achieve high overall accuracy relative improvement baseline finding suggest autonomous agent may play role design future ai system alongside human hope agentrxiv allow agent collaborate research goal enable researcher accelerate discovery,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18065,unseen see rewrite observation instruction use foundation model augment vision language navigation,"Ziming Wei, Bingqian Lin, Yunshuang Nie, Jiaqi Chen, Shikui Ma, Hang Xu, Xiaodan Liang",data scarcity long standing challenge vision language navigation vln field extremely hinder generalization agent unseen environment previous work primarily rely additional simulator data web collected improve generalization however simulator environment still face limited diversity web collected data often require extensive labor remove noise paper propose rewriting driven augmentation ram paradigm vln directly create unseen observation instruction pair rewrite human annotated training data benefiting rewrite mechanism new observation instruction obtain simulator free labor saving manner promote generalization specifically first introduce object enriched observation rewriting combine vision language model vlms large language model llm derive rewritten object enriched scene description enable observation synthesis diverse object spatial layout text to image generation model propose observation contrast instruction rewriting generate observation aligned rewritten instruction require llm reason difference original new observation develop mixing then focusing training strategy random observation crop scheme effectively enhance data distribution diversity suppress augmentation data noise training experiment discrete environment reverie datasets continuous environment dataset show superior performance impressive generalization ability method code available http url,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18050,g i dle generative inference distribution preserving logit exclusion kl divergence minimization constrain decoding,Hanwool Lee,propose g i dle new approach constrain decode leverage kl divergence minimization preserve intrinsic conditional probability distribution autoregressive language model exclude undesirable token conventional method naively set ban token logits distort conversion raw logits posterior probability increase output variance g i dle re normalizes allow token probability minimize distortion validate method dataset specifically design assess korean language fluency logical reasoning cultural appropriateness experimental result model range demonstrate g idle boost mean evaluation score also substantially reduce variance output quality,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18034,expand boundary vision prior knowledge multi modal large language model,"Qiao Liang, Yanjiang Liu, Ben He, Yaojie Lu, Hongyu Lin, Jia Zheng, Xianpei Han, Le Sun, Yingfei Sun",prior knowledge vision encoder constrain capability boundary multi modal large language model mllms exist research treat mllms unified system optimize end to end training impact vision encoder prior knowledge seldom investigate work introduce novel metric quantify effect vision encoder prior knowledge mllm performance analysis reveal positive correlation prior knowledge mllm performance moreover find domain specific fine tuning use solely end to end visual question answering vqa data insufficient particularly entity low inherent visual prior knowledge address issue propose vispre vision prior remediation two stage training framework explicitly incorporate prior knowledge vision encoder level experimental result demonstrate augment vision encoder prior knowledge substantially boost visual understanding capability mllms offer novel effective strategy improve performance especially scenario involve uncommon visual entity,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17979,trade offs large reason model empirical analysis deliberative adaptive reasoning foundational capability,"Weixiang Zhao, Xingyu Sui, Jiahe Guo, Yulin Hu, Yang Deng, Yanyan Zhao, Bing Qin, Wanxiang Che, Tat-Seng Chua, Ting Liu",recent advancement large reasoning model lrms openai demonstrate remarkable performance specialized reasoning task human like deliberative thinking long chain of thought reasoning however systematic evaluation various model family deepseek qwen llama scale reveals acquire deliberative reasoning capability significantly reduce foundational capability lrms include notable decline helpfulness harmlessness alongside substantially increased inference cost importantly demonstrate adaptive reasoning employ mode zero thinking less thinking summary thinking effectively alleviate drawback empirical insight underline critical need develop versatile lrms capable dynamically allocate inference time compute accord specific task characteristic,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17955,human ai interaction user satisfaction empirical evidence online review ai product,"Stefan Pasch, Sun-Young Ha",human ai interaction hai guideline design principle become increasingly important industry academia guide development ai system align user need expectation however large scale empirical evidence hai principle shape user satisfaction practice remains limited study address gap analyze user review ai related product http url lead review platform business software service base widely adopt industry guideline identify seven core hai dimension examine coverage sentiment review find sentiment four hai dimension adaptability customization error recovery security is positively associate overall user satisfaction moreover show engagement hai dimension varies professional background user technical job role likely discuss system focused aspect reliability non technical user emphasize interaction focused feature customization feedback interestingly relationship hai sentiment overall satisfaction moderate job role suggest hai dimension identify user effect satisfaction consistent job role,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17928,debiasing large language model noise aware preference optimization,"Zefeng Zhang, Hengzhu Tang, Jiawei Sheng, Zhenyu Zhang, Yiming Ren, Zhenyang Li, Dawei Yin, Duohe Ma, Tingwen Liu",multimodal large language model excel various task yet often struggle modality bias model tend rely heavily single modality overlook critical information modality lead incorrect focus generate irrelevant response paper propose use paradigm preference optimization solve modality bias problem include rlaifvbias debiased preference optimization dataset noise aware preference optimization algorithm specifically first construct dataset introduce perturbation reduce informational content certain modality compel model rely specific modality generate negative response address inevitable noise automatically construct data combine noise robust mean absolute error binary cross entropy direct preference optimization negative box cox transformation dynamically adjust algorithm noise robustness base evaluated noise level data extensive experiment validate approach demonstrate effectiveness mitigate modality bias also significant role minimize hallucination,CL,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.17793,sample matter leverage mixture of expert high quality data efficient accurate code llm,"Codefuse, Ling Team: Wenting Cai, Yuchen Cao, Chaoyu Chen, Chen Chen, Siba Chen, Qing Cui, Peng Di, Junpeng Fang, Zi Gong, Ting Guo, Zhengyu He, Yang Huang, Cong Li, Jianguo Li, Zheng Li, Shijie Lian, BingChang Liu, Songshan Luo, Shuo Mao, Min Shen, Jian Wu, Jiaolong Yang, Wenjie Yang, Tong Ye, Hang Yu, Wei Zhang, Zhenduo Zhang, Hailin Zhao, Xunjin Zheng, Jun Zhou",recent advancement code large language model llm demonstrate remarkable capability code generation understanding still challenge build code llm comprehensive performance yet ultimate efficiency many attempt release open source community break trade off performance efficiency qwen coder series deepseek coder series paper introduce yet attempt area namely ling coder lite leverage efficient mixture of expert moe architecture set high quality data curation method especially base program analytics build efficient yet powerful code llm ling coder lite exhibit on par performance representative cod benchmark compare state of the art model similar size offer competitive latency throughput practice achieve reduction deployment resource compare similar sized dense model performance loss facilitate research development area open source model well substantial portion high quality data annealing post training stage model data access http url,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17783,energy aware llm step sustainable ai downstream application,"Nguyen Phuc Tran, Brigitte Jaumard, Oscar Delgado",advanced large language model llm revolutionize various field include communication network spark innovation wave lead new application service significantly enhanced solution scheme impressive development llms typically require huge computational resource result terribly high energy consumption thus research study propose end to end pipeline investigate trade off energy efficiency model performance llm fault ticket analysis communication network evaluate pipeline performance use two real world datasets task root cause analysis response feedback communication network result show appropriate combination quantization prune technique able reduce energy consumption significantly improve model performance,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17736,evaluate video language understanding visual prompt good human model interaction,"Yiming Zhao, Yu Zeng, Yukun Qi, YaoYang Liu, Lin Chen, Zehui Chen, Xikun Bao, Jie Zhao, Feng Zhao",large vision language model lvlms make significant progress field video understand recently however current benchmark uniformly lean text prompt evaluation often necessitate complex referential language fail provide precise spatial temporal reference limitation diminish experience efficiency human model interaction address limitation propose video visual prompt benchmark comprehensive benchmark specifically design evaluate lvlms video understand capability multimodal human model interaction scenario include unique video qa pair cover main task dimension facilitate instance level fine grained understanding align human cognition benchmarking result reveal even powerful model perform poorly significantly low human expert highlight current shortcoming lvlms understand video visual prompt hope serve foundation advance multimodal human model interaction video understanding evaluation project page http url,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17632,fairflow mitigating dataset bias undecided learning,"Jiali Cheng, Hadi Amiri",language model prone dataset bias know shortcut spurious correlation data often result performance drop new data present new debiasing framework call fairflow mitigate dataset bias learn undecided prediction data sample representation associate know unknown bias framework introduces two key component suite data model perturbation operation generate different biased view input sample contrastive objective learn debiased robust representation result biased view sample experiment show fairflow outperforms exist debiasing method particularly out of domain hard test sample compromise in domain performance,CL,22 Mar 2025
https://doi.org/10.48550/arXiv.2503.17553,autonomous radiotherapy treatment plan use dola privacy preserving llm based optimization agent,"Humza Nusrat (1 and 2), Bing Luo (1), Ryan Hall (1), Joshua Kim (1), Hassan Bagher-Ebadian (1 and 2), Anthony Doemer (1), Benjamin Movsas (1 and 2), Kundan Thind (1 and 2) ((1) Department of Radiation Oncology, Henry Ford Health, Detroit, USA (2) College of Human Medicine, Michigan State University, East Lansing, USA)",radiotherapy treatment planning complex time intensive process often impact inter planner variability subjective decision making address challenge introduce dose optimization language agent dola autonomous large language model llm  base agent design optimize radiotherapy treatment plan rigorously protect patient privacy dola integrate llm directly commercial treatment plan system utilize chain of thought prompting retrieval augmented generation rag reinforcement learning rl operate entirely secure local infrastructure agent eliminate external data share evaluate dola use retrospective cohort prostate cancer patient prescribe gy fraction compare model size billion billion parameter optimization strategy no rag rag planning iteration model demonstrate significantly improve performance achieve approximately high final score model rag approach outperform no rag baseline incorporate rl accelerate convergence highlight synergy retrieval based memory reinforcement learning optimal temperature hyperparameter analysis identify provide best balance exploration exploitation proof concept study represent first successful deployment locally host llm agent autonomous optimization treatment plan commercial radiotherapy planning system extend human machine interaction interpretable natural language reasoning dola offer scalable privacy conscious framework significant potential clinical implementation workflow improvement,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17502,large language model llm source code analysis application model datasets,"Hamed Jelodar, Mohammad Meymani, Roozbeh Razavi-Far",large language model llm transformer based architecture increasingly utilized source code analysis software system grow complexity integrate llm code analysis workflows become essential enhance efficiency accuracy automation paper explore role llm different code analysis task focus three key aspect analyze application model use datasets use challenge face regard goal research investigate scholarly article explore use llm source code analysis uncover research development current trend intellectual structure emerge field additionally summarize limitation highlight essential tool datasets key challenge could valuable future work,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17500,variance control weight rescale llm pre training,"Louis Owen, Abhay Kumar, Nilabhra Roy Chowdhury, Fabian Güra",outcome large language model llm pre training strongly depend weight initialization variance control strategy importance initial variance control well document neural network general literature initialization management growth llm pre training specifically somewhat sparse paper introduce layer index rescaling lir weight initialization scheme target variance rescaling tvr variance control strategy experiment parameter llama model demonstrate good variance management use technique yield substantial improvement downstream task performance common pre training benchmark reduce extreme activation value thus mitigate challenge associate quantization low precision training code available http url,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17438,text talent pipeline extract insight candidate profile,"Paolo Frazzetto, Muhammad Uzair Ul Haq, Flavia Fabris, Alessandro Sperduti",recruitment process undergo significant transformation increase use machine learning natural language processing technique previous study focus automate candidate selection role multiple vacancy process remain understudied paper address gap propose novel pipeline leverage large language model graph similarity measure suggest ideal candidate specific job opening approach represent candidate profile multimodal embeddings enable capture nuanced relationship job requirement candidate attribute propose approach significant implication recruitment industry enable company streamline hiring process identify top talent efficiently work contribute grow body research application machine learning human resource highlight potential llm graph based method revolutionize recruitment landscape,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17421,understand social support need question hybrid approach integrate semi supervised learning llm based data augmentation,"Junwei Kuang, Liang Yang, Shaoze Cui, Weiguo Fan",patient increasingly turn online health q community social support improve well being however support receive align specific need may prove ineffective even detrimental necessitate model capable identify social support need question however train model challenge due scarcity class imbalance issue label data overcome challenge follow computational design science paradigm develop novel framework hybrid approach social support need classification ha so ha sos integrates answer enhanced semi supervised learning approach text data augmentation technique leverage large language model llm reliability  diversity aware sample selection mechanism unified training process automatically label social support need question extensive empirical evaluation demonstrate ha so significantly outperform exist question classification model alternative semi supervised learning approach research contribute literature social support question classification semi supervised learning text data augmentation practice ha sos framework facilitates online q platform manager answerer good understand user social support need enable provide timely personalized answer intervention,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17382,state fourier diffusion language model sfdlm scalable novel iterative approach language modeling,"Andrew Kiruluta, Andreas Lemos",recent year diffusion base method emerge powerful paradigm generative modeling discrete diffusion natural language processing explore less extent show promise task require iterative denoising token base data standard approach text generation transformer dominate reliance self attention often incur high computational cost paper introduce fully diffusion driven discrete text generation model build transformer large convolution module instead model integrate structured state space dynamic time domain novel complex fourier multi layer perceptron module operate frequency domain forward noise process randomly sample vocabulary replace token controlled probability learned reverse model systematically revert corrupted sequence original state compose local state space update global fourier base mixing approach effectively capture short long range dependency,CL,16 Mar 2025
https://doi.org/10.48550/arXiv.2503.16586,big help big brother audit tracking profile personalization generative ai assistant,"Yash Vekaria (1), Aurelio Loris Canino (2), Jonathan Levitsky (1), Alex Ciechonski (3), Patricia Callejo (4), Anna Maria Mandalari (3), Zubair Shafiq (1) ((1) UC Davis, (2) Mediterranea University of Reggio Calabria, (3) University College London, (4) Universidad Carlos III de Madrid)",generative ai genai browser assistant integrate powerful capability genai web browser provide rich experience question answering content summarization agentic navigation assistant available today browser extension track detailed browse activity search click data also autonomously perform task fill form raise significant privacy concern crucial understand design operation genai browser extension include collect store process share user data end study ability profile user personalize response base explicit inferred demographic attribute interest user perform network traffic analysis use novel prompting framework audit tracking profile personalization ten popular genai browser assistant extension find instead rely local in browser model assistant largely depend server side apis auto invoked explicit user interaction invoke collect share webpage content often full html dom sometimes even user form input first party server assistant also share identifier user prompt third party tracker google analytics collection sharing continue even webpage contain sensitive information health personal information name ssn enter web form find several genai browser assistant infer demographic attribute age gender income interest use profile carry browse context personalize response summary work show genai browser assistant collect personal sensitive information profiling personalization little safeguard,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.17363,dance critique enhance llm reason stepwise natural language self critique,"Yansi Li, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Qiuzhi Liu, Rui Wang, Zhuosheng Zhang, Zhaopeng Tu, Haitao Mi, Dong Yu",enhance reason capability large language model llm particularly complex task require multi step logical deduction remain significant challenge traditional inference time scale method utilize scalar reward signal process reward model evaluate candidate reason step scalar reward lack nuanced qualitative information essential understand justify step paper propose novel inference time scaling approach stepwise natural language self critique panel employ self generated natural language critique feedback guide step level search process generate rich human readable critique candidate reason step panel retain essential qualitative information facilitate good informed decision making inference approach bypass need task specific verifier associated training overhead make broadly applicable diverse task experimental result challenge reason benchmark include aime gpqa demonstrate panel significantly enhance reason performance outperform traditional scalar reward based method code available http url support encourage future research promising field,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17336,efficient intent based filtering multi party conversation use knowledge distillation llm,"Reem Gody, Mohamed Abdelghaffar, Mohammed Jabreel, Ahmed Tawfik",large language model llm showcased remarkable capability conversational ai enable open domain response chat bot well advanced processing conversation summarization intent classification insight generation however model resource intensive demand substantial memory computational power address propose cost effective solution filter conversational snippet interest llm processing tailor target downstream application rather process snippet work introduce innovative approach leverage knowledge distillation llm develop intent based filter multi party conversation optimize compute power constrain environment method combine different strategy create diverse multi party conversational dataset annotate target intent use fine tune mobilebert model multi label intent classification model achieve balance efficiency performance effectively filter conversation snippet base intent pass relevant snippet llm processing approach significantly reduce overall operational cost depend intent data distribution demonstrate experiment,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17287,fastcurl curriculum reinforcement learn progressive context extension efficient train reasoning model,"Mingyang Song, Mao Zheng, Zheng Li, Wenjie Yang, Xuan Luo, Yue Pan, Feng Zhang",paper propose fastcurl simple yet efficient cu rriculum r einforcement l earn approach context window extend strategy accelerate reinforcement learn training efficiency reasoning model enhance performance tackle complex reason task long chain of thought rationale particularly parameter language model fastcurl consists two main procedure length aware training data segmentation context window extension training specifically former first split original training data three different level input prompt length latter leverage segment train datasets progressively increase context window length train reasoning model experimental result demonstrate fastcurl surpasses five datasets include math aime amc minerva math olympiadbench utilize training step furthermore training stage complete use single node gpus,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17279,case condition aware sentence embeddings conditional semantic textual similarity measurement,"Gaifan Zhang, Yi Zhou, Danushka Bollegala",meaning convey sentence often depend context appear progress sentence embed method remain unclear best modify sentence embed condition context address problem propose condition aware sentence embeddings case efficient accurate method create embedding sentence give condition first case create embedding condition use large language model llm sentence influence attention score compute token condition pool next supervised nonlinear projection learn reduce dimensionality llm based text embeddings show case significantly outperform previously propose conditional semantic textual similarity c sts method exist standard benchmark dataset find subtract condition embed consistently improve c sts performance llm based text embeddings moreover propose supervised dimensionality reduction method reduce dimensionality llm based embeddings also significantly improve performance,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17247,tokenizers family domain specific character level tokenizers legal financial preprocessing application,"Michael J Bommarito, Daniel Martin Katz, Jillian Bommarito",present tokenizers family specialized tokenizers legal financial governmental text establish work tokenization specialized tokenizers professional domain remain understudied paper offer two main contribution introduce domain specific bpe tokenizers legal financial governmental text tokenizer use few token domain specific document small vocabulary specialized terminology cased tokenizer even efficient use few token legal term few token financial develop character level bpe tokenizers vocabulary size text correction task ocr post processing tokenizers keep consistent token boundary error containing correct text make easy model learn correction tokenizers help professional application fit text context window reduce computational need preserve meaning domain specific term analysis show efficiency gain directly benefit processing long legal financial document release tokenizers code github hug face support research specialized tokenization,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17239,safemerge preserving safety alignment fine tuned large language model selective layer wise model merging,"Aladin Djuhera, Swanand Ravindra Kadhe, Farhan Ahmed, Syed Zawad, Holger Boche",fine tuning large language model llm downstream task inadvertently erode safety alignment even benign fine tuning datasets address challenge propose safemerge post fine tuning framework preserve safety maintain task utility achieve selectively merge fine tuned safety aligned model layer deviate safe behavior measure cosine similarity criterion evaluate safemerge fine tuning  post fine tuning stage approach model pubmedqa task explore different merging strategy find safemerge consistently reduce harmful output compare baseline significantly sacrifice performance sometimes even enhance result suggest selective subspace guided per layer merging method provide effective safeguard inadvertent loss safety fine tuned llm outperform simple post fine tuning stage defense,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17222,automate adjudication cardiovascular event use large language model,"Sonish Sivarajkumar, Kimia Ameri, Chuqin Li, Yanshan Wang, Min Jiang",cardiovascular event heart attack stroke remain leading cause mortality globally necessitate meticulous monitoring adjudication clinical trial process traditionally perform manually clinical expert time consuming resource intensive prone inter reviewer variability potentially introduce bias hinder trial progress study address critical limitation present novel framework automate adjudication cardiovascular event clinical trial use large language model llm develop two stage approach first employ llm based pipeline event information extraction unstructured clinical data second use llm based adjudication process guide tree thought approach clinical endpoint committee cec guideline use cardiovascular event specific clinical trial data framework achieve event extraction accuracy adjudication furthermore introduce cleart score novel automate metric specifically design evaluate quality ai generated clinical reasoning adjudicate cardiovascular event approach demonstrate significant potential substantially reduce adjudication time cost maintain high quality consistent auditable outcome clinical trial reduced variability enhanced standardization also allow fast identification mitigation risk associate cardiovascular therapy,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17211,language anchor guided method robust noisy domain generalization,"Zilin Dai, Lehong Wang, Fangzhou Lin, Yidong Wang, Zhigang Li, Kazunori D Yamada, Ziming Zhang, Wang Lu",real world machine learning application often struggle two major challenge distribution shift label noise model tend overfit focus redundant uninformative feature training data make hard generalize target domain data worsens problem cause overfitting noise mean exist method often fail tell difference true invariant feature misleading spurious one tackle issue introduce anchor alignment adaptive weighting new algorithm use sample reweighting guide natural language processing nlp anchor extract representative feature simple term leverage semantic representation natural language model source domain invariant prior knowledge additionally employ weighted loss function adjust sample contribution base similarity corresponding nlp anchor adjustment make model robust label extensive experiment standard benchmark datasets show consistently outperform state of the art domain generalization method offer significant improvement accuracy robustness different datasets noise level,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17136,coke customizable fine grained story evaluation chain of keyword rationalization,"Brihi Joshi, Sriram Venkatapathy, Mohit Bansal, Nanyun Peng, Haw-Shiuan Chang",evaluate creative text human written story use language model always challenging task owe subjectivity multi annotator rating mimic thinking process human chain thought cot generate free text explanation help guide model prediction self consistency sc marginalize prediction multiple generated explanation study discover widely used self consistency reason method cause suboptimal result due objective mismatch generate explanation actually lead good rating prediction aspect story overcome challenge propose c hain  f  ke ywords coke generate sequence keywords generate free text rationale guide rating prediction evaluation language model generate diverse set keywords aggregate score correspond generation storyer dataset coke base small fine tuned evaluation model reach human level performance significantly outperform boost correlation human annotator also require drastically less number parameter,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17126,modify large language model post training diverse creative writing,"John Joon Young Chung, Vishakh Padmakumar, Melissa Roemmele, Yuqian Sun, Max Kreminski",creative writing task singular correct answer large language model llm train perform task able generate diverse valid output however llm post training often focus improve generation quality neglect facilitate output diversity hence creative writing generation investigate post training approach promote output diversity quality core idea include deviation degree difference training sample sample prompt training objective facilitate learn rare high quality instance adopt approach direct preference optimization dpo odds ratio preference optimization orpo demonstrate promote output diversity trained model minimally decrease quality best model parameter could achieve on par diversity human created dataset output quality similar best instruction tuned model examine validate approach human evaluation ablation comparison exist diversification approach divpo,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17073,study investigate temporal robustness llm,"Jonas Wallat, Abdelrahman Abdallah, Adam Jatowt, Avishek Anand",large language model llm encapsulate surprising amount factual world knowledge however performance temporal question historical knowledge limit often understand temporal scope orientation neglect temporal aspect altogether study aim measure precisely robust llm question answer base ability process temporal information perform task require temporal reasoning temporal factual knowledge specifically design eight time sensitive robustness test factual information check sensitivity six popular llm zero shot setting overall find llms lacking temporal robustness especially temporal reformulations use different granularity temporal reference show selection eight test use automatically judge model temporal robustness user question fly finally apply finding study improve temporal qa performance percent,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17039,summarization metric spanish basque automatic score llm judge correlate human,"Jeremy Barnes, Naiara Perez, Alba Bonet-Jover, Begoña Altuna",study evaluation metric llm as a judge model automatic text summarization largely focus english limit understanding effectiveness language new dataset basse basque spanish summarization evaluation address situation collect human judgment abstractive summary basque spanish generate manually five llm four different prompt summary annotator evaluate five criterion likert scale coherence consistency fluency relevance use data reevaluate traditional automatic metric use evaluate summary well several llm as a judge model show strong performance task english result show currently proprietary judge llm high correlation human judgment follow criteria specific automatic metric open sourced judge llm perform poorly release basse code publicly first large scale basque summarization dataset contain news article subhead,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.17003,survey personalized alignment missing piece large language model real world application,"Jian Guan, Junfei Wu, Jia-Nan Li, Chuanqi Cheng, Wei Wu",large language model llm demonstrate remarkable capability transition real world application reveal critical limitation inability adapt individual preference maintain alignment universal human value current alignment technique adopt one size fits all approach fail accommodate user diverse background need paper present first comprehensive survey personalized alignment a paradigm enable llms adapt behavior ethical boundary base individual preference propose unified framework comprise preference memory management personalize generation feedback based alignment systematically analyze implementation approach evaluate effectiveness various scenario examine current technique potential risk future challenge survey provide structured foundation develop adaptable ethically aligned llm,CL,"21 Mar 2025 (v1), last revised 24 Mar 2025 (this version, v2)"
https://doi.org/10.48550/arXiv.2503.16965,word outperform vision vlms self improve text only training human centered decision making,"Zhe Hu, Jing Li, Yu Yin",embody decision making fundamental ai agent operate real world environment visual language model vlms advance capability still struggle complex decision particularly human centered situation require deep reasoning human need value study systematically evaluate open sourced vlms multimodal human centered decision making task find llm receive textual description unexpectedly outperform vlm counterpart similar scale process actual image suggest visual alignment may hinder vlm ability address challenge propose novel text only training approach synthesized textual data method strengthen vlms language component transfer learned ability multimodal inference eliminate need expensive image text pair data furthermore show vlms achieve substantial performance gain self improvement use train data generate llm counterparts rather rely large teacher model finding establish efficient scalable approach enhance vlms human centered decision making capability open new avenue optimize vlms self improvement mechanism,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16883,assess reliability validity annotate emotion appraisal rating,"Deniss Ruder, Andero Uusberg, Kairit Sirts",appraisal theory suggest emotion arise subjective evaluation event refer appraisal taxonomy appraisal quite diverse usually give rating likert scale annotate experiencer annotator reader annotator paradigm paper study reader annotator specific appraisal rating different prompt setting aim evaluate improve performance compare human annotator find effective reader annotator perform close even slightly good human annotator result significantly improve use majority voting five completion also effectively predict appraisal rating emotion label use single prompt add instruction complexity result poor performance also find longer event description lead accurate annotation model human annotator rating work contribute grow usage llm psychology strategy improve performance annotate appraisal,CL,"21 Mar 2025 (v1), last revised 24 Mar 2025 (this version, v2)"
https://doi.org/10.48550/arXiv.2503.16868,joint extraction matter prompt based visual question answer multi field document information extraction,"Mengsay Loem, Taiju Hosaka",visual question answering vqa emerge flexible approach extract specific piece information document image however exist work typically query field isolation overlook potential dependency multiple item paper investigate merit extract multiple field jointly versus separately experiment multiple large vision language model datasets show jointly extract field often improve accuracy especially field share strong numeric contextual dependency analyze performance scale number requested item use regression base metric quantify inter field relationship result suggest multi field prompt mitigate confusion arise similar surface form related numeric value provide practical method design robust vqa system document information extraction task,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16858,mtbench multimodal time series benchmark temporal reasoning question answering,"Jialin Chen, Aosong Feng, Ziyu Zhao, Juan Garza, Gaukhar Nurbek, Cheng Qin, Ali Maatouk, Leandros Tassiulas, Yifeng Gao, Rex Ying",understand relationship textual news time series evolution critical yet under explored challenge applied data science multimodal learning gain traction exist multimodal time series datasets fall short evaluate cross modal reasoning complex question answering essential capture complex interaction narrative information temporal pattern bridge gap introduce multimodal time series benchmark mtbench large scale benchmark design evaluate large language model llm time series text understanding financial weather domain mtbench comprises pair time series textual data include financial news correspond stock price movement weather report align historical temperature record exist benchmark focus isolated modality mtbench provide comprehensive testbed model jointly reason structured numerical trend unstructured textual narrative richness mtbench enables formulation diverse task require deep understanding text time series data include time series forecasting semantic technical trend analysis news driven question answering qa task target model ability capture temporal dependency extract key insight textual context integrate cross modal information evaluate state of the art llm mtbench analyze effectiveness model complex relationship news narrative temporal pattern finding reveal significant challenge current model include difficulty capture long term dependency interpret causality financial weather trend effectively fuse multimodal information,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16856,mmcr benchmarking cross source reasoning scientific paper,"Yang Tian, Zheng Lu, Mingqi Gao, Zheng Liu, Bo Zhao",fully comprehend scientific paper machine reflect high level artificial general intelligence require ability reason fragment heterogeneous source information present complex practically significant challenge vision language model vlms make remarkable stride various task particularly involve reason evidence source single image text page ability use cross source information reason remain open problem work present mmcr high difficulty benchmark design evaluate vlms capacity reason cross source information scientific paper benchmark comprise high quality question meticulously annotate human subject task type experiment vlms demonstrate cross source reasoning present substantial challenge exist model notably even top performing model achieve overall accuracy accuracy multi table comprehension task second best model reach overall accuracy furthermore investigate impact chain of thought cot technique cross source reasoning observe detrimental effect small model whereas large model demonstrate substantially enhanced performance result highlight press need develop vlms capable effectively utilize cross source information reasoning,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16853,imagine hear auditory knowledge generation effective assistant language model,"Suho Yoo, Hyunjong Ok, Jaeho Lee",language model pretrained text only corpus often struggle task require auditory commonsense knowledge previous work address problem augment language model retrieve knowledge external audio database approach several limitation potential lack relevant audio database high cost associate constructing query database address issue propose imagine hear novel approach dynamically generate auditory knowledge use generative model framework detect multiple audio related textual span give prompt generates correspond auditory knowledge develop several mechanism efficiently process multiple auditory knowledge include clap based rejection sampler language audio fusion module experiment show method achieve state of the art performance auditorybench rely external database highlight effectiveness generation based approach,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16826,tom eat kimchi evaluate cultural bias multimodal large language model cultural mixture context,"Jun Seong Kim, Kyaw Ye Thu, Javad Ismayilzada, Junyeong Park, Eunsu Kim, Huzama Ahmad, Na Min An, James Thorne, Alice Oh",highly globalized world important multi modal large language model mllms recognize respond correctly mixed cultural input example model correctly identify kimchi korean food image asian woman eat well african man eat however current mllms show over reliance visual feature person lead misclassification entity examine robustness mllms different ethnicity introduce mixcube cross cultural bias benchmark study element five country four ethnicity finding reveal mllms achieve high accuracy low sensitivity perturbation high resource culture low resource culture best performing model overall show difference accuracy original perturbed cultural setting low resource culture dataset publicly available http url,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16789,conversational user ai intervention study prompt rewrite improved llm response generation,"Rupak Sarkar, Bahareh Sarrafzadeh, Nirupama Chandrasekaran, Nagu Rangan, Philip Resnik, Longqi Yang, Sujay Kumar Jauhar",human llm conversation increasingly become pervasive people professional personal life yet many user still struggle elicit helpful response llm chatbots one reason issue user lack understand craft effective prompt accurately convey information need meanwhile existence real world conversational datasets one hand text understanding faculty llm present unique opportunity study problem potential solution scale thus paper present first llm centric study real human ai chatbot conversation focus investigate aspect user query fall short express information need potential use llm rewrite suboptimal user prompt finding demonstrate rephrase ineffective prompt elicit good response conversational system preserve user original intent notably performance rewrite improves long conversation contextual inference user need make accurately additionally observe llms often need inherently make plausible assumption user intention goal interpret prompt finding largely hold true conversational domain user intent llm vary size family indicate promise use prompt rewriting solution good human ai interaction,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16779,chain of tool utilizing massive unseen tool cot reasoning frozen language model,"Mengsong Wu, Tong Zhu, Han Han, Xiang Zhang, Wenbiao Shao, Wenliang Chen",tool learning broaden usage scenario large language model llm however exist method either need finetune model use tool see training data add tool demonstration prompt low efficiency paper present new tool learn method chain of tool make full use powerful semantic representation capability frozen llm finish tool call cot reason huge flexible tool pool may contain unseen tool especially validate effectiveness approach massive unseen tool scenario construct new dataset simpletoolquestions conduct experiment two numerical reason benchmark funcqa two knowledge based question answer benchmark kamel simpletoolquestions experimental result show approach perform good baseline also identify dimension model output critical tool selection enhance model interpretability code data available http url,CL,21 Mar 2025
https://doi.org/10.48550/arXiv.2503.16745,spacer parallel dataset speech production comprehension error repair,"Shiva Upadhye, Jiaxuan Li, Richard Futrell",speech error natural part communication yet rarely lead complete communicative failure speaker comprehenders detect correct error prior research examine monitoring correction production comprehension separately integrated investigation system impede scarcity parallel data study present spacer parallel dataset capture naturalistic speech error correct speaker comprehenders focus single word substitution error extract switchboard corpus accompany speaker self repairs comprehenders response offline text editing experiment exploratory analysis suggest asymmetry error correction strategy speaker likely repair error introduce great semantic phonemic deviation whereas comprehenders tend correct error phonemically similar plausible alternative fit prior context dataset enable future research integrated approach study language production comprehension,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16728,natural language generation,"Emiel van Miltenburg, Chenghua Lin",article provide brief overview field natural language generation term natural language generation nlg broad definition refers study system verbalize form information natural language information could store large database knowledge graph data to text application nlg researcher may also study summarisation text to text image captioning image to text example subfield natural language processing nlg closely relate sub discipline machine translation mt dialog system nlg researcher exclude mt definition field content selection involve system determine say conversely dialog system typically fall header natural language generation nlg one component dialog system others natural language understanding dialog management however rise large language model llm different subfields natural language processing converge similar methodology production natural language evaluation automatically generate text,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16674,llm look glass socratic self assessment donkey elephant market,"Molly Kennedy, Ayyoob Imani, Timo Spinde, Hinrich Schütze",detect avoid bias llm generated text become increasingly important medium bias often remain subtle subjective make particularly difficult identify mitigate study assess medium bias llm generated content llm ability detect subtle ideological bias conduct evaluation use two datasets poligen econolex cover political economic discourse respectively evaluate eight widely use llm prompt generate article analyze ideological preference self assessment use self assessment study aim directly measure model bias rather rely external interpretation thereby minimize subjective judgment medium bias result reveal consistent preference democratic republican position model conversely economic topic bias vary western llm develop china lean strongly socialism,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16655,accelerate antibiotic discovery large language model knowledge graph,"Maxime Delmas, Magdalena Wysocka, Danilo Gusicuma, André Freitas",discovery novel antibiotic critical address grow antimicrobial resistance amr however pharmaceutical industry face high cost billion long timeline high failure rate worsen rediscovery known compound propose llm based pipeline act alarm system detect prior evidence antibiotic activity prevent costly rediscovery system integrate organism chemical literature knowledge graph kg ensure taxonomic resolution synonym handling multi level evidence classification test pipeline private list potential antibiotic producing organism disclose negative hit evaluation result highlight effectiveness pipeline evidence reviewing reduce false negative accelerate decision making kg negative hit user interface interactive exploration make publicly available,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16622,leverage large language model explainable activity recognition smart home critical evaluation,"Michele Fiori, Gabriele Civitarese, Priyankar Choudhary, Claudio Bettini",explainable artificial intelligence xai aim uncover inner reasoning machine learning model iot system xai improve transparency model process sensor data multiple heterogeneous device ensure end user understand trust output many application xai also apply sensor based activity daily living adls recognition smart home exist approach highlight sensor event important predicted activity use simple rule convert event natural language explanation non expert user however method produce rigid explanation lack natural language flexibility scalable recent rise large language model llm worth explore enhance explanation generation consider proven knowledge human activity paper investigate potential approach combine xai llm sensor based adl recognition evaluate llm use explainable zero shot adl recognition model avoid costly label data collection b automate generation explanation exist data driven xai approach train data available goal high recognition rate critical evaluation provide insight benefit challenge use llm explainable adl recognition,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16614,classification user report detection faulty computer component use nlp model case study,"Maria de Lourdes M. Silva, André L. C. Mendonça, Eduardo R. D. Neto, Iago C. Chaves, Felipe T. Brito, Victor A. E. Farias, Javam C. Machado",computer manufacturer typically offer platform user report fault however remain significant gap platform ability effectively utilize textual report impede user describe issue word context natural language processing nlp offer promising solution enable analysis user generated text paper present innovative approach employ nlp model classify user report detect faulty computer component cpu memory motherboard video card work build dataset user report obtain many source additionally extensive experimental evaluation approach achieve accuracy dataset,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.16585,distribute llm multimodal large language model survey advance challenge future direction,"Hadi Amini, Md Jueal Mia, Yasaman Saadati, Ahmed Imteaj, Seyedsina Nabavirazavi, Urmish Thakker, Md Zarif Hossain, Awal Ahmed Fime, S.S. Iyengar",language model lm machine learning model design predict linguistic pattern estimate probability word sequence base large scale datasets text lm wide range application natural language processing nlp task include autocomplete machine translation large datasets typically enhance lm performance scalability remain challenge due constraint computational power resource distribute compute strategy offer essential solution improve scalability manage grow computational demand use sensitive datasets training deployment raise significant privacy concern recent research focus develop decentralize technique enable distributed training inference utilize diverse computational resource enable edge ai paper present survey distributed solution various lm include large language model llm vision language model vlms multimodal llm mllms small language model slms llms focus processing generate text mllms design handle multiple modality data text image audio integrate broad application end paper review key advancement mllm pipeline include distributed training inference fine tuning deployment also identify contribution limitation future area improvement categorize literature base six primary focus area decentralization analysis describe gap current methodology enable distributed solution lm outline future research direction emphasize need novel solution enhance robustness applicability distributed lm,CL,20 Mar 2025
https://doi.org/10.48550/arXiv.2503.18950,target aware video diffusion model,"Taeksoo Kim, Hanbyul Joo",present target aware video diffusion model generate video input image actor interact specify target perform desired action target define segmentation mask desired action describe text prompt exist controllable image to video diffusion model often rely dense structural motion cue guide actor movement target target aware model require simple mask indicate target leverage generalization capability pretrained model produce plausible action make method particularly effective human object interaction hoi scenario provide precise action guidance challenge enable use video diffusion model high level action planning application robotics build target aware model extend baseline model incorporate target mask additional input enforce target awareness introduce special token encode target spatial information text prompt fine tune model curated dataset use novel cross attention loss align cross attention map associate token input target mask improve performance selectively apply loss semantically relevant transformer block attention region experimental result show target aware model outperforms exist solution generate video actor interact accurately specified target demonstrate efficacy two downstream application video content creation zero shot hoi motion synthesis,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18948,equivariant image modeling,"Ruixiao Dong, Mengde Xu, Zigang Geng, Li Li, Han Hu, Shuyang Gu",current generative model autoregressive diffusion approach decompose high dimensional data distribution learn series simple subtasks however inherent conflict arise joint optimization subtasks exist solution fail resolve conflict sacrifice efficiency scalability propose novel equivariant image model framework inherently align optimization target subtasks leverage translation invariance natural visual signal method introduces column wise tokenization enhance translational symmetry horizontal axis windowed causal attention enforce consistent contextual relationship position evaluate class conditioned imagenet generation resolution approach achieve performance comparable state of the art ar model use few computational resource systematic analysis demonstrate enhance equivariance reduces inter task conflict significantly improve zero shot generalization enable ultra long image synthesis work establish first framework task aligned decomposition generative modeling offer insight efficient parameter share conflict free optimization code model publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18947,tuning free amodal segmentation occlusion free bias inpainting model,"Jae Joong Lee, Bedrich Benes, Raymond A. Yeh",amodal segmentation aim predict segmentation mask visible occluded region object existing work formulate supervised learning problem require manually annotate amodal mask synthetic training data consequently performance depend quality datasets often lack diversity scale work introduce tuning free approach repurposes pretrained diffusion based inpainting model amodal segmentation approach motivate occlusion free bias inpainting model inpainted object tend complete object occlusion specifically reconstruct occluded region object inpainting apply segmentation additional training fine tuning experiment five datasets demonstrate generalizability robustness approach average approach achieve accurate mask state of the art,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18945,aether geometric aware unified world modeling,"Aether Team, Haoyi Zhu, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Yang Zhou, Zizun Li, Junyi Chen, Chunhua Shen, Jiangmiao Pang, Tong He",integration geometric reconstruction generative modeling remain critical challenge develop ai system capable human like spatial reasoning paper propose aether unified framework enable geometry aware reasoning world model jointly optimize three core capability dynamic reconstruction action conditioned video prediction goal conditioned visual planning task interleaved feature learning achieve synergistic knowledge share reconstruction prediction plan objective building video generation model framework demonstrate unprecedented synthetic to real generalization never observe real world data training furthermore approach achieve zero shot generalization action follow reconstruction task thanks intrinsic geometric modeling remarkably even real world data reconstruction performance far exceed domain specific model additionally aether leverage geometry informed action space seamlessly translate prediction action enable effective autonomous trajectory planning hope work inspire community explore new frontier physically reasonable world modeling application,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18944,dino room leveraging foundation model segmentation,"Karim Abou Zeid, Kadir Yilmaz, Daan de Geus, Alexander Hermans, David Adrian, Timm Linder, Bastian Leibe",vision foundation model vfms train large scale image datasets provide high quality feature significantly advance visual recognition however potential vision remain largely untapped common availability image alongside point cloud datasets significant research dedicate fusion recent state of the art method predominantly focus data leave integration vfms model underexplored work challenge trend introduce ditr simple yet effective approach extract foundation model feature project finally inject point cloud segmentation model ditr achieve state of the art result indoor outdoor semantic segmentation benchmark enable use vfms even image unavailable inference propose distill foundation model backbone pretraining task initialize backbone knowledge distil vfms create strong basis downstream segmentation task ultimately boost performance various datasets,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18943,family token efficient video large language model long form video understanding,"Mingze Xu, Mingfei Gao, Shiyu Li, Jiasen Lu, Zhe Gan, Zhengfeng Lai, Meng Cao, Kai Kang, Yinfei Yang, Afshin Dehghan",introduce abbreviate family video large language model llm offer token efficient solution long form video understanding model family employ two stream slowfast mechanism enable efficient modeling long range temporal context meet demand lightweight mobile friendly video llm provide model range parameter optimize streamlined training pipeline high quality data mixture compose publicly available datasets experimental result demonstrate achieves competitive performance wide range video image benchmark robust result model size notably achieves state of the art result long form video understanding longvideobench mlvu excels small scale various video benchmark,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18942,test time scaling video generation,"Fangfu Liu, Hanyang Wang, Yimo Cai, Kaiyan Zhang, Xiaohang Zhan, Yueqi Duan",scale capability increase training data model size computational cost video generation achieve impressive result digital creation enable user express creativity various domain recently researcher large language model llm expand scaling test time significantly improve llm performance use inference time computation instead scale video foundation model expensive training cost explore power test time scaling tt video generation aim answer question video generation model allow use non trivial amount inference time compute much improve generation quality give challenge text prompt work reinterpret test time scaling video generation search problem sample good trajectory gaussian noise space target video distribution specifically build search space test time verifier provide feedback heuristic algorithm guide search process give text prompt first explore intuitive linear search strategy increase noise candidate inference time full step denoising frame simultaneously require heavy test time computation cost design efficient tt method video generation call tree of frame tof adaptively expand prune video branch autoregressive manner extensive experiment text conditioned video generation benchmark demonstrate increase test time compute consistently lead significant improvement quality video project page http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18940,training free diffusion acceleration bottleneck sample,"Ye Tian, Xin Xia, Yuxi Ren, Shanchuan Lin, Xing Wang, Xuefeng Xiao, Yunhai Tong, Ling Yang, Bin Cui",diffusion model demonstrate remarkable capability visual content generation remain challenge deploy due high computational cost inference computational burden primarily arise quadratic complexity self attention respect image video resolution exist acceleration method often compromise output quality necessitate costly retrain observe diffusion model pre trained low resolution present opportunity exploit low resolution prior efficient inference degrade performance work introduce bottleneck sampling training free framework leverage low resolution prior reduce computational overhead preserve output fidelity bottleneck sample follow high low high denoising workflow perform high resolution denoising initial final stage operating low resolution intermediate step mitigate aliasing blurring artifact refine resolution transition point adaptively shift denoising timesteps stage evaluate bottleneck sampling image video generation task extensive experiment demonstrate accelerate inference image generation video generation maintain output quality comparable standard full resolution sample process multiple evaluation metric code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18933,syncvp joint diffusion synchronous multi modal video prediction,"Enrico Pallotta, Sina Mokhtarzadeh Azar, Shuai Li, Olga Zatsarynna, Juergen Gall",predict future video frame essential decision making system yet rgb frame alone often lack information need fully capture underlying complexity real world address limitation propose multi modal framework synchronous video prediction syncvp incorporate complementary data modality enhance richness accuracy future prediction syncvp build pre trained modality specific diffusion model introduces efficient spatio temporal cross attention module enable effective information share modality evaluate syncvp standard benchmark datasets cityscape bair use depth additional modality furthermore demonstrate generalization modality synthia semantic information climate data notably syncvp achieves state of the art performance even scenario one modality present demonstrate robustness potential wide range application,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18931,comp continual multimodal pre training vision foundation model,"Yitong Chen, Lingchen Meng, Wujian Peng, Zuxuan Wu, Yu-Gang Jiang",pre trained vision foundation model vfms provide strong visual representation wide range application paper continually pre train prevail vfms multimodal manner effortlessly process visual input vary size produce visual representation aligned language representation regardless original pre training process end introduce comp carefully design multimodal pre training pipeline comp use continual rotary position embed support native resolution continual pre training alignment loss visual textual feature language prototype align multimodal representation three stage training vfms achieve remarkable improvement multimodal understanding also downstream task classification segmentation remarkably comp siglip achieves score chartqa docvqa llm maintain accuracy miou frozen chunk evaluation,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18923,video simpleqa towards factuality evaluation large video language model,"Meng Cao, Pengfei Hu, Yingyao Wang, Jihao Gu, Haoran Tang, Haoze Zhao, Jiahua Dong, Wangbo Yu, Ge Zhang, Ian Reid, Xiaodan Liang",recent advancement large video language model lvlms highlight potential multi modal understanding yet evaluate factual grounding video context remain critical unsolved challenge address gap introduce video simpleqa first comprehensive benchmark tailor factuality evaluation lvlms work distinguishes exist video benchmark following key feature knowledge require demand integration external knowledge explicit narrative fact seeking question targeting objective undisputed event relationship avoid subjective interpretation definitive short form answer answer craft unambiguous definitively correct short format enable automate evaluation llm a a judge framework minimal score variance external source verify annotation undergo rigorous validation authoritative external reference ensure reliability temporal reasoning require annotated question type encompass static single frame understanding dynamic temporal reasoning explicitly evaluate lvlms factuality long context dependency extensively evaluate state of the art lvlms summarize key finding follow current lvlms exhibit notable deficiency factual adherence particularly open source model best performing model achieves merely f score test time compute paradigm show insignificant performance gain reveal fundamental constraint enhance factuality post hoc computation retrieval augmented generation demonstrate consistent improvement cost additional inference time overhead present critical efficiency performance trade off,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18903,building block robust effective semi supervised real world object detection,"Moussa Kassem Sbeyti, Nadja Klein, Azarm Nowzad, Fikret Sivrikaya, Sahin Albayrak",semi supervised object detection ssod base pseudo labeling significantly reduce dependence large label datasets effectively leverage label unlabeled data however real world application ssod often face critical challenge include class imbalance label noise labeling error present in depth analysis ssod real world condition uncover cause suboptimal pseudo labeling key trade offs label quality quantity base finding propose four building block seamlessly integrate ssod framework rare class collage rcc data augmentation method enhance representation rare class create collage rare object rare class focus rcf stratified batch sample strategy ensure balanced representation class training ground truth label correction glc label refinement method identifies corrects false miss noisy ground truth label leverage consistency teacher model prediction pseudo label selection pls selection method remove low quality pseudo labeled image guide novel metric estimate miss detection rate account class rarity validate method comprehensive experiment autonomous drive datasets result increase ssod performance overall investigation novel data centric broadly applicable building block enable robust effective ssod complex real world scenario code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18897,online scene reconstruction use neural object prior,"Thomas Chabal, Shizhe Chen, Jean Ponce, Cordelia Schmid",paper address problem reconstruct scene online level object give rgb d video sequence current object aware neural implicit representation hold promise limit online reconstruction efficiency shape completion main contribution alleviate limitation twofold first propose feature grid interpolation mechanism continuously update grid based object centric neural implicit representation new object part reveal second construct object library previously map object advance leverage corresponding shape prior initialize geometric object model new video subsequently complete novel view well synthesize past view avoid lose original object detail extensive experiment synthetic environment replica dataset real world scannet sequence video capture laboratory demonstrate approach outperform state of the art neural implicit model task term reconstruction accuracy completeness,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18886,cfg zero improve classifier free guidance flow matching model,"Weichen Fan, Amber Yijia Zheng, Raymond A. Yeh, Ziwei Liu",classifier free guidance cfg widely adopt technique model improve image fidelity controllability work first analytically study effect cfg flow matching model train gaussian mixture ground truth flow derive observe early stage training flow estimation inaccurate cfg directs sample incorrect trajectory building observation propose cfg zero improved cfg two contribution optimize scale scalar optimize correct inaccuracy estimated velocity hence name b zero init involve zero first step ode solver experiment text to image lumina next stable diffusion flux text to video generation demonstrate cfg zero consistently outperform cfg highlight effectiveness guide flow matching model code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18883,efficient accurate scene text recognition cascaded transformer,"Savas Ozkan, Andrea Maracani, Hyowon Kim, Sijun Cho, Eunchung Noh, Jeongwon Min, Jung Min Cho, Mete Ozay",recent year vision transformer text decoder demonstrate remarkable performance scene text recognition str due ability capture long range dependency contextual relationship high learn capacity however computational memory demand model significant limit deployment resource constrained application address challenge propose efficient accurate str system specifically focus improve efficiency encoder model introduce cascaded transformers structure structure progressively reduce vision token size encoding step effectively eliminate redundant token reduce computational cost experimental result confirm str system achieve comparable performance state of the art baseline substantially decrease computational requirement particular large model accuracy remain computational complexity almost halve structure,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18880,see speech sound distinguishing locate audio visual scene,"Hyeonggon Ryu, Seongyu Kim, Joon Son Chung, Arda Senocak",present unified model capable simultaneously ground spoken language non speech sound visual scene address key limitation current audio visual grounding model exist approach typically limited handle speech non speech sound independently best together sequentially mix limitation prevent capture complexity real world audio source often mixed approach introduce framework audio visual alignment objective jointly learn correspondence disentanglement use mixed audio objective model learn produce distinct embeddings audio type enable effective disentanglement grounding mixed audio source additionally create new dataset evaluate simultaneous grounding mixed audio source demonstrate model outperform prior method approach also achieve comparable good performance standard segmentation cross modal retrieval task highlight benefit mix and separate approach,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18873,efficient self supervised adaptation medical image analysis,"Moein Sorkhei, Emir Konuk, Jingyu Guo, Christos Matsoukas, Kevin Smith",self supervised adaptation ssa improve foundation model transfer medical domain computationally prohibitive parameter efficient fine tuning method lora explore supervised adaptation effectiveness ssa remain unknown work introduce efficient self supervised adaptation essa framework apply parameter efficient fine tuning technique ssa aim reduce computational cost improve adaptation performance method test attention projection layer adaptation apla set new state of the art consistently surpass full parameter ssa supervise fine tuning diverse medical task reduce gpu memory increase training throughput maintain inference efficiency,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18872,curriculum coarse to fine selection high ipc dataset distillation,"Yanda Chen, Gongwei Chen, Miao Zhang, Weili Guan, Liqiang Nie",dataset distillation dd excels synthesize small number image class ipc struggle maintain effectiveness high ipc setting recent work dataset distillation demonstrate combine distil real data mitigate effectiveness decay however analysis combination paradigm reveals current one shot independent selection mechanism induce incompatibility issue distil real image address issue introduce novel curriculum coarse to fine selection ccfs method efficient high ipc dataset distillation ccfs employ curriculum selection framework real data selection leverage coarse to fine strategy select appropriate real data base current synthetic dataset curriculum extensive experiment validate ccfs surpass state of the art tiny imagenet high ipc setting notably ccfs achieve test accuracy compression ratio tiny imagenet closely match full dataset training degradation code http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18862,explore integration key value attention pure hybrid transformer semantic segmentation,"DeShin Hwa, Tobias Holmes, Klaus Drechsler",cnns long consider state art image processing introduction transformer architecture challenge position achieve excellent result image classification segmentation transformer remain inherently reliant large train datasets remain computationally expensive newly introduce transformer derivative name kv transformer show promise result synthetic nlp image classification task reduce complexity memory usage especially conducive use case local inference require medical screening application endeavour evaluate merit kv transformer semantic segmentation task specifically domain medical imaging directly compare traditional kv variant base architecture provide insight practical tradeoff reduced model complexity observe notable reduction parameter count multiply accumulate operation achieve similar performance kv variant model directly compare qkv implementation,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18860,hunyuanportrait implicit condition control enhanced portrait animation,"Zunnan Xu, Zhentao Yu, Zixiang Zhou, Jun Zhou, Xiaoyu Jin, Fa-Ting Hong, Xiaozhong Ji, Junwei Zhu, Chengfei Cai, Shiyu Tang, Qin Lin, Xiu Li, Qinglin Lu",introduce diffusion based condition control method employ implicit representation highly controllable lifelike portrait animation give single portrait image appearance reference video clip drive template hunyuanportrait animate character reference image facial expression head pose driving video framework utilize pre trained encoders achieve decoupling portrait motion information identity video implicit representation adopt encode motion information employ control signal animation phase leverage power stable video diffusion main building block carefully design adapter layer inject control signal denoising unet attention mechanism bring spatial richness detail temporal consistency hunyuanportrait also exhibit strong generalization performance effectively disentangle appearance motion different image style framework outperform exist method demonstrate superior temporal consistency controllability project available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18854,mc llava multi concept personalized vision language model,"Ruichuan An, Sihan Yang, Ming Lu, Renrui Zhang, Kai Zeng, Yulin Luo, Jiajun Cao, Hao Liang, Ying Chen, Qi She, Shanghang Zhang, Wentao Zhang",current vision language model vlms show exceptional ability diverse task visual question answer enhance user experience recent study investigate vlm personalization understand user provided concept however mainly focus single concept personalization neglect existence interplay multiple concept limit real world applicability paper propose first multi concept personalization paradigm mc llava specifically mc llava employ multi concept instruction tune strategy effectively integrate multiple concept single training step reduce cost relate joint training propose personalized textual prompt use visual token information initialize concept token additionally introduce personalized visual prompt inference aggregate location confidence map enhanced recognition ground capability advance multi concept personalization research contribute high quality instruction tune dataset carefully collect image multiple character object movie manually generate question answer sample multi concept scenario feature superior diversity comprehensive qualitative quantitative experiment demonstrate mc llava achieve impressive multi concept personalized response pave way vlms become good user specific assistant code dataset publicly available http url http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18853,texture swap object single reference image,"Xiao Cao, Beibei Lin, Bo Wang, Zhiyong Huang, Robby T. Tan",texture swapping allow customization object texture enable efficient versatile visual transformation editing dedicated method exists adapt editing text driven edit approach serve purpose however edit require frame by frame manipulation cause inconsistency view text driven edit struggle preserve texture characteristic reference image tackle challenge introduce texture swap method integrate progressive generation view consistency gradient guidance prompt tuned gradient guidance ensure view consistency progressive generation process start edit single reference image gradually propagate edits adjacent view view consistency gradient guidance reinforces consistency condition generation model feature difference consistent inconsistent output preserve texture characteristic introduce prompt tuning based gradient guidance learn token precisely capture difference reference image object token guide edit process ensure consistent texture preservation view overall integrates novel strategy achieve higher fidelity texture transfer preserve structural coherence multiple viewpoint extensive qualitative quantitative evaluation confirm three novel component enable convincing effective texture swap object code available upon acceptance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18830,dagait generalize skeleton guided data alignment gait recognition,"Zhengxian Wu, Chuanrui Zhang, Hangrui Xu, Peng Jiao, Haoqian Wang",gait recognition emerge promising innovative area field computer vision widely apply remote person identification exist gait recognition method achieve substantial success controlled laboratory datasets performance often decline significantly transition wild http url argue performance gap primarily attribute spatio temporal distribution inconsistency present wild datasets subject appear vary angle position distance frame achieve accurate gait recognition wild propose skeleton guided silhouette alignment strategy use prior knowledge skeleton perform affine transformation corresponding http url best knowledge first study explore impact data alignment gait recognition conduct extensive experiment multiple datasets network architecture result demonstrate significant advantage propose alignment http url challenge dataset method achieve average performance improvement evaluate network furthermore method achieve substantial improvement cross domain datasets accuracy improvement,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18817,enhance ood detection cross modal alignment multi modal representation,"Jeonghyeon Kim, Sangheum Hwang",prior research out of distribution detection oodd primarily focus single modality model recently advent large scale pretrained vision language model clip oodd method utilize multi modal representation zero shot prompt learning strategy emerge however method typically involve either freeze pretrained weight partially tune suboptimal downstream datasets paper highlight multi modal fine tuning mmft achieve notable oodd performance recent work demonstrate impact fine tuning method oodd remain significant potential performance improvement investigate limitation naïve fine tuning method examine fail fully leverage pretrained knowledge empirical analysis suggest issue could stem modality gap in distribution id embeddings address propose training objective enhance cross modal alignment regularize distance image text embeddings id data adjustment help good utilizing pretrained textual information align similar semantics different modality text image closely hyperspherical representation space theoretically demonstrate propose regularization correspond maximum likelihood estimation energy based model hypersphere utilizing ood benchmark datasets show method combine post hoc oodd approach leverage pretrained knowledge neglabel significantly outperform exist method achieve state of the art oodd performance lead id accuracy,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18812,skdu de factify vision transformer data augmentation ai generated image detection,"Shrikant Malviya, Neelanjan Bhowmik, Stamos Katsigiannis",aim work explore potential pre trained vision language model vision transformer vit enhance advanced data augmentation strategy detection ai generated image approach leverage fine tuned vit model train dataset include image generate state of the art model stable diffusion stable diffusion xl stable diffusion dall e midjourney employ perturbation technique flip rotation gaussian noise injection jpeg compression training improve model robustness generalisation experimental result demonstrate vit based pipeline achieve state of the art performance significantly outperform compete method validation test datasets,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18808,crcl causal representation consistency learn anomaly detection surveillance video,"Yang Liu, Hongjin Wang, Zepu Wang, Xiaoguang Zhu, Jing Liu, Peng Sun, Rui Tang, Jianwei Du, Victor C.M. Leung, Liang Song",video anomaly detection vad remain fundamental yet formidable task video understand community promising application area information forensics public safety protection due rarity diversity anomaly exist method use easily collect regular event model inherent normality normal spatial temporal pattern unsupervised manner previous study show exist unsupervised vad model incapable label independent data offset scene change real world scenario may fail respond light anomaly due overgeneralization deep neural network inspire causality learning argue exist causal factor adequately generalize prototypical pattern regular event present significant deviation anomalous instance occur regard propose causal representation consistency learning crcl implicitly mine potential scene robust causal variable unsupervised video normality learning specifically build structural causal model propose scene debiasing learning causality inspired normality learn strip away entangled scene bias deep representation learn causal video normality respectively extensive experiment benchmark validate superiority method conventional deep representation learning moreover ablation study extension validation show crcl cope label independent bias multi scene setting maintain stable performance limited training data available,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18803,revisiting change detection caption video model perspective,"Duowang Zhu, Xiaohu Huang, Haiyan Huang, Hao Zhou, Zhenfeng Shao",paper present framework reconceptualizes change detection captioning task video modeling recent method achieve remarkable success regard pair bi temporal image separate frame employ shared weight image encoder extract spatial feature use change extractor capture difference two image however image feature encode task agnostic process attend change region effectively furthermore different change extractor design various change detection caption task make difficult unified framework tackle challenge regard bi temporal image comprise two frame akin tiny video integrate learnable perception frame bi temporal image video encoder enable perception frame interact image directly perceive difference therefore get rid intricate change extractor provide unified framework different change detection caption task verify multiple task encompass change detection include binary change detection semantic change detection building damage assessment change captioning eight standard benchmark bell whistle simple yet effective framework achieve superior performance ultra light video model comprise parameter flop compare state of the art method hope could alternative model facilitate future research,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18794,nexusgs sparse view synthesis epipolar depth prior gaussian splatting,"Yulong Zheng, Zicheng Jiang, Shengfeng He, Yandu Sun, Junyu Dong, Huaidong Zhang, Yong Du",neural radiance field nerf gaussian splatting noticeably advance photo realistic novel view synthesis use image densely space camera viewpoint however method struggle few shot scenario due limited supervision paper present nexusgs approach enhance novel view synthesis sparse view image directly embed depth information point cloud rely complex manual regularization exploit inherent epipolar geometry method introduce novel point cloud densification strategy initialize dense point cloud reduce randomness point placement prevent over smoothing overfitting specifically nexusgs comprises three key step epipolar depth nexus flow resilient depth blending flow filtered depth pruning step leverage optical flow camera pose compute accurate depth map mitigate inaccuracy often associate optical flow incorporate epipolar depth prior nexusgs ensures reliable dense point cloud coverage support stable train sparse view condition experiment demonstrate nexusgs significantly enhance depth accuracy render quality surpass state of the art method considerable margin furthermore validate superiority generated point cloud substantially boost performance compete method project page http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18785,lgi detr local global interaction uav object detection,Zifa Chen,uav widely use various field however exist object detector use drone end to end require design various complex component careful fine tuning exist end to end object detector design natural scene ideal apply directly uav image order solve challenge design local global information interaction detr uavs namely lgi detr cross layer bidirectional low level high level feature information enhancement fusion method effective especially field small objection detection initial stage encoder propose local spatial enhancement module lse enhance low level rich local spatial information high level feature reduce loss local information transmission process high level information final stage encoder propose novel global information injection module gii design integrate rich high level global semantic representation low level feature map hierarchical fusion mechanism effectively address inherent limitation local receptive field propagate contextual information feature hierarchy experimental result two challenge uav image object detection benchmark uavdt show propose model outperform sota model compare baseline model ap improve respectively,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18784,leverage perturbation robustness enhance out of distribution detection,"Wenxi Chen, Raymond A. Yeh, Shaoshuai Mou, Yan Gu",out of distribution ood detection task identify input deviate training data distribution capability essential safely deploy deep computer vision model open world environment work propose post hoc method perturbation rectified ood detection pro base insight prediction confidence ood input susceptible reduction perturbation in distribution ind input base observation propose adversarial score function search local minimum score original input apply gradient descent procedure enhance separability ind ood sample importantly approach improve ood detection performance complex modification underlie model architecture conduct extensive experiment use openood approach push limit softmax based ood detection lead post hoc method small scale model model adversarial training pro effectively detect near ood input achieve reduction fpr compare state of the art method,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18783,frequency dynamic convolution dense image prediction,"Linwei Chen, Lin Gu, Liang Li, Chenggang Yan, Ying Fu",dynamic convolution dy conv show promising performance enable adaptive weight selection multiple parallel weight combine attention mechanism frequency response weight tend exhibit high similarity result high parameter cost limited adaptability work introduce frequency dynamic convolution fdconv novel approach mitigate limitation learn fixed parameter budget fourier domain fdconv divide budget frequency based group disjoint fourier index enable construction frequency diverse weight increase parameter cost enhance adaptability propose kernel spatial modulation ksm frequency band modulation fbm ksm dynamically adjust frequency response filter spatial level fbm decomposes weight distinct frequency band frequency domain modulate dynamically base local content extensive experiment object detection segmentation classification validate effectiveness fdconv demonstrate apply fdconv achieves superior performance modest increase parameter outperform previous method require substantial increase parameter budget condconv kw moreover fdconv seamlessly integrate variety architecture include convnext swin transformer offer flexible efficient solution modern vision task code make publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18767,good keypoints two view geometry estimation problem,"Konstantin Pakulev, Alexander Vakhitov, Gonzalo Ferrer",local feature essential many modern downstream application therefore interest determine property local feature contribute downstream performance good design feature detector descriptor work propose new theoretical model score feature point keypoints context two view geometry estimation problem model determine two property good keypoint solve homography estimation problem repeatable small expect measurement error result provide key insight maximize number correspondence always lead good homography estimation accuracy use developed model design method detect keypoints benefit homography estimation introduce bound ness st boness st keypoint detector novelty boness st come strong theoretical foundation accurate keypoint score due subpixel refinement cost design superior robustness low saliency keypoints result boness st outperforms prior self supervised local feature detector planar homography epipolar geometry estimation problem,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18755,egosurgery hts dataset egocentric hand tool segmentation open surgery video,"Nathan Darjana, Ryo Fujii, Hideo Saito, Hiroki Kajita",egocentric open surgery video capture rich fine grained detail essential accurately model surgical procedure human behavior operating room detailed pixel level understanding hand surgical tool crucial interpret surgeon action intention introduce egosurgery hts new dataset pixel wise annotation benchmark suite segment surgical tool hand interact tool egocentric open surgery video specifically provide labeled dataset tool instance segmentation distinct surgical tool hand instance segmentation hand tool segmentation label hand tool manipulate use egosurgery hts conduct extensive evaluation state of the art segmentation method demonstrate significant improvement accuracy hand hand tool segmentation egocentric open surgery video compare exist datasets dataset release http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18753,self supervised learning base transformed image reconstruction equivariance coherent feature representation,"Qin Wang, Benjamin Bruns, Hanno Scharr, Kai Krajsek",equivariant behaviour feature essential many computer vision task yet popular self supervised learning ssl method tend constrain equivariance design propose self supervised learning approach system learn transformation independently reconstruct image undergo previously unseen transformation specifically model task reconstruct intermediate transform image translate rotate image prior knowledge transformation auxiliary task encourage model develop equivariance coherent feature rely predefined transformation rule end apply transformation input image generate image pair split extracted feature two set image one set use usual ssl loss encourage invariance loss base auxiliary task reconstruct intermediate transform image loss ssl loss linearly combine weighted term evaluate synthetic task natural image propose method strongly outperform competitor regardless design learn equivariance furthermore trained alongside augmentation based method invariance task ibot successfully learn balanced combination invariant equivariant feature approach perform strong rich set realistic computer vision downstream task almost always improve baseline,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18746,linguistics aware mask image model self supervised scene text recognition,"Yifei Zhang, Chang Liu, Jin Wei, Xiaomeng Yang, Yu Zhou, Can Ma, Xiangyang Ji",text image unique dual nature encompass visual linguistic information visual component encompass structural appearance based feature linguistic dimension incorporate contextual semantic element scenario degraded visual quality linguistic pattern serve crucial supplement comprehension highlight necessity integrate aspect robust scene text recognition str contemporary str approach often use language model semantic reasoning module capture linguistic feature typically require large scale annotated datasets self supervised learning lack annotation present challenge disentangle linguistic feature relate global context typically sequence contrastive learning emphasize alignment local feature mask image modeling mim tend exploit local structure reconstruct visual pattern result limited linguistic knowledge paper propose linguistics aware masked image modeling lmim approach channel linguistic information decode process mim separate branch specifically design linguistics alignment module extract vision independent feature linguistic guidance use input different visual appearance feature extend mere visual structure lmim must consider global context achieve reconstruction extensive experiment various benchmark quantitatively demonstrate state of the art performance attention visualization qualitatively show simultaneous capture visual linguistic information,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18742,sfdla source free document layout analysis,"Sebastian Tewes, Yufan Chen, Omar Moured, Jiaming Zhang, Rainer Stiefelhagen",document layout analysis dla fundamental task document understanding however exist dla adaptation method often require access large scale source data target label requirement severely limit real world applicability particularly privacy sensitive resource constrained domain financial statement medical record proprietary business document accord observation directly transfer source domain fine tuned model target domain often result significant performance drop avg work introduce source free document layout analysis sfdla aim adapt pre trained source dla model unlabeled target domain access source data address challenge establish first sfdla benchmark cover three major dla datasets geometric  content aware adaptation furthermore propose document layout analysis adapter dladapter novel framework design improve source free adaptation document domain method achieve improvement source only baseline gain exist source free method publaynet doclaynet believe work inspire dla community investigate source free document understanding support future research community benchmark model code publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18725,fg fine grained cross view localization fine grained feature match,"Zimin Xia, Alexandre Alahi",propose novel fine grained cross view localization method estimate degree freedom pose ground level image aerial image surroundings match fine grained feature two image pose estimate align point plane generate ground image point plane sample aerial image generate ground point first map ground image feature point cloud method learn select feature height dimension pool point bev plane selection enable trace feature ground image contribute bev representation next sample set sparse match compute point correspondence two point plane compute relative pose use procrustes alignment compare previous state of the art method reduce mean localization error vigor cross area test set qualitative result show method learn semantically consistent match ground aerial view weakly supervise learn camera pose,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18719,boost resolution generalization diffusion transformer randomized positional encoding,"Cong Liu, Liang Hou, Mingwu Zheng, Xin Tao, Pengfei Wan, Di Zhang, Kun Gai",resolution generalization image generation task enable production higher resolution image low training resolution overhead however significant challenge resolution generalization particularly widely use diffusion transformer lie mismatch positional encoding encounter test use training exist method employ technique interpolation extrapolation combination none fully resolve issue paper propose novel two dimensional randomize positional encoding framework focus learn positional order image patch instead specific distance enable seamless high  low resolution image generation require high  low resolution image training specifically independently select position broad range horizontal vertical ax ensure position encoding train inference phase thus improve resolution generalization additionally propose random data augmentation technique enhance modeling position order address issue image cropping cause augmentation introduce correspond micro conditioning enable model perceive specific cropping pattern imagenet dataset propose achieves state of the art resolution generalization performance outperform exist competitive method train resolution infer well scale also exhibit outstanding capability low resolution image generation multi stage training acceleration multi resolution inheritance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18718,g marker generalizable robust watermarking gaussian splatting,"Lijiang Li, Jinglu Wang, Xiang Ming, Yan Lu",generative ai era safeguard model become increasingly urgent invisible watermarking well established image encoder decoder framework generalizable robust solution remain elusive main difficulty arises renderer encoder decoder disrupt direct gradient flow complicate train exist method typically rely per scene iterative optimization result time inefficiency limited generalization work propose single pas watermarking approach gaussian splatting well known yet underexplored representation watermarking identify two major challenge ensure effective training generalize diverse model reliably extract watermark free view rendering even distortion framework name g marker incorporate encoder embed message distortion layer enhance resilience various distortion decoder extract watermark rendering key innovation adaptive marker control mechanism adaptively perturb initially optimized escape local minimum improve training stability convergence extensive experiment show g marker outperforms per scene training approach term decode accuracy model fidelity also significantly reduce computation time,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18712,llavaction evaluating train multi modal large language model action recognition,"Shaokai Ye, Haozhe Qi, Alexander Mathis, Mackenzie W. Mathis",understand human behavior require measure behavioral action due complexity behavior best map rich semantic structure language recent development multi modal large language model mllms promising candidate wide range action understand task work focus evaluating improve mllms perform action recognition reformulate one large challenging egocentric action datasets form video multiple question answer show sample difficult incorrect answer distractors lead mllms struggle recognize correct action propose series method greatly improve mllms ability perform action recognition achieve state of the art validation set well outperform point accuracy lastly show improvement action related video benchmark egoschema perceptiontest longvideobench videomme mvbench suggest mllms promising path forward complex action task code model available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18711,novel view synthesis dataset,"Thomas Sugg, Kyle O'Brien, Lekh Poudel, Alex Dumouchelle, Michelle Jou, Marc Bosch, Deva Ramanan, Srinivasa Narasimhan, Shubham Tulsiani",paper introduce specialized dataset design research novel view synthesis specifically airborne ground imagery data collect austin tx pittsburgh pa collection encompass six diverse real world scene capture airborne ground camera result total image address challenge vary altitude transient object dataset intend supplement exist datasets provide additional resource comprehensive research rather serve benchmark,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18709,revisit automatic data curation vision foundation model digital pathology,"Boqi Chen, Cédric Vincent-Cuaz, Lydia A. Schoenpflug, Manuel Madeira, Lisa Fournier, Vaishnavi Subramanian, Sonali Andani, Samuel Ruiperez-Campillo, Julia E. Vogt, Raphaëlle Luisier, Dorina Thanou, Viktor H. Koelzer, Pascal Frossard, Gabriele Campanella, Gunnar Rätsch",vision foundation model fm accelerate development digital pathology algorithm transform biomedical research model learn self supervised manner represent histological feature highly heterogeneous tile extract whole slide image wsis real world patient sample performance fm significantly influence size diversity balance pre training data however data selection primarily guide expert knowledge wsi level focus factor disease classification tissue type largely overlook granular detail available tile level paper investigate potential unsupervised automatic data curation tile level take account million tile specifically apply hierarchical clustering tree pre extracted tile embeddings allow sample balanced datasets uniformly embed space pretrained fm identify datasets subject trade off size balance potentially compromise quality representation learn fm propose tailored batch sample strategy mitigate effect demonstrate effectiveness method improve performance diverse range clinically relevant downstream task,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18705,benchmarking burst super resolution polarization image noise dataset analysis,"Inseung Hwang, Kiseok Choi, Hyunho Ha, Min H. Kim",snapshot polarization image calculates polarization state linearly polarize subimages achieve polarization camera employ double bayer patterned sensor capture color polarization demonstrate low light efficiency low spatial resolution result increase noise compromise polarization measurement burst super resolution effectively reduce noise enhance spatial resolution apply polarization image pose challenge due lack tailored datasets reliable ground truth noise statistic address issue introduce polarns polarburstsr two innovative datasets develop specifically polarization imaging polarns provide characterization polarization noise statistic facilitate thorough analysis polarburstsr function benchmark burst super resolution polarization image datasets collect various real world condition enable comprehensive evaluation additionally present model analyze polarization noise quantify noise propagation test large dataset capture darkroom environment part application compare late burst super resolution model highlight advantage training tailor polarization compare rgb based method work establish benchmark polarization burst super resolution offer critical insight noise propagation thereby enhance polarization image reconstruction,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18703,channel consistency prior self reconstruction strategy base unsupervised image deraining,"Guanglu Dong, Tianheng Zheng, Yuanzhouhan Cao, Linbo Qing, Chao Ren",recently deep image deraining model base paired datasets make series remarkable progress however well apply real world application due difficulty obtain real pair datasets poor generalization performance paper propose novel channel consistency prior self reconstruction strategy base unsupervised image deraining framework csud tackle aforementioned challenge train unpaired data csud capable generate high quality pseudo clean rainy image pair use enhance performance deraining network specifically preserve image background detail transfer rain streak rainy image unpaired clean image propose novel channel consistency loss ccloss introduce channel consistency prior ccp rain streak training process thereby ensure generated pseudo rainy image closely resemble real one furthermore propose novel self reconstruction sr strategy alleviate redundant information transfer problem generator improve deraining performance generalization capability method extensive experiment multiple synthetic real world datasets demonstrate deraining performance csud surpass state of the art unsupervised method csud exhibit superior generalization capability,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18695,ocrt boosting foundation model open world object concept relation triad,"Luyao Tang, Yuxuan Yuan, Chaoqi Chen, Zeyu Zhang, Yue Huang, Kun Zhang",foundation model fm claim powerful generalization ability significantly decrease face distribution shift weak supervision malicious attack open world hand domain generalization adversarial fine tuning method task related model specific ignore universality practical application transferability fm paper delve problem generalize fm out of domain data propose novel framework object concept relation triad ocrt enable fms extract sparse high level concept intricate relational structure raw visual input key idea bind object visual scene set object centric representation unsupervised decoupling iterative refinement specific project object centric representation semantic concept space model readily interpret estimate importance filter irrelevant element concept based graph flexible degree construct incorporate set concept corresponding importance enable extraction high order factor informative concept facilitate relational reasoning concept extensive experiment demonstrate ocrt substantially boost generalizability robustness sam clip multiple downstream task,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18682,hardware rasterized ray based gaussian splatting,"Samuel Rota Bulò, Nemanja Bartolovic, Lorenzo Porzi, Peter Kontschieder",present novel hardware rasterize render approach ray based gaussian splatting raygs obtain fast high quality result novel view synthesis work contain mathematically rigorous geometrically intuitive derivation efficiently estimate relevant quantity render raygs model structure respect standard hardware rasterization shaders solution first enable render raygs model sufficiently high frame rate support quality sensitive application virtual mixed reality second contribution enable alias free render raygs address mip related issue arise render diverge scale training test demonstrate significant performance gain different benchmark scene retain state of the art appearance quality raygs,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18678,nullswap proactive identity cloak deepfake face swap,"Tianyi Wang, Harry Cheng, Xiao Zhang, Yinglong Wang",suffer performance bottleneck passively detect high quality deepfake image due advancement generative model proactive perturbation offer promising approach disable deepfake manipulation insert signal benign image however exist proactive perturbation approach remain unsatisfactory several aspect visual degradation due direct element wise addition limit effectiveness face swap manipulation unavoidable reliance white  grey box setting involve generative model training study analyze essence deepfake face swapping argue necessity protect source identity rather target image propose nullswap novel proactive defense approach cloak source image identity nullifies face swap pure black box scenario design identity extraction module obtain facial identity feature source image perturbation block devise generate identity guided perturbation accordingly meanwhile feature block extract shallow level image feature fuse perturbation cloaking block image reconstruction furthermore ensure adaptability different identity extractor face swap algorithm propose dynamic loss weight adaptively balance identity loss experiment demonstrate outstanding ability approach fool various identity recognition model outperform state of the art proactive perturbation prevent face swap model generate image correct source identity,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18674,human motion unlearning,"Edoardo De Matteis, Matteo Migliarini, Alessio Sampieri, Indro Spinelli, Fabio Galasso",introduce task human motion unlearning prevent synthesis toxic animation preserve general text to motion generative performance unlearning toxic motion challenge generate explicit text prompt implicit toxic combination safe motion kicking load swing leg propose first motion unlearn benchmark filter toxic motion large recent text to motion datasets motion x propose baseline adapt state of the art image unlearn technique process spatio temporal signal finally propose novel motion unlearn model base latent code replacement dub lcr lcr training free suitable discrete latent space state of the art text to motion diffusion model lcr simple consistently outperform baseline qualitatively quantitatively project page http url http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18673,model free pose estimation novel object,"Taeyeop Lee, Bowen Wen, Minjun Kang, Gyuree Kang, In So Kweon, Kuk-Jin Yoon",introduce model free framework object pose estimation require single rgb d anchor image estimate pose size unknown object novel scene exist method rely textured model multiple viewpoint leverage joint object alignment process enhance alignment metric scale estimation improve pose accuracy approach integrate render and compare strategy generate refine pose hypothesis enable robust performance scenario occlusion non overlapping view diverse lighting condition large cross environment variation evaluate method five challenge datasets toyota light ycbineoat lm o demonstrate effectiveness significantly outperform state of the art method novel object pose estimation project page http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18672,feature calibration enhance parameter synthesis clip based class incremental learning,"Juncen Guo, Xiaoguang Zhu, Lianlong Sun, Liangyu Teng, Di Li, Yang Liu, Liang Song",class incremental learning cil enable model continuously learn new class knowledge memorize previous class facilitate adaptation evolution dynamic environment traditional cil method mainly base visual feature limit ability handle complex scenario contrast vision language model vlms show promise potential promote cil integrate pretrained knowledge textual feature however previous method make difficult overcome catastrophic forget preserve generalization capability vlms tackle challenge propose feature calibration enhance parameter synthesis fcps paper specifically fcps employ specific parameter adjustment mechanism iteratively refine proportion original visual feature participate final class determination ensure model foundational generalization capability meanwhile parameter integration different task achieve balance learn new class knowledge retain old knowledge experimental result popular benchmark validate superiority propose method,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18671,structure aware correspondence learning relative pose estimation,"Yihan Chen, Wenfei Yang, Huan Ren, Shifeng Zhang, Tianzhu Zhang, Feng Wu",relative pose estimation provide promising way achieve object agnostic pose estimation success exist correspondence based method reliance explicit feature match suffers small overlap visible region unreliable feature estimation invisible region inspire human ability assemble two object part small overlap region consider object structure propose novel structure aware correspondence learning method relative pose estimation consist two key module first structure aware keypoint extraction module design locate set kepoints represent structure object different shape appearance guidance keypoint base image reconstruction loss second structure aware correspondence estimation module design model intra image inter image relationship keypoints extract structure aware feature correspondence estimation jointly leverage two module propose method naturally estimate correspondence unseen object explicit feature match precise relative pose estimation experimental result objaverse linemod datasets demonstrate propose method significantly outperform prior method mean angular error dataset,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18665,boost virtual agent learning reasoning step wise multi dimensional generalist reward model benchmark,"Bingchen Miao, Yang Wu, Minghe Gao, Qifan Yu, Wendong Bu, Wenqiao Zhang, Yunfei Li, Siliang Tang, Tat-Seng Chua, Juncheng Li",development generalist virtual agent gvas power multimodal large language model mllms show significant promise autonomous task execution however current training paradigm face critical limitation include reliance outcome supervision labor intensive human annotation address challenge propose similar step wise multi dimensional generalist reward model offer fine grained signal agent training choose good action inference time scaling specifically begin systematically define five dimension evaluate agent action building framework design mcts p algorithm automatically collect annotate step wise five dimensional agent execution data use data train similar triple m strategy furthermore introduce first benchmark virtual agent domain step wise multi dimensional reward model training evaluation name srm benchmark consist two component srmtrain serve training set similar srmeval manually select test set evaluate reward model experimental result demonstrate similar step wise multi dimensional assessment synergistic gain provide gvas effective intermediate signal training inference time scaling code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18658,leverage land cover prior isoprene emission super resolution,"Christopher Ummerle, Antonio Giganti, Sara Mandelli, Paolo Bestagini, Stefano Tubaro",remote sense play crucial role monitor earth ecosystem yet satellite derived data often suffer limited spatial resolution restrict applicability atmospheric modeling climate research work propose deep learning based super resolution sr framework leverage land cover information enhance spatial accuracy biogenic volatile organic compound bvocs emission particular focus isoprene approach integrate land cover prior emission driver capture spatial pattern effectively traditional method evaluate model performance various climate condition analyze statistical correlation isoprene emission key environmental information cropland tree cover data additionally assess generalization capability sr model apply unseen climate zone geographical region experimental result demonstrate incorporate land cover data significantly improve emission sr accuracy particularly heterogeneous landscape study contribute atmospheric chemistry climate modeling provide cost effective data driven approach refine bvoc emission map propose method enhance usability satellite based emission data support application air quality forecasting climate impact assessment environmental study,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18652,robust face recognition base wing loss regularization,"Yaoyao Yun, Jianwen Xu",recent year sparse sample technique base regression analysis witness extensive application face recognition research presently numerous sparse sample model base regression analysis explore various researcher nevertheless recognition rate majority model would significantly decrease confront highly occlude highly damaged face image paper new wing constrained sparse cod model wcsc weighted version wwcsc introduce deal face recognition problem complex circumstance alternate direction method multiplier admm algorithm employ solve corresponding minimization problem addition performance propose method examine base four well known facial database namely orl facial database yale facial database ar facial database feret facial database also compare method literature wwcsc high recognition rate even complex situation face image high occlusion high damage illustrate robustness wwcsc method facial recognition,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18640,llgs unsupervised gaussian splatting image enhancement reconstruction pure dark environment,"Haoran Wang, Jingwei Huang, Lu Yang, Tianchen Deng, Gaojing Zhang, Mingrui Li",gaussian splatting show remarkable capability novel view render task exhibit significant potential multi view http url original gaussian splatting lack color representation input low light environment simply use enhance image input would lead issue multi view consistency current single view enhancement system rely pre trained data lack scene generalization problem limit application gaussian splatting low light condition field robotics include high fidelity modeling feature matching address challenge propose unsupervised multi view stereoscopic system base gaussian splatting call low light gaussian splatting llgs system aim enhance image low light environment reconstruct scene method introduce decomposable gaussian representation call m color separately characterize color information targeted enhancement furthermore propose unsupervised optimization method zero knowledge prior use direction based enhancement ensure multi view consistency experiment conduct real world datasets demonstrate system outperform state of the art method low light enhancement gaussian splatting,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18637,unbiasing textual description mitigate representation bias video benchmark,"Nina Shvetsova, Arsha Nagrani, Bernt Schiele, Hilde Kuehne, Christian Rupprecht",propose new unbiased textual description utd video benchmark base unbiased subset exist video classification retrieval datasets enable robust assessment video understanding capability namely tackle problem current video benchmark may suffer different representation bias object bias single frame bias mere recognition object utilization single frame sufficient correct prediction leverage vlms llm analyze debias benchmark representation bias specifically generate frame wise textual description video filter specific information object leverage examine representation bias three dimension concept bias determine specific concept object alone suffice prediction temporal bias assess temporal information contributes prediction common sense dataset bias evaluate zero shot reasoning dataset correlation contribute prediction conduct systematic analysis popular video classification retrieval datasets create new object debiased test split datasets moreover benchmark state of the art video model original debiased split analyze bias model facilitate future development robust video understand benchmark model release utd description dataset rich structured description dataset utd splits dataset object debiased test split,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18635,occo lvm guided infrared visible image fusion framework base object aware contextual contrastive learning,"Hui Li, Congcong Bian, Zeyang Zhang, Xiaoning Song, Xi Li, Xiao-Jun Wu",image fusion crucial technique field computer vision goal generate high quality fused image improve performance downstream task however exist fusion method struggle balance two factor achieve high quality fused image may result low performance downstream visual task vice versa address drawback novel lvm large vision model  guide fusion framework object aware contextual contrastive learning propose term occo pre trained lvm utilize provide semantic guidance allow network focus solely fusion task emphasize learn salient semantic feature form contrastive learning additionally novel feature interaction fusion network also design resolve information conflict fusion image cause modality difference learn distinction positive sample negative sample latent feature space contextual space integrity target information fused image improve thereby benefit downstream performance finally compare eight state of the art method four datasets effectiveness propose method validate exceptional performance also demonstrate downstream visual task,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18631,robust lane detection wavelet enhanced context modeling adaptive sampling,"Kunyang Li, Ming Hou",lane detection critical autonomous driving ad vanced driver assistance system adas recent method clrnet achieve strong performance struggle adverse con ditions extreme weather illumination change occlusion complex curve propose wavelet enhanced feature net work we fpn address challenge wavelet based non local block integrate feature pyramid improve global context modeling especially occlude curve lane additionally de sign adaptive preprocessing module enhance lane visibility poor lighting attention guided sampling strategy reffnes spa tial feature boost accuracy distant curve lane experiment culane tusimple demonstrate approach signiffcantly outperform baseline challenge scenario achieve good robust ness accuracy real world driving condition,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18629,towards human understandable multi dimensional concept discovery,"Arne Grobrügge, Niklas Kühl, Gerhard Satzger, Philipp Spitzer",concept based explainable ai c xai aim overcome limitation traditional saliency map convert pixel human understandable concept consistent entire dataset crucial aspect c xai completeness measure well set concept explain model decision c xai method multi dimensional concept discovery mcd effectively improve completeness break cnn latent space distinct interpretable concept subspace however explanation difficult human understand raise concern practical utility address propose human understandable multi dimensional concept discovery hu mcd hu mcd use segment anything model concept identification implement cnn specific input mask technique reduce noise introduce traditional masking method change mcd pair completeness relation enable hu mcd enhance concept understandability maintain explanation faithfulness experiment include human subject study show hu mcd provide precise reliable explanation exist c xai method code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18627,dig diffusion information gain image fusion,"Bing Cao, Baoshuo Cai, Changqing Zhang, Qinghua Hu",image fusion integrate complementary information multi source image generate informative result recently diffusion model demonstrate unprecedented generative potential explore image fusion however approach typically incorporate predefined multimodal guidance diffusion fail capture dynamically change significance modality lack theoretical guarantee address issue reveal significant spatio temporal imbalance image denoising specifically diffusion model produce dynamic information gain different image region denoising step base observation dig diffusion information gain theoretically derive diffusion based dynamic image fusion framework provably reduce upper bound generalization error accordingly introduce diffusion information gain dig quantify information contribution modality different denoising step thereby provide dynamic guidance fusion process extensive experiment multiple fusion scenario confirm method outperform exist diffusion based approach term fusion quality inference efficiency,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18626,generative dataset distillation use min max diffusion model,"Junqiao Fan, Yunjiao Zhou, Min Chang Jordan Ren, Jianfei Yang",paper address problem generative dataset distillation utilize generative model synthesize image generator may produce number image preserved evaluation time work leverage popular diffusion model generator compute surrogate dataset boost min max loss control dataset diversity representativeness training however diffusion model time consuming generate image require iterative generation process observe critical trade off number image sample image quality control diffusion step propose diffusion step reduction achieve optimal performance paper detail comprehensive method performance model achieve nd place generative track http url first dataset distillation challenge demonstrate superior performance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18623,training free personalization retrieval reason fingerprint,"Deepayan Das, Davide Talon, Yiming Wang, Massimiliano Mancini, Elisa Ricci",vision language model vlms lead major improvement multimodal reasoning yet still struggle understand user specific concept exist personalization method address limitation heavily rely training procedure either costly unpleasant individual user depart exist work first time explore training free setting context personalization propose novel method retrieval reason personalization leverage internal knowledge vlms first leverage vlms extract concept fingerprint key attribute uniquely define concept semantic class query arrive similar fingerprint retrieve score chain of thought reasoning reduce risk hallucination score validate cross modal verification attribute level case discrepancy score refine concept association pairwise multimodal matching retrieved fingerprint image directly compare query validate two publicly available benchmark newly introduce dataset personal concept visual ambiguity perva concept identification highlight challenge visual ambiguity consistently outperform state of the art approach various downstream task benchmark code available upon acceptance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18589,unified uncertainty aware diffusion multi agent trajectory modeling,"Guillem Capellera, Antonio Rubio, Luis Ferraz, Antonio Agudo",multi agent trajectory modeling primarily focus forecast future state often overlook broad task trajectory completion crucial real world application correct track data exist method also generally predict agent state offer state wise measure uncertainty moreover popular multi modal sampling method lack error probability estimate generate scene prior observation make difficult rank prediction inference time introduce unified diffusion model design handle trajectory completion provide state wise uncertainty estimate jointly uncertainty estimation achieve augment simple denoising loss negative log likelihood predicted noise propagate latent space uncertainty real state space additionally incorporate rank neural network post processing enable error probability estimation generated mode demonstrate strong correlation error relative grind truth method outperform state of the art solution trajectory completion forecasting four challenge sport datasets nba basketball u football u soccer u highlight effectiveness uncertainty error probability estimation video http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18583,adapt video diffusion model time lapse microscopy,"Alexander Holmberg, Nils Mechtel, Wei Ouyang",present domain adaptation video diffusion model generate highly realistic time lapse microscopy video cell division hela cell state of the art generative video model advance significantly natural video remain underexplored microscopy domain address gap fine tune pretrained video diffusion model microscopy specific sequence explore three condition strategy text prompt derive numeric phenotypic measurement proliferation rate migration speed cell death frequency direct numeric embeddings phenotype score image conditioned generation initial microscopy frame extend complete video sequence evaluation use biologically meaningful morphological proliferation migration metric demonstrate fine tuning substantially improve realism accurately capture critical cellular behavior mitosis migration notably fine tuned model also generalize training horizon generate coherent cell dynamic even extended sequence however precisely control specific phenotypic characteristic remain challenging highlight opportunity future work enhance condition method result demonstrate potential domain specific fine tuning generative video model produce biologically plausible synthetic microscopy data support application in silico hypothesis testing data augmentation,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18567,advance cross organ domain generalization test time style transfer diversity enhancement,"Biwen Meng, Xi Long, Wanrong Yang, Ruochen Liu, Yi Tian, Yalin Zheng, Jingxin Liu",deep learning make significant progress address challenge various field include computational pathology cpath however due complexity domain shift problem performance exist model degrade especially come multi domain cross domain task paper propose test time style transfer use bidirectional mapping mechanism project feature source target domain unified feature space enhance generalization ability model increase style expression space introduce cross domain style diversification module csdm ensure orthogonality style base addition data augmentation low rank adaptation technique use improve feature alignment sensitivity enable model adapt multi domain input effectively method demonstrate effectiveness three unseen datasets,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18559,amd hummingbird towards efficient text to video model,"Takashi Isobe, He Cui, Dong Zhou, Mengmeng Ge, Dong Li, Emad Barsoum",text to video generation attract significant attention ability synthesize realistic video textual description however exist model struggle balance computational efficiency high visual quality particularly resource limited device igpus mobile phone prior work prioritizes visual fidelity overlook need small efficient model suitable real world deployment address challenge propose lightweight framework term hummingbird prune exist model enhances visual quality visual feedback learning approach reduce size u net billion billion parameter significantly improve efficiency preserve high quality video generation additionally introduce novel data processing pipeline leverage large language model llm video quality assessment vqa model enhance quality text prompt video data support user driven training style customization publicly release full training code include data processing model training extensive experiment show method achieve speedup compare state of the art model also attain high overall score vbench moreover method support generation video frame address limitation exist u net based method long video generation notably entire training process require four gpus delivers performance competitive exist lead method hummingbird present practical efficient solution generation combine high performance scalability flexibility real world application,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18557,leanstereo leaner backbone base stereo network,"Rafia Rahim, Samuel Woerz, Andreas Zell",recently end to end deep network base stereo match method mainly performance gain popularity however improvement performance come cost increased computational memory bandwidth requirement thus necessitate specialize hardware gpus even method large inference time compare classical method limit applicability real world application desire high accuracy stereo method reasonable inference time end propose fast end to end stereo match method majority speedup come integrate leaner backbone recover performance lose leaner backbone propose use learned attention weight base cost volume combine loss stereo matching use loss improve overall performance propose network also lead faster convergence detailed empirical evaluation different design choice show method require less operation also faster compare state art method acvnet leastereo cfnet give comparable performance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18556,instruction aligned visual attention mitigate hallucination large vision language model,"Bin Li, Dehong Gao, Yeyuan Wang, Linbo Jin, Shanqing Yu, Xiaoyan Cai, Libin Yang",significant success large vision language model lvlms model still suffer hallucination describe image generate answer include non existent object report model tend over focus certain irrelevant image token contain critical information answer question distort output address propose instruction aligned visual attention iava approach identify irrelevant token compare change attention weight two different instruction apply contrastive decoding dynamically adjust logits generate original image token irrelevant image token reduce model over attention irrelevant information experimental result demonstrate iava consistently outperform exist decode technique benchmark mme pope textvqa mitigate object hallucination iava approach available online http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18553,atar aerial traffic atomic activity recognition temporal segmentation dataset,"Zihao Chen, Hsuanyu Wu, Chi-Hsi Kung, Yi-Ting Chen, Yan-Tsung Peng",traffic atomic activity describe traffic pattern topological intersection dynamic crucial topic advancement intelligent drive system however exist atomic activity datasets collect egocentric view support scenario traffic activity entire intersection require moreover exist datasets provide video level atomic activity annotation require exhaust effort manually trim video recognition limit application untrimmed video bridge gap introduce aerial traffic atomic activity recognition segmentation atar dataset first aerial dataset design multi label atomic activity analysis offer atomic activity label frame accurately record interval traffic activity moreover propose novel task multi label temporal atomic activity recognition enable study accurate temporal localization atomic activity ease burden manual video trim recognition conduct extensive experiment evaluate exist state of the art model atomic activity recognition temporal atomic activity segmentation result highlight unique challenge atar dataset recognize extremely small object activity provide comprehensive discussion analyze challenge offer valuable insight future direction improve recognize atomic activity aerial view source code dataset available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18552,evanimate event conditioned image to video generation human animation,"Qiang Qu, Ming Li, Xiaoming Chen, Tongliang Liu",conditional human animation transform static reference image dynamic sequence apply motion cue pose motion cue typically derive video data susceptible limitation include low temporal resolution motion blur overexposure inaccuracy low light condition contrast event camera provide data stream exceptionally high temporal resolution wide dynamic range inherent resistance motion blur exposure issue work propose evanimate framework leverage event stream motion cue animate static human image approach employ specialized event representation transform asynchronous event stream slice controllable slice rate appropriate slice density ensure compatibility diffusion model subsequently dual branch architecture generate high quality video harness inherent motion dynamic event stream thereby enhance video quality temporal consistency specialize data augmentation strategy enhance cross person generalization finally establish new benchmarking include simulated event data training validation real world event dataset capture human action normal extreme scenario experiment result demonstrate evanimate achieves high temporal fidelity robust performance scenario traditional video derived cue fall short,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18548,benchmarking post hoc unknown category detection food recognition,"Lubnaa Abdur Rahman, Ioannis Papathanail, Lorenzo Brigato, Stavroula Mougiakakou",food recognition model often struggle distinguish see unseen sample frequently misclassifying sample unseen category assign in distribution id label misclassification present significant challenge deploy model real world application particularly automatic dietary assessment system incorrect label lead cascade error system ideally model prompt user unknown sample encounter allow corrective action give prior research explore food recognition real world setting work conduct empirical analysis various post hoc out of distribution ood detection method fine grained food recognition finding indicate virtual logit matching vim perform best overall likely due combination logits feature space representation additionally work reinforces prior notion ood domain note model high id accuracy perform good evaluated ood detection method furthermore transformer based architecture consistently outperform convolution based model detect ood sample various method,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18544,distil stereo network performant efficient leaner network,"Rafia Rahim, Samuel Woerz, Andreas Zell",knowledge distillation quite popular vision task classification segmentation however much work do distil state of the art stereo match method range application one reason lack use stereo matching network due inherent complexity network typical network compose multiple two  three dimensional module work systematically combine insight state of the art stereo method general knowledge distillation technique develop joint framework stereo network distillation competitive result fast inference moreover show detailed empirical analysis distil knowledge stereo network require careful design complete distillation pipeline start backbone right selection distillation point corresponding loss function result student network leaner faster give excellent performance instance student network perform good performance orient method psmnet cfnet leastereo benchmark sceneflow dataset faster respectively furthermore compare speed orient method inference time less student network perform good test method addition student network also show good generalization capability test unseen datasets middlebury,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18541,unipcgc towards practical point cloud geometry compression efficient unified approach,"Kangli Wang, Wei Gao",learning based point cloud compression method make significant progress term performance however method still encounter challenge include high complexity limited compression mode lack support variable rate restrict practical application method order promote development practical point cloud compression propose efficient unified point cloud geometry compression framework dub unipcgc lightweight framework support lossy compression lossless compression variable rate variable complexity first introduce uneven lossless coder uelc lossless mode allocate computational complexity group high coding difficulty merges group low coding difficulty second variable rate complexity module vrcm achieve lossy mode joint adoption rate modulation module dynamic sparse convolution finally dynamic combination uelc vrcm achieve lossy compression lossless compression variable rate complexity unified framework compare previous state of the art method method achieve compression ratio cr gain lossless compression bjontegaard delta rate bd rate gain lossy compression also support variable rate variable complexity,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18540,hire fusedmim high resolution rgb dsm pre trained model building level remote sensing application,"Guneet Mutreja, Philipp Schuegraf, Ksenia Bittner",recent advance self supervised learning lead development foundation model significantly advance performance various computer vision task however potential model often overlook crucial role high resolution digital surface model dsms understand urban environment particularly building level analysis essential application digital twin address gap introduce hires fusedmim novel pre trained model specifically design leverage rich information contain high resolution rgb dsm data hire fusedmim utilize dual encoder simple mask image modeling simmim architecture multi objective loss function combine reconstruction contrastive objective enable learn powerful joint representation modality conduct comprehensive evaluation hire fusedmim diverse set downstream task include classification semantic segmentation instance segmentation result demonstrate hire fusedmim outperforms previous state of the art geospatial method several building related datasets include whu aerial loveda demonstrate effectiveness capture leverage fine grained building information incorporate dsms pre training consistently improve performance compare use rgb data alone highlight value elevation information building level analysis dual encoder architecture hire fusedmim separate encoders rgb dsm data significantly outperform single encoder model vaihingen segmentation task indicate benefit learn specialized representation modality facilitate research application direction publicly release trained model weight,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18536,din diffusion model robust medical vqa semantic noisy label,"Erjian Guo, Zhen Zhao, Zicheng Wang, Tong Chen, Yunyi Liu, Luping Zhou",medical visual question answer med vqa system benefit interpretation medical image contain critical clinical information however challenge noisy label limited high quality datasets remain underexplored address establish first benchmark noisy label med vqa simulate human mislabeling semantically design noise type importantly introduce din framework leverage diffusion model handle noisy label med vqa dominant classification based vqa approach directly predict answer answer diffuser ad module employ coarse to fine process refine answer candidate diffusion model improved accuracy answer condition generator acg enhance process generate task specific conditional information integrate answer embeddings fused image question feature address label noise noisy label refinement nlr module introduce robust loss function dynamic answer adjustment boost performance ad module,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18527,aerial image building point cloud reconstruction,"Soulaimene Turki, Daniel Panangian, Houda Chaabouni-Chouayakh, Ksenia Bittner",three dimensional urban reconstruction building single view image attract significant attention past two decade however recent method primarily focus rooftop aerial image often overlook essential geometrical detail additionally notable lack datasets contain complete point cloud entire building challenge obtain reliable camera pose information aerial image paper address challenge present novel methodology utilize generated dataset include complete point cloud determine camera pose approach take feature single aerial image input concatenate essential additional condition binary mask sobel edge map enable edge aware reconstruction incorporate point cloud diffusion model base centered denoising diffusion probabilistic model cdpm project concatenate feature partially denoised point cloud use camera pose diffusion step propose method able reconstruct complete building point cloud include wall information demonstrate superior performance compare exist baseline technique allow comparison methodology dataset make available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18513,lookcloser frequency aware radiance field tiny detail scene,"Xiaoyu Zhang, Weihong Pan, Chong Bao, Xiyu Zhang, Xiaojun Xiang, Hanqing Jiang, Hujun Bao",human perceive comprehend surroundings information span multiple frequency immersive scene people naturally scan environment grasp overall structure examine fine detail object capture attention however current nerf framework primarily focus model high frequency local view broad structure scene low frequency information limit balance introduce fa nerf novel frequency aware framework view synthesis simultaneously capture overall scene structure high definition detail single nerf model achieve propose frequency quantification method analyze scene frequency distribution enable frequency aware rendering framework incorporate frequency grid fast convergence querying frequency aware feature re weighting strategy balance feature different frequency content extensive experiment show method significantly outperform exist approach model entire scene preserve fine detail,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18512,uncertainty guided perturbation image super resolution diffusion model,"Leheng Zhang, Weiyi You, Kexuan Shi, Shuhang Gu",diffusion based image super resolution method demonstrate significant advantage gan based approach particularly term perceptual quality building lengthy markov chain diffusion based method possess remarkable modeling capacity enable achieve outstanding performance real world scenario previous method focus modify noise schedule sample process enhance performance approach emphasize improved utilization lr information find different region lr image view correspond different timesteps diffusion process flat area close target hr distribution edge texture region far away flat area apply slight noise advantageous reconstruction associate characteristic uncertainty propose apply uncertainty estimate guide region specific noise level control technique refer uncertainty guided noise weighting pixel low uncertainty flat region receive reduce noise preserve lr information therefore improve performance furthermore modify network architecture previous method develop uncertainty guided perturbation super resolution upsr model extensive experimental result demonstrate reduce model size training overhead propose uwsr method outperform current state of the art method various datasets quantitatively qualitatively,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18507,text to video generation help video language alignment,"Luca Zanella, Massimiliano Mancini, Willi Menapace, Sergey Tulyakov, Yiming Wang, Elisa Ricci",recent video language alignment model train set video associate positive caption negative caption generate large language model problem procedure negative caption may introduce linguistic bias concept see negative never associate video solution would collect video negative caption exist database lack fine grained variation need cover possible negative work study synthetic video help overcome issue preliminary analysis multiple generator show promise task synthetic video harm performance model others hypothesize issue link noise semantic visual generated video develop method synvita account synvita dynamically weight contribution synthetic video base similar target caption real counterpart moreover semantic consistency loss make model focus fine grained difference caption rather difference video appearance experiment show average synvita improve exist method videocon test set atp hard benchmark first promising step use synthetic video learn video language model,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18484,parallel multilingual multi modal multi task benchmark large vision language model,"Junyuan Gao, Jiahe Song, Jiang Wu, Runchuan Zhu, Guanlin Shen, Shasha Wang, Xingjian Wei, Haote Yang, Songyang Zhang, Weijia Li, Bin Wang, Dahua Lin, Lijun Wu, Conghui He",exist multilingual benchmark large vision language model lvlms suffer limitation include language specific content bias disjoint multimodal input format lack safety evaluation address gap propose first parallel multilingual multi modal multi task benchmark lvlms feature parallel corpus design language enable fair accurate cross lingual comparison include vision set text query embed image require lvlms simultaneously see read think align real world application additionally bench incorporates safety evaluation address critical oversight exist multilingual benchmark use evaluate mainstream lvlms reveal significant cross linguistic performance disparity particularly vision setting identify ocr capability key determinant imbalance release http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18483,explain domain shift language concept erase interpretable image classification,"Zequn Zeng, Yudi Su, Jianqiao Sun, Tiansheng Wen, Hao Zhang, Zhengjue Wang, Bo Chen, Hongwei Liu, Jiawei Ma",concept based model map black box representation human understandable concept make decision making process transparent allow user understand reason prediction however domain specific concept often impact final prediction subsequently undermine model generalization capability prevent model use high stake application paper propose novel language guided concept erasing lance framework particular empirically demonstrate pre trained vision language model vlms approximate distinct visual domain shift domain descriptor prompt large language model llm easily simulate wide range descriptor unseen visual domain introduce novel plug in domain descriptor orthogonality ddo regularizer mitigate impact domain specific concept final prediction notably ddo regularizer agnostic design concept based model integrate several prevailing model evaluation domain generalization four standard benchmark three newly introduce benchmark demonstrate ddo significantly improve out of distribution ood generalization previous state of the art concept based http url code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18478,video xl pro reconstructive token compression extremely long video understanding,"Xiangrui Liu, Yan Shu, Zheng Liu, Ao Li, Yang Tian, Bo Zhao",advanced token compression technique exist multimodal large language model mllms still struggle hour long video understanding work propose video xl pro efficient method extremely long video understanding build reconstructive compression token recot learnable module leverage self supervised learning generate comprehensive compact video token recot introduces two key component dynamic token synthesizer dts dts generate pseudo video token static image token learn intra token relationship use masked video modeling ii semantic guided masking sgm sgm adaptively masks redundant visual token facilitate effective reconstructive learning improve training efficiency mllms fine tuning introduce video specific dataset pruning strategy design simple yet query aware selector enable model precisely locate query relevant video token parameter video xl pro outperforms model train large datasets multiple long video understanding benchmark moreover process frame single gpu maintain high quality performance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18476,global local tree search language guide scene generation,"Wei Deng, Mengshi Qi, Huadong Ma",large vision language model vlms achieve remarkable success various field however study indoor scene generation vlms paper consider task planning problem subject spatial layout common sense constraint solve problem vlm propose new global local tree search algorithm globally method place object sequentially explore multiple placement placement process problem space represent tree reduce depth tree decompose scene structure hierarchically room level region level floor object level support object level algorithm independently generate floor object different region support object place different floor object locally also decompose sub task placement object multiple step algorithm search tree problem space leverage vlm model produce position object discretize top down view space dense grid fill cell diverse emojis make cell distinct prompt vlm emoji grid vlm produce reasonable location object describe position name emojis quantitative qualitative experimental result illustrate approach generate plausible scene state of the art approach source code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18470,metaspatial reinforce spatial reasoning vlms metaverse,"Zhenyu Pan, Han Liu",present metaspatial first reinforcement learning rl  base framework design enhance spatial reason vision language model vlms enable real time scene generation need hard coded optimization metaspatial address two core challenge lack internalized spatial reasoning vlms limit ability generate realistic layout ii inefficiency traditional supervise fine tuning sft layout generation task perfect ground truth annotation unavailable key innovation multi turn rl based optimization mechanism integrate physics aware constraint render image evaluation ensure generate layout coherent physically plausible aesthetically consistent methodologically metaspatial introduces adaptive iterative reasoning process vlm refine spatial arrangement multiple turn analyze render output improve scene coherence progressively empirical evaluation demonstrate metaspatial significantly enhance spatial consistency format stability various scale model post training object placement realistic align functionally coherent validate effectiveness rl spatial reasoning metaverse digital twin game development application code data training pipeline publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18469,cfreid continual few shot person re identification,"Hao Ni, Lianli Gao, Pengpeng Zeng, Heng Tao Shen, Jingkuan Song",real world surveillance system dynamically evolve require person re identification model continuously handle newly incoming data various domain cope dynamic lifelong reid lreid propose learn accumulate knowledge multiple domain incrementally however lreid model need train large scale label data unseen domain typically inaccessible due privacy cost concern paper propose new paradigm call continual few shot reid cfreid require model incrementally trained use few shot data test see domain few shot condition cfreid face two core challenge learn knowledge few shot data unseen domain avoid catastrophic forgetting see domain tackle two challenge propose stable distribution alignment sda framework feature distribution perspective specifically sda compose two module meta distribution alignment mda prototype based few shot adaptation pfa support study cfreid establish evaluation benchmark cfreid five publicly available reid datasets extensive experiment demonstrate sda enhance few shot learning anti forgetting capability few shot condition notably approach use data id significantly outperform lreid state of the art performance require id,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18463,sit fer integration semantic  instance  text level information semi supervised facial expression recognition,"Sixian Ding, Xu Jiang, Zhongjing Du, Jiaqi Cui, Xinyi Zeng, Yan Wang",semi supervised deep facial expression recognition s dfer gain increasingly research interest due difficulty access sufficient label data practical setting however exist s dfer method mainly utilize generated semantic level pseudo label supervised learning unreliability compromise performance undermine practical utility paper propose novel s dfer framework simultaneously incorporate semantic instance text level information generate high quality pseudo label specifically unlabeled data consider comprehensive knowledge textual description instance representation respectively calculate similarity facial vision feature corresponding textual instance feature obtain probability text  instance level combine semantic level probability three level probability elaborately aggregate gain final pseudo label furthermore enhance utilization one hot label label data also incorporate text embeddings excavate textual description co supervise model training enable facial visual feature exhibit semantic correlation text space experiment three datasets demonstrate method significantly outperform current state of the art s dfer method even exceeds fully supervise baseline code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18461,muma pbr texturing multi channel multi view generation agentic post processing,"Lingting Zhu, Jingrui Ye, Runze Zhang, Zeyu Hu, Yingda Yin, Lanjiong Li, Jinnan Chen, Shengju Qian, Xin Wang, Qingmin Liao, Lequan Yu",current method generation still fall short physically base rendering pbr texturing primarily due limited data challenge model multi channel material work propose muma method pbr texturing multi channel multi view generation agentic post processing approach feature two key innovation opt model shaded albedo appearance channel shaded channel enable integration intrinsic decomposition module material property leverage multimodal large language model emulate artist technique material assessment selection experiment demonstrate muma achieves superior result visual quality material fidelity compare exist method,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18459,hide image diffusion model edit learn score function,"Haoyu Chen, Yunqiao Yang, Nan Zhong, Kede Ma",hide data use neural network neural steganography achieve remarkable success discriminative classifier generative adversarial network however potential data hide diffusion model remain relatively unexplored current method exhibit limitation achieve high extraction accuracy model fidelity hide efficiency due primarily entanglement hiding extraction process multiple denoising diffusion step address describe simple yet effective approach embed image specific timesteps reverse diffusion process edit learn score function additionally introduce parameter efficient fine tuning method combine gradient based parameter selection low rank adaptation enhance model fidelity hiding efficiency comprehensive experiment demonstrate method extract high quality image human indistinguishable level replicate original model behavior sample population level embeds image order magnitude faster prior method besides method naturally support multi recipient scenario independent extraction channel,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18458,stablegs floater free framework gaussian splatting,"Luchao Wang, Qian Ren, Kaiming He, Hua Wang, Zhi Chen, Yaohua Tang",recent year witness remarkable success gaussian splatting novel view synthesis surpass prior differentiable render method quality efficiency however training process suffers couple opacity color optimization frequently converge local minimum produce floater artifact degrade visual fidelity present stablegs framework eliminate floater cross view depth consistency constraint introduce dual opacity g model decouple geometry material property translucent object enhance reconstruction quality weakly textured region integrate depth estimation significantly improve geometric stability method fundamentally address training instability outperform exist state of the art method open source datasets,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18454,inpo inversion preference optimization reparametrized ddim efficient diffusion model alignment,"Yunhong Lu, Qichao Wang, Hengyuan Cao, Xierui Wang, Xiaoyin Xu, Min Zhang",use explicit reward direct preference optimization dpo employ paired human preference data fine tune generative model method garner considerable attention large language model llm however exploration align text to image diffusion model human preference remain limited comparison supervise fine tuning exist method align diffusion model suffer low training efficiency subpar generation quality due long markov chain process intractability reverse process address limitation introduce ddim inpo efficient method direct preference alignment diffusion model approach conceptualize diffusion model single step generative model allow fine tune output specific latent variable selectively order accomplish objective first assign implicit reward latent variable directly reparameterization technique construct inversion technique estimate appropriate latent variable preference optimization modification process enable diffusion model fine tune output latent variable strong correlation preference dataset experimental result indicate ddim inpo achieves state of the art performance step fine tuning surpass preference align baseline diffusion model human preference evaluation task,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18446,latent space super resolution higher resolution image generation diffusion model,"Jinho Jeong, Sangmin Han, Jinwoo Kim, Seon Joo Kim",paper propose lsrna novel framework higher resolution exceed image generation use diffusion model leverage super resolution directly latent space exist diffusion model struggle scale training resolution often lead structural distortion content repetition reference based method issue upsampling low resolution reference guide higher resolution generation however face significant challenge upsampling latent space often cause manifold deviation degrade output quality hand upsampling rgb space tends produce overly smooth output overcome limitation lsrna combine latent space super resolution lsr manifold alignment region wise noise addition rna enhance high frequency detail extensive experiment demonstrate integrate lsrna outperforms state of the art reference based method various resolution metric show critical role latent space upsampling preserve detail sharpness code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18445,benchmarking multi modal semantic segmentation sensor failure missing noisy modality robustness,"Chenfei Liao, Kaiyu Lei, Xu Zheng, Junha Moon, Zhixiong Wang, Yixuan Wang, Danda Pani Paudel, Luc Van Gool, Xuming Hu",multi modal semantic segmentation mmss address limitation single modality data integrate complementary information modality notable progress significant gap persist research real world deployment due variability uncertainty multi modal data quality robustness thus become essential practical mmss application however absence standardized benchmark evaluate robustness hinders advancement address first survey exist mmss literature categorize representative method provide structured overview introduce robustness benchmark evaluate mmss model three scenario entire missing modality emm random missing modality rmm noisy modality nm probabilistic standpoint model modality failure two condition damage combination equally probable modality fail independently follow bernoulli distribution base propose four metrics  avg emm e emm avg rmm e rmm  to assess model robustness emm rmm work provide first dedicate benchmark mmss robustness offer new insight tool advance field source code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18438,harmonizing generative reconstructive model drive scene representation,"Guosheng Zhao, Xiaofeng Wang, Chaojun Ni, Zheng Zhu, Wenkang Qin, Guan Huang, Xingang Wang",combine reconstruction model generative model emerge promising paradigm closed loop simulation autonomous driving example recondreamer demonstrate remarkable success render large scale maneuver however significant gap remain generate data real world sensor observation particularly term fidelity structured element ground surface address challenge propose enhanced framework significantly improve overall rendering quality mitigate domain gap refine representation ground surface specifically introduces novel trajectory deformable network ntdnet leverage learnable spatial deformation mechanism bridge domain gap synthesize novel view original sensor observation moreover structured element ground surface preserve geometric prior knowledge gaussians optimization process focus refine appearance attribute preserve underlie geometric structure experimental evaluation conduct multiple datasets waymo nuscenes pandaset euvs confirm superior performance specifically waymo achieves performance comparable street gaussians original trajectory significantly outperform recondreamer novel trajectory particular achieve substantial improvement include increase nta iou improvement fid remarkable gain ground surface metric ntl iou highlight effectiveness accurately reconstruct structure element road surface,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18435,perception bottleneck vlms chart understanding,"Junteng Liu, Weihao Zeng, Xiwen Zhang, Yijun Wang, Zifei Shan, Junxian He",chart understand require model effectively analyze reason numerical data textual element complex visual component observation reveal perception capability exist large vision language model lvlms constitute critical bottleneck process study delve perception bottleneck decompose two component vision encoder bottleneck visual representation may fail encapsulate correct information extraction bottleneck language model struggle extract necessary information provide visual representation comprehensive experiment find information embed visual representation substantially rich typically capture linear extractor widely use retrieval accuracy metric instruction tune effectively enhance extraction capability lvlms vision encoder remain critical bottleneck demand focused attention improvement therefore enhance visual encoder mitigate vision encoder bottleneck contrastive learning framework empirical result demonstrate approach significantly mitigate perception bottleneck improve ability lvlms comprehend chart code publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18434,simple yet effective layout token large language model document understanding,"Zhaoqing Zhu, Chuwei Luo, Zirui Shao, Feiyu Gao, Hangdi Xing, Qi Zheng, Ji Zhang",recent method integrate spatial layout text document understanding large language model llm show promising result commonly use method represent layout information text token interleave text content input llm however method still demonstrate limitation require additional position id token use represent layout information due constraint max position id assign layout information reduces available text content reduce capacity model learn text training also introduce large number potentially untrained position id long context inference hinder performance document understanding task address issue propose laytokenllm simple yet effective method document understanding laytokenllm represent layout information single token text segment use specialized positional encode scheme share position id text layout token eliminate need additional position id design maintain model capacity learn text mitigate long context issue inference furthermore novel pre training objective call next interleaved text layout token prediction ntlp devise enhance cross modality learn text layout token extensive experiment show laytokenllm outperforms exist layout integrated llm mllms similar scale multi page document understand task well single page task,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18430,cq dino mitigating gradient dilution category query vast vocabulary object detection,"Zhichao Sun, Huazhang Hu, Yidong Ma, Gang Liu, Nemo Chen, Xu Tang, Yongchao Xu",exponential growth data traditional object detection method increasingly struggle handle vast vocabulary object detection task effectively analyze two key limitation classification based detector positive gradient dilution rare positive category receive insufficient learning signal hard negative gradient dilution discriminative gradient overwhelm numerous easy negative address challenge propose cq dino category query based object detection framework reformulate classification contrastive task object query learnable category query method introduces image guided query selection reduce negative space adaptively retrieve top k relevant category image cross attention thereby rebalancing gradient distribution facilitate implicit hard example mining furthermore cq dino flexibly integrate explicit hierarchical category relationship structured datasets learn implicit category correlation self attention generic datasets coco experiment demonstrate cq dino achieves superior performance challenge benchmark surpass previous method ap maintain competitiveness coco work provide scalable solution real world detection system require wide category coverage dataset code publicly http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18429,teller real time stream audio driven portrait animation autoregressive motion generation,"Dingcheng Zhen, Shunshun Yin, Shiyang Qin, Hou Yi, Ziwei Zhang, Siyuan Liu, Gan Qi, Ming Tao",work introduce first autoregressive framework real time audio driven portrait animation talk head challenge lengthy animation time critical challenge realistic talk head generation lie preserve natural movement diverse body part end propose teller first stream audio driven protrait animation framework autoregressive motion generation specifically teller first decompose facial body detail animation two component facial motion latent generation fmlg base autoregressive transfromer movement authenticity refinement use efficient temporal module etm fmlg employ residual vq model map facial motion latent implicit keypoint based model discrete motion token temporally slice audio embeddings enable ar tranformer learn real time stream based mapping audio motion furthermore teller incorporate etm capture fine motion detail module ensure physical consistency body part accessory neck muscle earring improve realism movement teller design efficient surpass inference speed diffusion based model hallo teller one second video generation achieve real time streaming performance fps extensive experiment demonstrate method outperform recent audio driven portrait animation model especially small movement validate human evaluation significant margin quality realism,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18422,break encoder barrier seamless video language understanding,"Handong Li, Yiyuan Zhang, Longteng Guo, Xiangyu Yue, Jing Liu",video large language model video llm adopt encoder decoder framework vision encoder extract frame wise feature processing language model however approach incur high computational cost introduces resolution bias struggle capture fine grained multimodal interaction overcome limitation propose elva encoder free video llm directly model nuanced video language interaction rely vision encoder employ token merge construct bottom up hierarchical representation incorporate video guidance supervisor direct spatiotemporal representation learning additionally hybrid resolution mechanism strategically integrate high  low resolution frame input achieve optimal balance performance efficiency publicly available video text pair elva achieves performance par encoder based video llm reduce flop inference latency offer scalable efficient solution real time video understanding,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18421,rate aware gaussian compression efficient streamable free viewpoint video,"Qiang Hu, Zihan Zheng, Houqiang Zhong, Sihua Fu, Li Song, XiaoyunZhang, Guangtao Zhai, Yanfeng Wang",gaussian splatting substantial potential enable photorealistic free viewpoint video fvv experience however vast number gaussians associate attribute pose significant challenge storage transmission exist method typically handle dynamic representation compression separately neglect motion information rate distortion rd trade off training lead performance degradation increase model redundancy address gap propose novel rate aware gaussian compression framework significantly reduce storage size maintain superior rd performance fvv specifically introduces motion aware dynamic gaussian representation utilize compact motion grid combine sparse compensate gaussians exploit inter frame similarity representation effectively handle large motion preserve quality reduce temporal redundancy furthermore present end to end compression scheme employ differentiable quantization tiny implicit entropy model compress motion grid compensated gaussians efficiently entire framework jointly optimize use rate distortion trade off extensive experiment demonstrate support variable bitrates consistently outperform exist method rd performance multiple datasets,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18420,panorama generation nfov image do right,"Dian Zheng, Cheng Zhang, Xiao-Ming Wu, Cao Li, Chengfei Lv, Jian-Fang Hu, Wei-Shi Zheng",generate panorama narrow field view nfov image promising computer vision task virtual reality vr application exist method mostly generated panorama inceptionnet clip base metric tend perceive image quality suitable evaluate distortion work first propose distortion specific clip name distort clip accurately evaluate panorama distortion discover visual cheating phenomenon previous work tend improve visual result sacrifice distortion accuracy phenomenon arise prior method employ single network learn distinct panorama distortion content completion lead model prioritize optimize latter address phenomenon propose panodecouple decoupled diffusion model framework decouple panorama generation distortion guidance content completion aim generate panorama accurate distortion visual appeal specifically design distortnet distortion guidance impose panorama specific distortion prior modified condition registration mechanism contentnet content completion impose perspective image information additionally distortion correction loss function distort clip introduce constrain distortion explicitly extensive experiment validate panodecouple surpasses exist method distortion visual metric,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18414,u repa aligning diffusion u net vits,"Yuchuan Tian, Hanting Chen, Mengyu Zheng, Yuchen Liang, Chao Xu, Yunhe Wang",representation alignment repa align diffusion transformer dit hide state vit visual encoders prove highly effective dit training demonstrate superior convergence property validate canonical diffusion u net architecture show fast convergence compare dit however adapt repa u net architecture present unique challenge different block functionality necessitate revise alignment strategy spatial dimension inconsistency emerge u net spatial downsampling operation space gap u net vit hinder effectiveness tokenwise alignment encounter challenge propose u repa representation alignment paradigm bridge u net hidden state vit feature follow firstly propose observation due skip connection middle stage u net best alignment option secondly propose upsampling u net feature pass mlps thirdly observe difficulty perform tokenwise similarity alignment introduces manifold loss regularize relative similarity sample experiment indicate result u repa could achieve excellent generation quality greatly accelerate convergence speed cfg guidance interval u repa could reach fid epoch iteration imagenet need half total epoch perform good repa code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18408,fast physically based neural explicit surface relightable human avatar,"Jiacheng Wu, Ruiqi Zhang, Jie Chen, Hui Zhang",efficiently model relightable human avatar sparse view video crucial application current method use neural implicit representation capture dynamic geometry reflectance incur high cost due need dense sampling volume render overcome challenge introduce physically based neural explicit surface phynes employ compact neural material map base neural explicit surface ne representation phynes human model compact space enhance material disentanglement efficiency connect sign distance field explicit surface phynes enables efficient geometry inference parameterized human shape model approach model dynamic geometry texture material map neural representation enable efficient rasterization phynes effectively capture physical surface attribute vary illumination enable real time physically based rendering experiment show phynes achieves relighting quality comparable sota method significantly improve render speed memory efficiency reconstruction quality,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18407,vtd clip video to text discretization prompt clip,"Wencheng Zhu, Yuexin Wang, Hongxuan Li, Pengfei Zhu, Danqing Song, Qinghua Hu",vision language model bridge visual linguistic understanding prove powerful video recognition task exist approach primarily rely parameter efficient fine tuning image text pre trained model yet often suffer limited interpretability poor generalization due inadequate temporal modeling address propose simple yet effective video to text discretization framework method repurposes frozen text encoder construct visual codebook video class label due many to one contrastive alignment visual textual embeddings multimodal pretraining codebook effectively transform temporal visual data textual token feature lookup offer interpretable video representation explicit video modeling enhance robustness irrelevant noisy frame introduce confidence aware fusion module dynamically weight keyframes assess semantic relevance codebook furthermore method incorporate learnable text prompt conduct adaptive codebook update extensive experiment validate superiority approach achieve competitive improvement state of the art method code publicly available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18406,instruct clip improve instruction guided image edit automate data refinement use contrastive learning,"Sherry X. Chen, Misha Sra, Pradeep Sen",natural language instruction offer intuitive way guide automated image editing deep learning model often struggle achieve high quality result largely due challenge create large high quality training datasets previous work typically rely text toimage generative model produce pair original edited image simulate instruction guided image editing model however image pair often fail align specify edit instruction due limitation model negatively impact model train datasets address present instruct clip self supervised method learn semantic change original edited image refine good align instruction exist datasets furthermore adapt instruct clip handle noisy latent image diffusion timesteps use train latent diffusion model ldms efficiently enforce alignment edit instruction image change latent space step diffusion pipeline use instruct clip correct dataset get refined sample use fine tune model guide novel instruct clip based loss function result model produce edits aligned give instruction code dataset available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18405,offline meteorology pollution couple global air pollution forecast model bilinear pooling,"Xu Fan, Yuetan Lin, Bing Gong, Hao Li",air pollution become major threat human health make accurate forecasting crucial pollution control traditional physics based model forecast global air pollution couple meteorology pollution process use online offline method depend fully integrate meteorological model run simultaneously however high computational demand method severely limit real time prediction efficiency exist deep learning dl solution employ online coupling strategy global air pollution forecasting finetune pollution forecasting base pretrained atmospheric model require substantial training resource study pioneer dl based offline couple framework utilize bilinear pool achieve offline couple meteorological field pollutant propose model require parameter dl based online couple model achieve competitive performance compare state of the art global air pollution forecast model cam approach demonstrate superiority variable forecast time step variable prediction exceed hour work pioneer experimental validation effectiveness meteorological field dl based global air pollution forecasting demonstrate offline couple meteorological field pollutant achieve relative reduction rmse pollution variable research establish new paradigm real time global air pollution warn system delivers critical technical support develop efficient comprehensive ai powered global atmospheric forecasting framework,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18403,knowledge graph enhance generative multi modal model class incremental learning,"Xusheng Cao, Haori Lu, Linlan Huang, Fei Yang, Xialei Liu, Ming-Ming Cheng",continual learning computer vision face critical challenge catastrophic forgetting model struggle retain prior knowledge adapt new task recent study attempt leverage generalization capability pre trained model mitigate overfitting current task model still tend forget detail previously learn category task progress lead misclassification address limitation introduce novel knowledge graph enhance generative multi modal model kg gmm build evolve knowledge graph learning process approach utilizes relationship knowledge graph augment class label assigns different relation similar category enhance model differentiation test propose knowledge graph augment inference method locate specific category analyze relationship generated text thereby reduce loss detailed information old class learn new knowledge alleviate forgetting experiment demonstrate method effectively leverage relational information help model correct mispredictions achieve state of the art result conventional cil few shot cil setting confirm efficacy knowledge graph preserve knowledge continual learning scenario,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18402,dashgaussian optimize gaussian splatting second,"Youyu Chen, Junjun Jiang, Kui Jiang, Xiao Tang, Zhihao Li, Xianming Liu, Yinyu Nie",gaussian splatting render pixel rasterize gaussian primitive rendering resolution primitive number conclude optimization complexity dominate time cost primitive optimization paper propose dashgaussian scheduling scheme optimization complexity strip redundant complexity accelerate optimization specifically formulate optimization progressively fit high level frequency component training view propose dynamic rendering resolution scheme largely reduce optimization complexity base formulation besides argue specific render resolution cooperate proper primitive number good balance compute redundancy fitting quality schedule growth primitive synchronize render resolution extensive experiment show method accelerate optimization various backbone average preserve rendering quality,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18393,pddm pseudo depth diffusion model rgb pd semantic segmentation base complex indoor scene,"Xinhua Xu, Hong Liu, Jianbing Wu, Jinfu Liu",integration rgb depth modality significantly enhance accuracy segment complex indoor scene depth data rgb d camera play crucial role improvement however collect rgb d dataset expensive rgb dataset due need specialized depth sensor align depth rgb image also pose challenge due sensor positioning issue miss data noise contrast pseudo depth pd high precision depth estimation algorithm eliminate dependence rgb d sensor alignment process well provide effective depth information show significant potential semantic segmentation therefore explore practicality utilize pseudo depth instead real depth semantic segmentation design rgb pd segmentation pipeline integrate rgb pseudo depth propose pseudo depth aggregation module pdam fully exploit informative clue provide diverse pseudo depth map pdam aggregate multiple pseudo depth map single modality make easily adaptable rgb d segmentation method addition pre trained diffusion model serve strong feature extractor rgb segmentation task multi modal diffusion based segmentation method remain unexplored therefore present pseudo depth diffusion model pddm adopt large scale text image diffusion model feature extractor simple yet effective fusion strategy integrate pseudo depth verify applicability pseudo depth pddm perform extensive experiment sunrgb d datasets experimental result demonstrate pseudo depth effectively enhance segmentation performance pddm achieves state of the art performance outperform method miou miou sunrgb d,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18386,resource efficient motion control video generation dynamic mask guidance,"Sicong Feng, Jielong Yang, Li Peng",recent advance diffusion model bring new vitality visual content creation however current text to video generation model still face significant challenge high training cost substantial data requirement difficulty maintain consistency give text motion foreground object address challenge propose mask guided video generation control video generation mask motion sequence require limited training data model enhance exist architecture incorporate foreground mask precise text position matching motion trajectory control mask motion sequence guide video generation process maintain consistent foreground object sequence additionally first frame sharing strategy autoregressive extension approach achieve stable long video generation extensive qualitative quantitative experiment demonstrate approach excel various video generation task video editing generate artistic video outperform previous method term consistency quality generated result view supplementary material,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18384,lidar remote sense meet weak supervision concept method perspective,"Yuan Gao, Shaobo Xia, Pu Wang, Xiaohuan Xi, Sheng Nie, Cheng Wang",lidar light detection range enable rapid accurate acquisition three dimensional spatial data widely apply remote sense area surface mapping environmental monitoring urban modeling forestry inventory lidar remote sense primarily include data interpretation lidar based inversion however lidar interpretation typically rely dense precise annotation costly time consuming similarly lidar inversion depend scarce supervisory signal expensive field survey annotation address challenge weakly supervise learning gain significant attention recent year many method emerge tackle lidar remote sense task use incomplete inaccurate inexact annotation well annotation domain exist review article treat lidar interpretation inversion separate task review first time adopt unified weakly supervise learn perspective systematically examine research lidar interpretation inversion summarize late advancement provide comprehensive review development application weakly supervise technique lidar remote sensing discuss potential future research direction field,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18382,pp formulanet bridging accuracy efficiency advanced formula recognition,"Hongen Liu, Cheng Cui, Yuning Du, Yi Liu, Gang Pan",formula recognition important task document intelligence involve convert mathematical expression document image structure symbolic format computer easily work latex common format use purpose work present pp formulanet state of the art formula recognition model excel accuracy efficiency meet diverse need application develop two specialized model pp formulanet l tailor high accuracy scenario pp formulanet s optimize high efficiency context extensive evaluation reveal pp formulanet l attains accuracy level surpass prominent model unimernet significant conversely pp formulanet s operates speed time faster advancement facilitate seamless integration pp formulanet broad spectrum document processing environment involve intricate mathematical formula furthermore introduce formula mining system capable extract vast amount high quality formula data system enhance robustness applicability formula recognition model code model publicly available paddleocr http url paddlex http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18378,explore state space model wavelet domain infrared visible image fusion network wavelet transform state space model,"Tianpei Zhang, Yiming Zhu, Jufeng Zhao, Guangmang Cui, Yuchen Zheng",deep learning technique revolutionize infrared visible image fusion ivif show remarkable efficacy complex scenario however current method fully combine frequency domain feature global semantic information result suboptimal extraction global feature modality insufficient preservation local texture detail address issue propose wavelet mamba w mamba integrate wavelet transform state space model ssm specifically introduce wavelet ssm module incorporate wavelet based frequency domain feature extraction global information extraction ssm thereby effectively capture global local feature additionally propose cross modal feature attention modulation facilitate efficient interaction fusion different modality experimental result indicate method achieve visually compelling result superior performance compare current state of the art method code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18371,best get enough rest continual learning,"Hankyul Kang, Gregor Seifer, Donghyun Lee, Jongbin Ryu",accord forget curve theory enhance memory retention learn extensive data take adequate rest mean order effectively retain new knowledge essential learn thoroughly ensure sufficient rest brain memorize forget main takeaway theory learn extensive data necessitates sufficient rest learn data aspect human long term memory retention effectively utilized address continual learning neural network retain new knowledge long period time catastrophic forgetting critical problem continual learning therefore base ebbinghaus theory introduce view batch model adjust learning schedule optimize recall interval retrain sample propose view batch model allow network get enough rest learn extensive knowledge sample recall interval sufficient length end specifically present two approach replay method guarantee optimal recall interval self supervised learning acquire extensive knowledge single training sample time empirically show approach method align forget curve theory enhance long term memory experiment also demonstrate method significantly improve many state of the art continual learning method various protocol scenario open source project http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18370,diffusedwrinkles diffusion based model data driven garment animation,"Raquel Vidaurre, Elena Garces, Dan Casas",present data driven method learn generate animation garment use image diffusion model contrast exist method typically base fully connect network graph neural network generative adversarial network difficulty cope parametric garment fine wrinkle detail approach able synthesize high quality animation wide variety garment body shape agnostic garment mesh topology key idea represent garment deformation layout consistent texture encode offset respect parametric garment template use representation encode large dataset garment simulate various motion shape train novel conditional diffusion model able synthesize high quality pose shape and design dependent garment deformation model generative synthesize various plausible deformation give target pose shape design additionally show condition model use exist garment state enable generation temporally coherent sequence,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18368,efficient monarch sparse tune representation learning,"Xu Han, Yuan Tang, Jinfeng Xu, Xianzhi Li",introduce monarch sparse tuning first reparameterization based parameter efficient fine tuning peft method tailor representation learning exist adapter based prompt tuning peft method introduces additional inference overhead compatible many representation learn backbone core present new family structured matrix point cloud point monarch capture local geometric feature irregular point offer high expressiveness reparameterizes dense update weight matrix sparse point monarch matrix significantly reduce parameter retain strong performance experiment various backbone show simple effective highly generalizable capture local feature point cloud achieve state of the art result multiple benchmark acc scanobjectnn classification also combine matrix decomposition low rank kronecker reduce parameter,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18364,matting level semantic segmentation benchmark,"Chenxi Xie, Minghan Li, Hui Zeng, Jun Luo, Lei Zhang",high resolution semantic segmentation essential application image editing bokeh imaging etc unfortunately exist datasets often limit resolution lack precise mask detail boundary work build large scale matting level semantic segmentation dataset name consist real world image resolution provide high quality mask annotation number object categorize seven category human vegetation ground sky water building others feature precise mask average mask complexity time high exist semantic segmentation datasets consequently present method specifically design high resolution semantic segmentation namely massformer employ efficient pixel decoder aggregate high level semantic feature low level texture feature three stage aim produce high resolution mask minimal computational cost finally propose new learning paradigm integrate high quality mask seven give category pseudo label new class enable massformer transfer accurate segmentation capability class object propose massformer comprehensively evaluate benchmark together representative segmentation model expect meticulously annotate dataset massformer model facilitate research high resolution high quality semantic segmentation datasets code find http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18363,monoinstance enhance monocular prior multi view instance alignment neural rendering reconstruction,"Wenyuan Zhang, Yixiao Yang, Han Huang, Liang Han, Kanle Shi, Yu-Shen Liu",monocular depth prior widely adopt neural rendering multi view base task reconstruction novel view synthesis however due inconsistent prediction view effectively leverage monocular cue multi view context remain challenge current method treat entire estimate depth map indiscriminately use ground truth supervision ignore inherent inaccuracy cross view inconsistency monocular prior resolve issue propose monoinstance general approach explore uncertainty monocular depth provide enhanced geometric prior neural rendering reconstruction key insight lie align segment instance depth multiple view common space thereby cast uncertainty estimation monocular depth density measure noisy point cloud high uncertainty area depth prior unreliable introduce constraint term encourage projected instance align correspond instance mask nearby view monoinstance versatile strategy seamlessly integrate various multi view neural rendering framework experimental result demonstrate monoinstance significantly improve performance reconstruction novel view synthesis various benchmark,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18361,nerfprior learning neural radiance field prior indoor scene reconstruction,"Wenyuan Zhang, Emily Yue-ting Jia, Junsheng Zhou, Baorui Ma, Kanle Shi, Yu-Shen Liu",recently show prior vital neural implicit function reconstruct high quality surface multi view rgb image however current prior require large scale pre training merely provide geometric clue consider importance color paper present nerfprior adopt neural radiance field prior learn signed distance field use volume render surface reconstruction nerf prior provide geometric color clue also get train fast scene additional data base nerf prior enable learn signed distance function sdf explicitly impose multi view consistency constraint ray intersection surface inference specifically ray intersection use density prior coarse geometry estimation use color surface clue check visibility view angle textureless area multi view consistency constraint work well introduce depth consistency loss confidence weight infer sdf experimental result state of the art method widely use benchmark,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18359,context enhanced memory refined transformer online action detection,"Zhanzhong Pang, Fadime Sener, Angela Yao",online action detection oad detect action stream video use past observation state of the art oad approach model past observation interaction anticipated future past encode use short  long term memory capture immediate long range dependency anticipation compensates miss future context identify training inference discrepancy exist oad method hinders learn effectiveness training use vary length short term memory inference relies full length short term memory remedy propose context enhanced memory refined transformer cmert cmert introduce context enhanced encoder improve frame representation use additional near past context also feature memory refined decoder leverage near future generation enhance performance cmert achieve state of the art online detection anticipation crosstask,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18358,cost sensitive learning long tailed temporal action segmentation,"Zhanzhong Pang, Fadime Sener, Shrinivas Ramasubramanian, Angela Yao",temporal action segmentation untrimmed procedural video aim densely label frame action class video inherently exhibit long tailed distribution action vary widely frequency duration temporal action segmentation approach identify bi level learning bias bias encompass class level bias stem class imbalance favor head class transition level bias arise variation transition prioritize commonly observe transition remedy introduce constrained optimization problem alleviate bias define learn state action class associated transition integrate optimization process propose novel cost sensitive loss function formulate weighted cross entropy loss weight adaptively adjust base learn state action transition experiment three challenge temporal segmentation benchmark various framework demonstrate effectiveness approach result significant improvement per class frame wise segment wise performance,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18352,ultra high resolution image synthesis latent diffusion model,"Jinjin Zhang, Qiuyu Huang, Junjie Liu, Xiefan Guo, Di Huang",paper present novel framework direct ultra high resolution image synthesis use text to image diffusion model core advancement include benchmark address absence publicly available image synthesis dataset construct comprehensive benchmark ultra high resolution image generation curated high quality dataset carefully select image caption generate additionally introduce glcm score compression ratio metric evaluate fine detail combine holistic measure fid aesthetic clipscore comprehensive assessment ultra high resolution image wavelet based fine tuning propose wavelet based fine tuning approach direct training photorealistic image applicable various latent diffusion model demonstrate effectiveness synthesize highly detailed image consequently achieves impressive performance high quality image synthesis text prompt adherence especially power modern large scale diffusion model extensive experimental result benchmark demonstrate superiority ultra high resolution image synthesis,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18349,human object interaction vision language model guide relative movement dynamic,"Zekai Deng, Ye Shi, Kaiyang Ji, Lan Xu, Shaoli Huang, Jingya Wang",human object interaction hoi vital advance simulation animation robotics enable generation long term physically plausible motion environment however exist method often fall short achieve physic realism support diverse type interaction address challenge paper introduce unified human object interaction framework provide unified control interaction static scene dynamic object use language command interaction human object part always describe continuous stable relative movement dynamic rmd human object part leverage world knowledge scene perception capability vision language model vlms translate language command rmd diagram use guide goal conditioned reinforcement learn sequential interaction object framework support long horizon interaction dynamic articulate static object support training evaluation framework present new dataset name interplay include multi round task plan generate vlms cover static dynamic hoi task extensive experiment demonstrate propose framework effectively handle wide range hoi task showcasing ability maintain long term multi round transition detail please refer project webpage http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18341,p eip robust photometric stereo base event interval profile,"Kazuma Kitazawa, Takahito Aoto, Satoshi Ikehata, Tsuyoshi Takatani",recently energy efficient photometric stereo method use event camera propose recover surface normal event trigger change logarithmic lambertian reflection moving directional light source however eventps treat event interval independently make sensitive noise shadow non lambertian reflection paper propose photometric stereo base event interval profile ps eip robust method recovers pixelwise surface normal time series profile event interval exploit continuity profile introduce outlier detection method base profile shape approach enhance robustness outlier shadow specular reflection experiment use real event data object demonstrate p eip significantly improve robustness outlier compare eventps deep learning variant eventps fcn rely deep learning,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18339,granq granular zero shot quantization unified layer channel awareness,"Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park",zero shot quantization zsq enable neural network compression train data crucial restricted data access environment however exist zsq method suffer significant activation loss low bit environment owe coarse grained scaling strategy address issue propose granq novel zsq approach leverage layer channel awareness minimize quantization error conventional layer  channel wise quantization granq dynamically adjust quantization granularity consider layer  channel level activation distribution enable fine grained quantization minimize activation distortion additionally introduce vectorized activation quantization enable efficient parallel computation reduce computational overhead preserve accuracy granq achieve superior performance compare state of the art zsq method employ quantization aware training finding anticipate granq inspire novel research direction conventional zsq approach focus data generation model training,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18338,spmtrack spatio temporal parameter efficient fine tuning mixture expert scalable visual tracking,"Wenrui Cai, Qingjie Liu, Yunhong Wang",state of the art tracker adopt one stream paradigm use single vision transformer joint feature extraction relation modeling template search region image however relation model different image patch exhibit significant variation instance background region dominate target irrelevant information require reduce attention allocation foreground particularly boundary area need emphasize single model may effectively handle kind relation model simultaneously paper propose novel tracker call spmtrack base mixture of expert tailor visual tracking task tmoe combine capability multiple expert handle diverse relation model flexibly benefit tmoe extend relation modeling image pair spatio temporal context improve track accuracy minimal increase model parameter moreover employ tmoe parameter efficient fine tuning method substantially reduce trainable parameter enable train spmtrack vary scale efficiently preserve generalization ability pretrained model achieve superior performance conduct experiment seven datasets experimental result demonstrate method significantly outperform current state of the art tracker source code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18337,coeff tuning graph filter subspace view tune attention based large model,"Zichen Miao, Wei Chen, Qiang Qiu",transformer based large pre trained model show remarkable generalization ability various parameter efficient fine tuning peft method propose customize model downstream task minimal computational memory budget previous peft method primarily design tensor decomposition perspective try effectively tune linear transformation find small subset parameter train study adopt orthogonal view represent attention operation graph convolution formulate multi head attention map convolutional filter subspace attention map subspace element paper propose tune large pre trained transformer learn small set combination coefficient construct expressive filter subspace original multi head attention map show analytically experimentally tuned filter subspace effectively expand feature space multi head attention enhance capacity transformer stabilize fine tuning residual parameterization tunable subspace coefficient enhance generalization regularization design directly apply dropout tunable coefficient training tunable coefficient take tiny number parameter combine previous peft method plug and play manner extensive experiment show approach achieve superior performance peft baseline neglectable additional parameter,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18334,mitigate cache noise test time adaptation large vision language model,"Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li",test time adaptation tta visual language model recently attract significant attention solution performance degradation cause distribution shift downstream task however exist cache based tta method certain limitation mainly rely accuracy cached feature label presence noisy pseudo label cause feature deviate true distribution make cache retrieval method base similarity match highly sensitive outlier extreme sample moreover current method lack effective mechanism model class distribution limit ability fully exploit potential cached information address challenge introduce comprehensive reliable caching mechanism propose novel zero shot tta method call cache residual gaussian crg method employ learnable residual parameter good align positive negative visual prototype text prototype thereby optimize quality cached feature also incorporate gaussian discriminant analysis gda dynamically model intra class feature distribution mitigate impact noisy feature experimental result benchmark demonstrate crg outperform state of the art tta method showcasing exceptional robustness adaptability,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18328,tensoflow tensorial flow based sampler inverse rendering,"Chun Gu, Xiaofei Wei, Li Zhang, Xiatian Zhu",inverse render aim recover scene geometry material property light multi view image give complexity light surface interaction importance sampling essential evaluation render equation reduce variance enhance efficiency monte carlo sample exist inverse render method typically use pre defined non learnable importance sampler prior manually struggle effectively match spatially directionally varied integrand result high variance suboptimal performance address limitation propose concept learn spatially directionally aware importance sampler render equation accurately flexibly capture unconstrained complexity typical scene formulate tensoflow generic approach sampler learning inverse rendering enable closely match integrand render equation spatially directionally concretely sampler parameterized normalize flow allow directional sampling incident light probability density function pdf inference capture characteristic sampler spatially learn tensorial representation scene space impose spatial condition together reflected direction lead spatially directionally aware sample distribution model optimize minimize difference integrand normalizing flow extensive experiment validate superiority tensoflow prior alternative synthetic real world benchmark,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18325,towards training free anomaly detection vision language foundation model,"Jinjin Zhang, Guodong Wang, Yizhou Jin, Di Huang",anomaly detection valuable real world application industrial quality inspection however approach focus detect local structural anomaly neglect compositional anomaly incorporate logical constraint paper introduce logsad novel multi modal framework require training logical structural anomaly detection first propose match of thought architecture employ advanced large multi modal model generate matching proposal formulate interest compositional rule thought anomaly detection second elaborate multi granularity anomaly detection consist patch token set interest composition match vision language foundation model subsequently present calibration module align anomaly score different detector follow integration strategy final decision consequently approach address logical structural anomaly detection unified framework achieve state of the art result need training even compare supervise approach highlight robustness effectiveness code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18324,plug and play interpretable responsible text to image generation dual space multi facet concept control,"Basim Azam, Naveed Akhtar",ethical issue text to image model demand comprehensive control generative content exist technique address issue responsible model aim generated content fair safe however method remain bounded handle facet responsibility concept individually also lack interpretability moreover often require alteration original model compromise model performance work propose unique technique enable responsible generation simultaneously account extensive range concept fair safe content generation scalable manner key idea distill target pipeline external plug and play mechanism learn interpretable composite responsible space desired concept condition target pipeline use knowledge distillation concept whitening enable inference learned space utilize modulate generative content typical pipeline present two plug in point approach namely text embed space diffusion model latent space develop module point show effectiveness approach range strong result,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18312,diff palm realistic palmprint generation polynomial crease intra class variation controllable diffusion model,"Jianlong Jin, Chenglong Zhao, Ruixin Zhang, Sheng Shang, Jianqing Xu, Jingyun Zhang, ShaoMing Wang, Yang Zhao, Shouhong Ding, Wei Jia, Yunsheng Wu",palmprint recognition significantly limit lack large scale publicly available datasets previous method adopt bézier curve simulate palm crease serve input conditional gans generate realistic palmprints however employ real data fine tuning performance recognition model train synthetic datasets would drastically decline indicate large gap generate real palmprints primarily due utilization inaccurate palm crease representation challenge balance intra class variation identity consistency address introduce polynomial based palm crease representation provide new palm crease generation mechanism closely align real distribution also propose palm crease condition diffusion model novel intra class variation control method apply propose k  step noise sharing sampling able synthesize palmprint datasets large intra class variation high identity consistency experimental result show first time recognition model train solely synthetic datasets fine tuning outperform train real datasets furthermore approach achieve superior recognition performance number generated identity increase,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18297,image to text medical report use adaptive co attention triple lstm module,"Yishen Liu, Shengda Liu, Hudan Pan",medical report generation require specialized expertise general large model often fail accurately capture moreover inherent repetition similarity medical data make difficult model extract meaningful feature result tendency overfit paper propose multimodal model co attention triple lstm network ca trinet deep learning model combine transformer architecture multi lstm network co attention module synergistically link vision transformer text transformer good differentiate medical image similarity augment adaptive weight operator catch amplify image label minor similarity furthermore triple lstm module refines generate sentence use targeted image object extensive evaluation three public datasets demonstrate ca trinet outperforms state of the art model term comprehensive ability even pre trained large language model metric,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18294,lgps lightweight gan based approach polyp segmentation colonoscopy image,"Fiseha B. Tesema, Alejandro Guerra Manzanares, Tianxiang Cui, Qian Zhang, Moses Solomon, Sean He",colorectal cancer crc major global cause cancer related death early polyp detection removal colonoscopy crucial prevention deep learn method show promise polyp segmentation challenge high computational cost difficulty segment small low contrast polyp limited generalizability datasets persist address issue propose lgps lightweight gan based framework polyp segmentation lgps incorporate three key innovation backbone enhance modified residual block squeeze and excitation rese module efficient feature extraction convolutional conditional random field convcrf precise boundary refinement hybrid loss function combine binary cross entropy weight iou loss dice loss address class imbalance enhance segmentation accuracy lgps validate five benchmark datasets compare state of the art sota method large challenge polypgen test dataset lgps achieve dice iou outperform sota work demonstrate robust generalization million parameter lgps time small small exist model make highly suitable real time clinical application lightweight design strong performance underscore potential improve early crc diagnosis code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18286,co spy combining semantic pixel feature detect synthetic image ai,"Siyuan Cheng, Lingjuan Lyu, Zhenting Wang, Xiangyu Zhang, Vikash Sehwag",rapid advancement generative ai possible synthesize high quality image second power technology raise significant concern regard misuse current effort distinguish real ai generated image may lack generalization effective certain type generative model susceptible post processing technique jpeg compression overcome limitation propose novel framework co spy first enhances exist semantic feature number finger hand artifact feature pixel value difference adaptively integrate achieve general robust synthetic image detection additionally create co spy bench comprehensive dataset comprise real image datasets state of the art generative model include late model flux also collect synthetic image wild internet enable evaluation practical setting extensive evaluation demonstrate detector outperform exist method identical training condition achieve average accuracy improvement approximately code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18283,voxel based point cloud geometry compression space to channel context,"Bojun Liu, Yangzhi Ma, Ao Luo, Li Li, Dong Liu",voxel based method efficient point cloud geometry compression particularly dense point cloud however face limitation due restricted receptive field especially handle high bit depth point cloud overcome issue introduce stage wise space to channel context model dense point cloud low level sparse point cloud model utilize channel wise autoregressive strategy effectively integrate neighborhood information coarse resolution high level sparse point cloud propose level wise context model address resolution limitation incorporate geometry residual coding grc consistent resolution cross level prediction additionally use spherical coordinate system compact representation enhance grc approach residual probability approximation rpa module feature large kernel size experimental result show context model achieve bit saving maintain improve reconstruction quality also reduce computational complexity compare state of the art voxel based compression method,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18282,dataset algorithm multi player tracking identification pose estimation basketball full court video,"Kazuhiro Yamada, Li Yin, Qingrui Hu, Ning Ding, Shunsuke Iwashita, Jun Ichikawa, Kiwamu Kotani, Calvin Yeung, Keisuke Fujii",multi object tracking player identification pose estimation fundamental component sport analytics essential analyze player movement performance tactical strategy however exist datasets methodology primarily target mainstream team sport soccer conventional basketball often overlook scenario involve fixed camera setup commonly use amateur level less mainstream sport datasets explicitly incorporate pose annotation paper propose dataset first publicly available comprehensive dataset specifically design multi player tracking player identification pose estimation basketball scenario dataset comprise three distinct subset indoor fixed camera outdoor fixed camera drone camera footage capture diverse full court camera perspective environment also introduce track id task simplified variant game state reconstruction task exclude field detection focus exclusively fixed camera scenario evaluate performance propose baseline algorithm call track id algorithm tailor assess tracking identification quality furthermore benchmark experiment utilizing recent multi object tracking algorithm bot sort reid top down pose estimation method hrnet rtmpose swinpose demonstrate robust result highlight remain challenge dataset evaluation benchmark provide solid foundation advance automated analytics basketball dataset code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18278,topv compatible token prune inference time optimization fast low memory multimodal vision language model,"Cheng Yang, Yang Sui, Jinqi Xiao, Lingyi Huang, Yu Gong, Chendi Li, Jinghua Yan, Yu Bai, Ponnuswamy Sadayappan, Xia Hu, Bo Yuan",vision language model vlms demand substantial computational resource inference largely due extensive visual input token represent visual information previous study note visual token tend receive less attention text token suggest low importance inference potential prune however method encounter several challenge reliance greedy heuristic criterion token importance incompatibility flashattention kv cache address issue introduce topv compatible ken p run inference time optimization fast low memory v lm achieve efficient prune additional training fine tuning instead rely attention score formulate token pruning optimization problem accurately identify important visual token remain compatible flashattention additionally perform pruning prefilling stage effectively reduce kv cache size optimization framework incorporate visual aware cost function consider factor feature similarity relative spatial distance absolute central distance measure importance source visual token enable effective pruning low importance token extensive experiment demonstrate method outperform previous token prune method validate effectiveness efficiency approach,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18267,enhance dataset distillation non critical region refinement,"Minh-Tuan Tran, Trung Le, Xuan-May Le, Thanh-Toan Do, Dinh Phung",dataset distillation become popular method compress large datasets small efficient representation preserve critical information model training data feature broadly categorize two type instance specific feature capture unique fine grained detail individual example class general feature represent share broad pattern class however previous approach often struggle balance features some focus solely class general pattern neglect finer instance detail others prioritize instance specific feature overlook share characteristic essential class level understanding paper introduce non critical region refinement dataset distillation nrr dd method preserve instance specific detail fine grained region synthetic data enrich non critical region class general information approach enable model leverage pixel information capture feature type enhance overall performance additionally present distance based representative dbr knowledge transfer eliminate need soft label training rely distance synthetic data prediction one hot encoded label experimental result show nrr dd achieves state of the art performance small  large scale datasets furthermore store two distance instance method delivers comparable result various setting code available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18254,surface aware distil semantic feature,"Lukas Uzolas, Elmar Eisemann, Petr Kellnhofer",many task pose alignment animation motion transfer reconstruction rely establish correspondence shape challenge recently approach match semantic feature pre trained vision model however power feature struggle differentiate instance semantic class left hand versus right hand lead substantial mapping error solve learn surface aware embedding space robust ambiguity importantly approach self supervised require small number unpaired training mesh infer feature new shape test time achieve introduce contrastive loss preserve semantic content feature distil foundational model disambiguate feature locate far apart shape surface observe superior performance correspondence matching benchmark enable downstream application include in part segmentation pose alignment motion transfer project site available http url,CV,24 Mar 2025
https://doi.org/10.48550/arXiv.2503.18244,customkd customize large vision foundation edge model improvement knowledge distillation,"Jungsoo Lee, Debasmit Das, Munawar Hayat, Sungha Choi, Kyuwoong Hwang, Fatih Porikli",propose novel knowledge distillation approach customkd effectively leverage large vision foundation model lvfms enhance performance edge model recent advancement lvfms clip potential knowledge distillation enhance edge model remain underexplored knowledge distillation promising approach improve performance edge model discrepancy model capacity heterogeneous architecture lvfms edge model pose significant challenge observation indicate utilizing large backbone vit s vit l teacher model improve downstream task performance knowledge distillation large teacher model fail bring much performance gain student model teacher model due large model discrepancy simple yet effective customkd customize well generalized feature inherent lvfms give student model order reduce model discrepancy specifically provide well generalized original knowledge teacher customkd align feature teacher student make easy student understand overcome large model discrepancy overall customkd significantly improve performance edge model scenario unlabeled data unsupervised domain adaptation officehome domainnet semi supervised learning labeled sample imagenet labeled sample achieve new state of the art performance,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18227,pg sam prior guided sam medical multi organ segmentation,"Yiheng Zhong, Zihong Luo, Chengzhi Liu, Feilong Tang, Zelin Peng, Ming Hu, Yingzhen Hu, Jionglong Su, Zongyuan Geand, Imran Razzak",segment anything model sam demonstrate powerful zero shot capability however accuracy robustness significantly decrease apply medical image segmentation exist method address issue modality fusion integrate textual image information provide detailed prior study argue granularity text domain gap affect accuracy prior furthermore discrepancy high level abstract semantics pixel level boundary detail image introduce noise fusion process address propose prior guided sam pg sam employ fine grained modality prior aligner leverage specialized medical knowledge good modality alignment core method lie efficiently address domain gap fine grained text medical llm meanwhile also enhance prior quality modality alignment ensure accurate segmentation addition decoder enhance model expressive capability multi level feature fusion iterative mask optimizer operation support unprompted learning also propose unified pipeline effectively supply high quality semantic information sam extensive experiment synapse dataset demonstrate propose pg sam achieve state of the art performance anonymous code release http url,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18223,mammalps multi view video behavior monitor dataset wild mammal swiss alp,"Valentin Gabeff, Haozhe Qi, Brendan Flaherty, Gencer Sumbül, Alexander Mathis, Devis Tuia",monitor wildlife essential ecology ethology especially light increase human impact ecosystem camera trap emerge habitat centric sensor enable study wildlife population scale minimal disturbance however lack annotated video datasets limit development powerful video understanding model need process vast amount fieldwork data collect advance research wild animal behavior monitoring present mammalps multimodal multi view dataset wildlife behavior monitoring camera trap swiss national park mammalps contain hour video audio segmentation map hour individual track densely label specie behavior base single animal clip propose first hierarchical multimodal animal behavior recognition benchmark use audio video reference scene segmentation map input furthermore also propose second ecology oriented benchmark aim identify activity specie number individual meteorological condition multi view long term ecological event include false positive trigger advocate task complementary contribute bridge gap machine learning ecology code data available http url,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18211,simmotionedit text based human motion edit motion similarity prediction,"Zhengyuan Li, Kai Cheng, Anindita Ghosh, Uttaran Bhattacharya, Liangyan Gui, Aniket Bera",text based human motion editing critical yet challenge task computer vision graphic training free approach explore recent release motionfix dataset include source text motion triplet open new avenue training yield promising result however exist method struggle precise control often lead misalignment motion semantics language instruction paper introduce related task motion similarity prediction propose multi task training paradigm train model jointly motion editing motion similarity prediction foster learning semantically meaningful representation complement task design advanced diffusion transformer based architecture separately handle motion similarity prediction motion editing extensive experiment demonstrate state of the art performance approach edit alignment fidelity,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18177,train neural network partially occlude road sign identification context autonomous vehicle,"Gulnaz Gimaletdinova, Dim Shaiakhmetov, Madina Akpaeva, Mukhammadmuso Abduzhabbarov, Kadyrmamat Momunov",increase number autonomous vehicle rapid development computer vision technology underscore particular importance conduct research accuracy traffic sign recognition numerous study field already achieve significant result demonstrate high effectiveness address traffic sign recognition task however task become considerably complex sign partially obscure surround object tree branch billboard element urban environment study investigate partial occlusion traffic sign affect recognition purpose collect dataset comprise image include fully visible partially occluded sign make publicly available use dataset compare performance custom convolutional neural network cnn achieve accuracy model train use transfer learning best result obtain full layer unfreezing reach accuracy additional experiment reveal model train solely fully visible sign lose effectiveness recognize occlude sign highlight critical importance incorporate real world data partial occlusion train set ensure robust model performance complex practical scenario enhance safety autonomous driving,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18170,self attention diffusion model zero shot biomedical image segmentation unlocking new frontier medical imaging,"Abderrachid Hamrani, Anuradha Godavarty",produce high quality segmentation mask medical image fundamental challenge biomedical image analysis recent research explore large scale supervised training enable segmentation various medical imaging modality unsupervised training facilitate segmentation dense annotation however construct model capable segment diverse medical image zero shot manner annotation remain significant hurdle paper introduce attention diffusion zero shot unsupervised system adzus novel approach leverage self attention diffusion model zero shot biomedical image segmentation adzus harness intrinsic capability pre trained diffusion model utilize generative discriminative potential segment medical image require annotated training data prior domain specific knowledge adzus architecture detail integration self attention mechanism facilitate context aware detail sensitive segmentation highlight experimental result various medical image datasets include skin lesion segmentation chest x ray infection segmentation white blood cell segmentation reveal adzus achieves state of the art performance notably adzus reach dice score range iou score different segmentation task demonstrate significant improvement handle novel unseen medical imagery noteworthy adzus demonstrate high effectiveness demand substantial computational resource extend processing time model efficacy zero shot setting underscore potential reduce reliance costly annotation seamlessly adapt new medical imaging task thereby expand diagnostic capability ai driven medical imaging technology,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18160,mao efficient model agnostic optimization prompt tune vision language model,"Haoyang Li, Siyu Zhou, Liang Wang, Guodong Long",clip based prompt tune significantly enhance pre trained vision language model exist research focus reconstruct model architecture additional loss calculation meta network approach generally lead increase complexity extend training cost maintain efficiency tuning process propose plug and play model agnostic optimization mao prompt tuning alter component prompt tune backbone introduce data driven enhancement framework optimize distribution initial data incorporate alterable regularization module boost task specific feature processing pipeline thereby improve overall performance maintain low computational cost extensive experiment mao demonstrate outstanding performance efficiency code mao available http url,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18159,diffusiontalker efficient compact speech driven talk head personalizer guided distillation,"Peng Chen, Xiaobao Wei, Ming Lu, Hui Chen, Feng Tian",real time speech driven facial animation attractive academia industry traditional method mainly focus learn deterministic mapping speech animation recent approach start consider nondeterministic fact speech driven face animation employ diffusion model task exist diffusion based method improve diversity facial animation however personalize speaking style convey accurate lip language still lack besides efficiency compactness still need improve work propose diffusiontalker address limitation personalizer guided distillation term personalization introduce contrastive personalizer learn identity emotion embeddings capture speak style audio propose personalizer enhancer distillation enhance influence embeddings facial animation efficiency use iterative distillation reduce step require animation generation achieve speedup inference achieve compactness distill large teacher model small student model reduce model storage minimize performance loss distillation user derive identity emotion embeddings audio quickly create personalized animation reflect specific speaking style extensive experiment conduct demonstrate method outperform state of the art method code release http url,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18155,decorum language based approach style conditioned synthesis indoor scene,"Kelly O. Marshall, Omid Poursaeed, Sergiu Oprea, Amit Kumar, Anushrut Jignasu, Chinmay Hegde, Yilei Li, Rakesh Ranjan",indoor scene generation important problem design digital real world environment automate process scene generation model able generate plausible scene layout also take consideration visual feature style preference exist method task exhibit limited control attribute allow text input form simple object level description pairwise spatial relationship propose method decorum enable user control scene generation process natural language adopt language based representation stage enable harness recent advancement large language model llm model language to language mapping addition show use text based representation allow select furniture scene use novel object retrieval method base multimodal llm evaluation benchmark dataset show method achieve improvement exist work text conditioned scene synthesis object retrieval,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18150,longdiff training free long video generation one go,"Zhuoling Li, Hossein Rahmani, Qiuhong Ke, Jun Liu",video diffusion model recently achieve remarkable result video generation encouraging performance model mainly design train short video generation lead challenge maintain temporal consistency visual detail long video generation paper propose longdiff novel training free method consisting carefully design component position mapping pm informative frame selection ifs tackle two key challenge hinder short to long video generation generalization temporal position ambiguity information dilution longdiff unlock potential off the shelf video diffusion model achieve high quality long video generation one go extensive experiment demonstrate efficacy method,CV,23 Mar 2025
https://doi.org/10.48550/arXiv.2503.18147,pht cad efficient cad parametric primitive analysis progressive hierarchical tuning,"Ke Niu, Yuwen Chen, Haiyang Yu, Zhuofan Chen, Xianghui Que, Bin Li, Xiangyang Xue",computer aided design cad play pivotal role industrial manufacturing yet parametric primitive analysis ppa remain underexplored due two key challenge structural constraint reasoning advance semantic understanding tackle challenge first propose efficient hybrid parametrization ehp good represent engineering drawing ehp contain four type atomic component point line circle arc additionally propose pht cad novel ppa framework harness modality alignment reason capability vision language model vlms precise engineering draw analysis pht cad introduce four dedicate regression head predict correspond atomic component train pht cad three stage training paradigm progressive hierarchical tuning pht propose progressively enhance pht cad capability perceive individual primitive infer structural constraint align annotation layer correspond geometric representation consider exist datasets lack complete annotation layer real world engineering drawing introduce paracad first large scale benchmark explicitly integrate geometric annotation layer paracad comprise million annotated drawing training real world industrial drawing complex topological structure physical constraint test extensive experiment demonstrate effectiveness pht cad highlight practical significance paracad advance ppa research,CV,23 Mar 2025
